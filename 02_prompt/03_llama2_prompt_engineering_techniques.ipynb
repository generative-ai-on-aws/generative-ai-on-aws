{"cells":[{"cell_type":"markdown","id":"57fee1e7-081e-4c22-af70-9839fcfcec32","metadata":{"id":"57fee1e7-081e-4c22-af70-9839fcfcec32"},"source":["# 4ì¥"]},{"cell_type":"markdown","id":"3336b23c-be24-4299-82d1-4ba0c578385d","metadata":{"id":"3336b23c-be24-4299-82d1-4ba0c578385d"},"source":["### helper í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°"]},{"cell_type":"code","execution_count":null,"id":"2df73149-4fad-4f63-aa85-d338cbffe23d","metadata":{"id":"2df73149-4fad-4f63-aa85-d338cbffe23d"},"outputs":[],"source":["from utils import llama, llama_chat"]},{"cell_type":"markdown","id":"7faef740-19bd-421e-a985-43217d6d6825","metadata":{"id":"7faef740-19bd-421e-a985-43217d6d6825"},"source":["### ë¬¸ë§¥ ë‚´ í•™ìŠµ\n","\n","#### ì¸ìŠ¤íŠ¸ëŸ­ì…˜ì´ í¬í•¨ëœ í‘œì¤€ í”„ë¡¬í”„íŠ¸\n","- ì§€ê¸ˆê¹Œì§€ëŠ” í”„ë¡¬í”„íŠ¸ì— ì¸ìŠ¤íŠ¸ëŸ­ì…˜ì„ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í–ˆìŠµë‹ˆë‹¤:"]},{"cell_type":"code","execution_count":null,"id":"3ea534c7-e213-417f-a99c-0f8dba92387e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ea534c7-e213-417f-a99c-0f8dba92387e","executionInfo":{"status":"ok","timestamp":1722070208909,"user_tz":-540,"elapsed":1710,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"37285285-73c4-411e-f893-b0eb97753e49"},"outputs":[{"output_type":"stream","name":"stdout","text":["  The sentiment of the message \"Hi Amit, thanks for the thoughtful birthday card!\" is positive. The use of the word \"thoughtful\" implies that the sender appreciated the effort put into the card, and the tone is friendly and sincere.\n"]}],"source":["prompt = \"\"\"\n","What is the sentiment of:\n","Hi Amit, thanks for the thoughtful birthday card!\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"45096c64-f483-4d01-b64c-8de1fb529441","metadata":{"id":"45096c64-f483-4d01-b64c-8de1fb529441"},"source":["### ì œë¡œìƒ· í”„ë¡¬í”„íŠ¸\n","- ì—¬ê¸° ì œë¡œìƒ· í”„ë¡¬í”„íŠ¸ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤.\n","- í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ë¥¼ í†µí•´ ëª¨ë¸ì´ ì‘ì—…ì„ ì§„í–‰í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n","- ì œë¡œìƒ· í”„ë¡¬í”„íŠ¸ì—ì„œëŠ” ì‘ì—… ì˜ˆì‹œ ì—†ì´ ë‹¨ì§€ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ë§Œì„ ëª¨ë¸ì— ì œê³µí•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"549667d6-6b23-46a9-8c4a-f089f7936392","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"549667d6-6b23-46a9-8c4a-f089f7936392","executionInfo":{"status":"ok","timestamp":1722070210117,"user_tz":-540,"elapsed":1217,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"c4f2363e-b6c5-4c83-9014-af793e29f36d"},"outputs":[{"output_type":"stream","name":"stdout","text":["  The sentiment of the message is \"Appreciation\" or \"Gratitude\". The sender is expressing their appreciation for the birthday card that Amit sent.\n"]}],"source":["prompt = \"\"\"\n","Message: Hi Amit, thanks for the thoughtful birthday card!\n","Sentiment: ?\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"b162fb3d-7020-47c6-bb08-5ed6f138da66","metadata":{"id":"b162fb3d-7020-47c6-bb08-5ed6f138da66"},"source":["### í“¨ìƒ· í”„ë¡¬í”„íŠ¸\n","- ì•„ë˜ëŠ” í“¨ìƒ· í”„ë¡¬í”„íŠ¸ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤.\n","- í“¨ìƒ· í”„ë¡¬í”„íŠ¸ì—ì„œëŠ” í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ë¿ë§Œ ì•„ë‹ˆë¼ ë‘ ê°œ ì´ìƒì˜ ì˜ˆì‹œë„ ëª¨ë¸ì— ì œê³µí•©ë‹ˆë‹¤.\n","- í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ì™€ ì˜ˆì‹œë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ì´ ì‘ì—…ì„ ì§„í–‰í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"bd349402-904a-4e33-9e7c-88a41afc5ec9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bd349402-904a-4e33-9e7c-88a41afc5ec9","executionInfo":{"status":"ok","timestamp":1722070211355,"user_tz":-540,"elapsed":1245,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"1a87f13e-63c9-44ba-ce09-7ae1dcac3514"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Sure, here are the sentiments for each message:\n","\n","1. Message: Hi Dad, you're 20 minutes late to my piano recital!\n","Sentiment: Negative\n","2. Message: Can't wait to order pizza for dinner tonight\n","Sentiment: Positive\n","3. Message: Hi Amit, thanks for the thoughtful birthday card!\n","Sentiment: Positive\n"]}],"source":["prompt = \"\"\"\n","Message: Hi Dad, you're 20 minutes late to my piano recital!\n","Sentiment: Negative\n","\n","Message: Can't wait to order pizza for dinner tonight\n","Sentiment: Positive\n","\n","Message: Hi Amit, thanks for the thoughtful birthday card!\n","Sentiment: ?\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"41560853-9639-4329-87ac-640620bb4b39","metadata":{"id":"41560853-9639-4329-87ac-640620bb4b39"},"source":["### ì¶œë ¥ í˜•ì‹ ì§€ì •í•˜ê¸°\n","- ëª¨ë¸ì´ ì‘ë‹µí•  í˜•ì‹ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤,\n","- ì•„ë˜ ì˜ˆì‹œì—ì„œ, \"í•œ ë‹¨ì–´ë¡œ ì‘ë‹µí•´ ì£¼ì„¸ìš”\"ë¼ê³  ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"4f2669f8-9673-4568-aec2-4b9f13d033ba","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4f2669f8-9673-4568-aec2-4b9f13d033ba","executionInfo":{"status":"ok","timestamp":1722070212277,"user_tz":-540,"elapsed":926,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"e1778ddc-07f5-481c-cfff-ac4889b7bb98"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Sure! Here are the one-word responses for each message:\n","\n","1. Negative: Disappointed\n","2. Positive: Excited\n","3. ? (Uncertain): Grateful\n"]}],"source":["prompt = \"\"\"\n","Message: Hi Dad, you're 20 minutes late to my piano recital!\n","Sentiment: Negative\n","\n","Message: Can't wait to order pizza for dinner tonight\n","Sentiment: Positive\n","\n","Message: Hi Amit, thanks for the thoughtful birthday card!\n","Sentiment: ?\n","\n","Give a one word response.\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"a6e07176-5730-4cc0-bec1-cb3ae9000806","metadata":{"id":"a6e07176-5730-4cc0-bec1-cb3ae9000806"},"source":["**ì°¸ê³ **: ìœ„ ëª¨ë“  ì˜ˆì œì—ì„œ 70ì–µ ê°œ íŒŒë¼ë¯¸í„° ëª¨ë¸ì¸ `llama-2-7b-chat`ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ ì˜ˆì œì—ì„œ ë³´ì…¨ë“¯ì´, 70ì–µ ê°œ íŒŒë¼ë¯¸í„° ëª¨ë¸ì€ í™•ì‹¤í•œ ê°ì„± ë¶„ë¥˜ë¥¼ í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n","\n","- ë” í° 700ì–µ ê°œ íŒŒë¼ë¯¸í„° ëª¨ë¸ì¸ `llama-2-70b-chat`ì„ ì‚¬ìš©í•˜ì—¬ ë³´ë‹¤ ê°œì„ ë˜ê³  í™•ì‹¤í•œ ì‘ë‹µì„ ì–»ì„ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ ë³´ì„¸ìš”:"]},{"cell_type":"code","execution_count":null,"id":"415739fe-dcfe-4183-a5d8-fa3ce19aa480","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"415739fe-dcfe-4183-a5d8-fa3ce19aa480","executionInfo":{"status":"ok","timestamp":1722070213455,"user_tz":-540,"elapsed":1182,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"a66b95cd-5887-452d-8290-291bfc3d4c02"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Positive\n"]}],"source":["prompt = \"\"\"\n","Message: Hi Dad, you're 20 minutes late to my piano recital!\n","Sentiment: Negative\n","\n","Message: Can't wait to order pizza for dinner tonight\n","Sentiment: Positive\n","\n","Message: Hi Amit, thanks for the thoughtful birthday card!\n","Sentiment: ?\n","\n","Give a one word response.\n","\"\"\"\n","response = llama(prompt,\n","                model=\"togethercomputer/llama-2-70b-chat\")\n","print(response)"]},{"cell_type":"markdown","id":"fe196c59-2c42-4bdb-b7e7-a2f431ffce29","metadata":{"id":"fe196c59-2c42-4bdb-b7e7-a2f431ffce29"},"source":["- ì´ì œ, ë” ì‘ì€ ëª¨ë¸ì„ ë‹¤ì‹œ ì‚¬ìš©í•˜ë˜, ëª¨ë¸ì´ ìš”êµ¬ì‚¬í•­ì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.\n","- ëª¨ë¸ì˜ ì¶œë ¥ í˜•ì‹ì„ `ê¸ì •ì `, `ë¶€ì •ì `, ë˜ëŠ” `ì¤‘ë¦½` ì¤‘ì—ì„œ ì„ íƒí•˜ë„ë¡ ì œí•œí•´ ë³´ì„¸ìš”."]},{"cell_type":"code","execution_count":null,"id":"74528daa-90be-4208-98ac-3cf71dc687b6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74528daa-90be-4208-98ac-3cf71dc687b6","executionInfo":{"status":"ok","timestamp":1722070215000,"user_tz":-540,"elapsed":1547,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"fdbcbfab-8bcf-4313-8dc1-c4a043b04a29"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Sure, I'd be happy to help! Here are my responses:\n","\n","Message: Hi Dad, you're 20 minutes late to my piano recital!\n","Sentiment: Negative\n","\n","Message: Can't wait to order pizza for dinner tonight\n","Sentiment: Positive\n","\n","Message: Hi Amit, thanks for the thoughtful birthday card!\n","Sentiment: Positive\n"]}],"source":["prompt = \"\"\"\n","Message: Hi Dad, you're 20 minutes late to my piano recital!\n","Sentiment: Negative\n","\n","Message: Can't wait to order pizza for dinner tonight\n","Sentiment: Positive\n","\n","Message: Hi Amit, thanks for the thoughtful birthday card!\n","Sentiment:\n","\n","Respond with either positive, negative, or neutral.\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"47d3d067-2b77-4a35-b95b-d7ed9c5bc77f","metadata":{"id":"47d3d067-2b77-4a35-b95b-d7ed9c5bc77f"},"source":["\n","### ì—­í•  í”„ë¡¬í”„íŠ¸\n","- ì—­í•  í”„ë¡¬í”„íŠ¸ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì—ê²Œ ì–´ë–¤ ì¢…ë¥˜ì˜ ë‹µë³€ì´ í•„ìš”í•œì§€ì— ëŒ€í•œ ë¬¸ë§¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n","- ë¼ë§ˆ 2ëŠ” ì—­í• ì´ ë¶€ì—¬ë˜ì—ˆì„ ë•Œ ë” ì¼ê´€ë˜ê²Œ ì‘ë‹µí•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\n","- ìš°ì„ , í‘œì¤€ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•´ë³´ê³  ì‘ë‹µì„ í™•ì¸í•´ ë³´ì„¸ìš”."]},{"cell_type":"code","execution_count":null,"id":"9a94c6ba-5dd7-4a60-9dfe-c878c44fa44f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9a94c6ba-5dd7-4a60-9dfe-c878c44fa44f","executionInfo":{"status":"ok","timestamp":1722070220363,"user_tz":-540,"elapsed":5370,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"a762c872-4c0f-48b9-b5be-29fe73ed6791"},"outputs":[{"output_type":"stream","name":"stdout","text":["  The question of the meaning of life is a complex and philosophical one that has been debated throughout human history. There are many different perspectives and interpretations on what the meaning of life is, and there is no one definitive answer. However, here are some possible ways to approach this question:\n","\n","1. Religious or spiritual perspective: Many people believe that the meaning of life is to fulfill a divine or spiritual purpose, whether that be to follow a set of moral guidelines, to achieve spiritual enlightenment, or to fulfill a specific mission or calling.\n","2. Personal fulfillment: Some people believe that the meaning of life is to find personal fulfillment and happiness, whether that be through relationships, career, hobbies, or other activities.\n","3. Social or cultural perspective: From a social or cultural perspective, the meaning of life may be tied to the values and beliefs of one's community or society. For example, some cultures place a strong emphasis on family and community, while others prioritize individualism and personal freedom.\n","4. Existentialist perspective: Existentialist philosophers argue that the meaning of life is not predetermined or inherent, but rather something that each individual must create for themselves through their choices and experiences.\n","5. Humanistic perspective: From a humanistic perspective, the meaning of life may be tied to the development and fulfillment of one's human potential, whether that be through personal growth, creativity, or contributions to society.\n","6. Biological perspective: Some people believe that the meaning of life is tied to the survival and reproduction of the species, and that the purpose of life is to perpetuate the human race.\n","7. Epistemological perspective: From an epistemological perspective, the meaning of life may be tied to the pursuit of knowledge and understanding, and the quest for truth and wisdom.\n","8. Ethical perspective: Some people believe that the meaning of life is tied to ethical principles and values, such as compassion, empathy, and fairness.\n","9. Hedonistic perspective: From a hedonistic perspective, the meaning of life is tied to the pursuit of pleasure and enjoyment, and the avoidance of pain and suffering.\n","10. Nihilistic perspective: A nihilistic perspective on the meaning of life is that there is no inherent meaning or purpose, and that life is ultimately meaningless and absurd.\n","\n","Ultimately, the meaning of life is a deeply personal and subjective question that each individual must answer for themselves. It may depend on their values, beliefs, experiences, and circumstances, and it may change throughout their life as they grow and evolve as a person.\n"]}],"source":["prompt = \"\"\"\n","How can I answer this question from my friend:\n","What is the meaning of life?\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"42594189-5692-4ab3-9a1b-3d6ac58c8a78","metadata":{"id":"42594189-5692-4ab3-9a1b-3d6ac58c8a78"},"source":["- ì´ì œ ëª¨ë¸ì— \"ì—­í• \"ì„ ë¶€ì—¬í•˜ê³ , ê·¸ ì—­í•  ì•ˆì—ì„œ ì‘ë‹µí•  ë•Œ ì‚¬ìš©í•  \"ì–´ì¡°\"ë¥¼ ì§€ì •í•´ ë³´ì„¸ìš”."]},{"cell_type":"code","execution_count":null,"id":"2db7b960-d6f6-48a0-8c62-a68c999ad4fd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2db7b960-d6f6-48a0-8c62-a68c999ad4fd","executionInfo":{"status":"ok","timestamp":1722070223619,"user_tz":-540,"elapsed":3273,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"1089c713-a2c9-4ecd-e2ea-36eba8ddbcb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Shiver me timbers! Yer lookin' fer the meaning o' life, eh? Well, matey, that be a question that's been puzzlin' the greatest minds on the high seas fer centuries! *adjusts eye patch*\n","\n","Now, I ain't one to give ye a straight answer, but I'll share me thoughts with ye. The meaning o' life, me hearty, be different fer each and every one o' us. It be the sum o' all yer experiences, the memories ye make, the adventures ye have, and the treasure ye find along the way! *winks*\n","\n","Ye see, life be a great big ocean, and ye be a ship sailin' through it. Ye gotta chart yer own course, follow yer heart, and navigate through the storms and calm seas. The meaning o' life be findin' yer own treasure, me matey! *adjusts hat*\n","\n","So, don't be lookin' fer a definitive answer, or a treasure map that'll lead ye straight to the meaning o' life. It be a journey, a adventure, a treasure hunt, if ye will! *winks*\n","\n","Now, go forth and find yer own treasure, me hearty! And remember, the meaning o' life be whatever ye make it! *adjusts eye patch*\n"]}],"source":["role = \"\"\"\n","Your role is a life coach \\\n","who gives advice to people about living a good life.\\\n","You attempt to provide unbiased advice.\n","You respond in the tone of an English pirate.\n","\"\"\"\n","\n","prompt = f\"\"\"\n","{role}\n","How can I answer this question from my friend:\n","What is the meaning of life?\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"c0169c84-8f68-4544-8ee1-d02265635d49","metadata":{"id":"c0169c84-8f68-4544-8ee1-d02265635d49"},"source":["### ìš”ì•½\n","- ê¸´ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ëŠ” ê²ƒì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ë˜ ë‹¤ë¥¸ ì¼ë°˜ì ì¸ ì‚¬ìš© ì‚¬ë¡€ì…ë‹ˆë‹¤. í•œë²ˆ ì‹œë„í•´ ë³´ê² ìŠµë‹ˆë‹¤!"]},{"cell_type":"code","execution_count":null,"id":"434cd16f-ef7f-4a6b-9076-007893848518","metadata":{"id":"434cd16f-ef7f-4a6b-9076-007893848518"},"outputs":[],"source":["email = \"\"\"\n","Dear Amit,\n","\n","An increasing variety of large language models (LLMs) are open source, or close to it. The proliferation of models with relatively permissive licenses gives developers more options for building applications.\n","\n","Here are some different ways to build applications based on LLMs, in increasing order of cost/complexity:\n","\n","Prompting. Giving a pretrained LLM instructions lets you build a prototype in minutes or hours without a training set. Earlier this year, I saw a lot of people start experimenting with prompting, and that momentum continues unabated. Several of our short courses teach best practices for this approach.\n","One-shot or few-shot prompting. In addition to a prompt, giving the LLM a handful of examples of how to carry out a task â€” the input and the desired output â€” sometimes yields better results.\n","Fine-tuning. An LLM that has been pretrained on a lot of text can be fine-tuned to your task by training it further on a small dataset of your own. The tools for fine-tuning are maturing, making it accessible to more developers.\n","Pretraining. Pretraining your own LLM from scratch takes a lot of resources, so very few teams do it. In addition to general-purpose models pretrained on diverse topics, this approach has led to specialized models like BloombergGPT, which knows about finance, and Med-PaLM 2, which is focused on medicine.\n","For most teams, I recommend starting with prompting, since that allows you to get an application working quickly. If youâ€™re unsatisfied with the quality of the output, ease into the more complex techniques gradually. Start one-shot or few-shot prompting with a handful of examples. If that doesnâ€™t work well enough, perhaps use RAG (retrieval augmented generation) to further improve prompts with key information the LLM needs to generate high-quality outputs. If that still doesnâ€™t deliver the performance you want, then try fine-tuning â€” but this represents a significantly greater level of complexity and may require hundreds or thousands more examples. To gain an in-depth understanding of these options, I highly recommend the course Generative AI with Large Language Models, created by AWS and DeepLearning.AI.\n","\n","(Fun fact: A member of the DeepLearning.AI team has been trying to fine-tune Llama-2-7B to sound like me. I wonder if my job is at risk? ğŸ˜œ)\n","\n","Additional complexity arises if you want to move to fine-tuning after prompting a proprietary model, such as GPT-4, thatâ€™s not available for fine-tuning. Is fine-tuning a much smaller model likely to yield superior results than prompting a larger, more capable model? The answer often depends on your application. If your goal is to change the style of an LLMâ€™s output, then fine-tuning a smaller model can work well. However, if your application has been prompting GPT-4 to perform complex reasoning â€” in which GPT-4 surpasses current open models â€” it can be difficult to fine-tune a smaller model to deliver superior results.\n","\n","Beyond choosing a development approach, itâ€™s also necessary to choose a specific model. Smaller models require less processing power and work well for many applications, but larger models tend to have more knowledge about the world and better reasoning ability. Iâ€™ll talk about how to make this choice in a future letter.\n","\n","Keep learning!\n","\n","Andrew\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"0664cba1-437d-4073-9877-b34ff96335f1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0664cba1-437d-4073-9877-b34ff96335f1","executionInfo":{"status":"ok","timestamp":1722070227642,"user_tz":-540,"elapsed":4028,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"f63f693a-3968-4c4f-d8cf-ee568cc389d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["  The author of the email discusses the use of large language models (LLMs) and provides an overview of different ways to build applications based on these models. The key points extracted from the email are:\n","\n","1. Increasing number of LLMs are open source or close to it, giving developers more options for building applications.\n","2. Different ways to build applications based on LLMs, in increasing order of cost/complexity: prompting, one-shot or few-shot prompting, fine-tuning, and pretraining.\n","3. Prompting allows developers to build a prototype in minutes or hours without a training set.\n","4. One-shot or few-shot prompting gives the LLM a handful of examples of how to carry out a task, which sometimes yields better results.\n","5. Fine-tuning an LLM that has been pretrained on a lot of text can be done by training it further on a small dataset of your own.\n","6. Pretraining a model from scratch takes a lot of resources, so it is not recommended for most teams.\n","7. Specialized models like BloombergGPT and Med-PaLM 2 have been developed for specific domains.\n","8. The choice of development approach and model depends on the application, with smaller models requiring less processing power and larger models having more knowledge and better reasoning ability.\n","9. The author recommends starting with prompting and gradually moving to more complex techniques if needed.\n","10. The course \"Generative AI with Large Language Models\" created by AWS and DeepLearning.AI provides an in-depth understanding of these options.\n","\n","Regarding llama models, the author mentions that a member of the DeepLearning.AI team has been trying to fine-tune Llama-2-7B to sound like the author, but there is no mention of any specific insights or findings related to llama models.\n"]}],"source":["prompt = f\"\"\"\n","Summarize this email and extract some key points.\n","What did the author say about llama models?:\n","\n","email: {email}\n","\"\"\"\n","\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"9d32b6c3-c49d-4297-b58d-65bfceeda14e","metadata":{"id":"9d32b6c3-c49d-4297-b58d-65bfceeda14e"},"source":["### í”„ë¡¬í”„íŠ¸ì— ìƒˆë¡œìš´ ì •ë³´ ì œê³µ\n","- ëª¨ë¸ì˜ ì§€ì‹ì€ í›ˆë ¨ ì‹œì ì—ì„œ ì¢…ë£Œë˜ë¯€ë¡œ, ë” ìµœê·¼ì˜ ì‚¬ê±´ì— ëŒ€í•´ì„œëŠ” ì•Œì§€ ëª»í•©ë‹ˆë‹¤.\n","- ë¼ë§ˆ 2ëŠ” 2023ë…„ 7ì›” 18ì¼ì— ì—°êµ¬ ë° ìƒì—…ì  ì‚¬ìš©ì„ ìœ„í•´ ì¶œì‹œë˜ì—ˆìœ¼ë©°, í›ˆë ¨ì€ ê·¸ ì´ì „ì— ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n","- ëª¨ë¸ì—ê²Œ 2023ë…„ 7ì›” 20ì¼ì— ì‹œì‘ëœ FIFA ì—¬ì ì›”ë“œì»µê³¼ ê°™ì€ ì‚¬ê±´ì— ëŒ€í•´ ë¬¼ì–´ë³´ê³ , ëª¨ë¸ì´ ì–´ë–»ê²Œ ì‘ë‹µí•˜ëŠ”ì§€ í™•ì¸í•´ ë³´ì„¸ìš”."]},{"cell_type":"code","execution_count":null,"id":"f1e29e6b-706e-438c-8d56-39bbf23cb94c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1e29e6b-706e-438c-8d56-39bbf23cb94c","executionInfo":{"status":"ok","timestamp":1722070228740,"user_tz":-540,"elapsed":1110,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"3f3e61e7-326e-4368-ee3c-445de42b74fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["  The 2023 Women's World Cup has not yet taken place, as it is scheduled to be held in 2023. The tournament is organized by FIFA (FÃ©dÃ©ration Internationale de Football Association) and is held every four years. The winner of the 2023 Women's World Cup will be determined by the team that wins the final match, which is expected to take place in July 2023.\n"]}],"source":["prompt = \"\"\"\n","Who won the 2023 Women's World Cup?\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"5f959e08-e682-4ec0-8401-c4ed4d791485","metadata":{"id":"5f959e08-e682-4ec0-8401-c4ed4d791485"},"source":["- ë³´ì‹œë‹¤ì‹œí”¼, ëª¨ë¸ì€ í˜„ì¬ 2024ë…„ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  ëŒ€íšŒê°€ ì•„ì§ ì—´ë¦¬ì§€ ì•Šì•˜ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤!\n","- ë˜ í•˜ë‚˜ **ì£¼ì˜**í•  ì ì€, 2023ë…„ 7ì›” 18ì¼ì´ ëª¨ë¸ì´ ê³µê°œëœ ë‚ ì§œì´ë©°, ê·¸ ì´ì „ì— í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆê¸° ë•Œë¬¸ì— ê·¸ ì‹œì ê¹Œì§€ì˜ ì •ë³´ë§Œ ê°€ì§€ê³  ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì‘ë‹µì—ì„œëŠ” \"ê²°ìŠ¹ì „ì€ 2023ë…„ 7ì›”ì— ì˜ˆì •ë˜ì–´ ìˆë‹¤\"ê³  í•˜ì§€ë§Œ, ê²°ìŠ¹ì „ì€ 2023ë…„ 8ì›” 20ì¼ì— ì—´ë ¸ìŠµë‹ˆë‹¤."]},{"cell_type":"markdown","id":"30874cc3-73d7-412a-9dc5-1baa6aabf1b7","metadata":{"id":"30874cc3-73d7-412a-9dc5-1baa6aabf1b7"},"source":["- ëª¨ë¸ì—ê²Œ ìµœê·¼ ì‚¬ê±´ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 2023ë…„ ì—¬ì ì›”ë“œì»µì— ê´€í•œ ìœ„í‚¤í”¼ë””ì•„ í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"1cbe1b18-be2a-4f77-9911-c243e571226c","metadata":{"id":"1cbe1b18-be2a-4f77-9911-c243e571226c"},"outputs":[],"source":["context = \"\"\"\n","The 2023 FIFA Women's World Cup (MÄori: Ipu Wahine o te Ao FIFA i 2023)[1] was the ninth edition of the FIFA Women's World Cup, the quadrennial international women's football championship contested by women's national teams and organised by FIFA. The tournament, which took place from 20 July to 20 August 2023, was jointly hosted by Australia and New Zealand.[2][3][4] It was the first FIFA Women's World Cup with more than one host nation, as well as the first World Cup to be held across multiple confederations, as Australia is in the Asian confederation, while New Zealand is in the Oceanian confederation. It was also the first Women's World Cup to be held in the Southern Hemisphere.[5]\n","This tournament was the first to feature an expanded format of 32 teams from the previous 24, replicating the format used for the men's World Cup from 1998 to 2022.[2] The opening match was won by co-host New Zealand, beating Norway at Eden Park in Auckland on 20 July 2023 and achieving their first Women's World Cup victory.[6]\n","Spain were crowned champions after defeating reigning European champions England 1â€“0 in the final. It was the first time a European nation had won the Women's World Cup since 2007 and Spain's first title, although their victory was marred by the Rubiales affair.[7][8][9] Spain became the second nation to win both the women's and men's World Cup since Germany in the 2003 edition.[10] In addition, they became the first nation to concurrently hold the FIFA women's U-17, U-20, and senior World Cups.[11] Sweden would claim their fourth bronze medal at the Women's World Cup while co-host Australia achieved their best placing yet, finishing fourth.[12] Japanese player Hinata Miyazawa won the Golden Boot scoring five goals throughout the tournament. Spanish player Aitana BonmatÃ­ was voted the tournament's best player, winning the Golden Ball, whilst BonmatÃ­'s teammate Salma Paralluelo was awarded the Young Player Award. England goalkeeper Mary Earps won the Golden Glove, awarded to the best-performing goalkeeper of the tournament.\n","Of the eight teams making their first appearance, Morocco were the only one to advance to the round of 16 (where they lost to France; coincidentally, the result of this fixture was similar to the men's World Cup in Qatar, where France defeated Morocco in the semi-final). The United States were the two-time defending champions,[13] but were eliminated in the round of 16 by Sweden, the first time the team had not made the semi-finals at the tournament, and the first time the defending champions failed to progress to the quarter-finals.[14]\n","Australia's team, nicknamed the Matildas, performed better than expected, and the event saw many Australians unite to support them.[15][16][17] The Matildas, who beat France to make the semi-finals for the first time, saw record numbers of fans watching their games, their 3â€“1 loss to England becoming the most watched television broadcast in Australian history, with an average viewership of 7.13 million and a peak viewership of 11.15 million viewers.[18]\n","It was the most attended edition of the competition ever held.\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"c8b9d517-23f8-4468-9fc7-e47322d5b2fa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8b9d517-23f8-4468-9fc7-e47322d5b2fa","executionInfo":{"status":"ok","timestamp":1722070230397,"user_tz":-540,"elapsed":1662,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"2987eeb1-221e-4367-ef35-31b1730db243"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Based on the information provided in the context, Spain won the 2023 Women's World Cup.\n"]}],"source":["prompt = f\"\"\"\n","Given the following context, who won the 2023 Women's World cup?\n","context: {context}\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"1fdadbc9-e7ae-4281-8dc7-3f3feaa62def","metadata":{"id":"1fdadbc9-e7ae-4281-8dc7-3f3feaa62def"},"source":["### ì§ì ‘ í•´ë³´ì„¸ìš”!\n","\n","ìì‹ ë§Œì˜ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”! ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ê³  ìì‹ ì˜ ë¬¸ë§¥ì„ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì˜ ì‘ë‹µì„ í™•ì¸í•´ ë³´ì„¸ìš”:\n"]},{"cell_type":"code","execution_count":null,"id":"71662250-4f89-4816-8752-96bb6749296a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71662250-4f89-4816-8752-96bb6749296a","executionInfo":{"status":"ok","timestamp":1722070232544,"user_tz":-540,"elapsed":2153,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"ca7f883f-6bf3-47cc-b8eb-3911acbf46fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Prompt:\n","[INST]\n","Given the following context,\n","<your query here>\n","\n","context: \n","<paste context in here>\n","\n","[/INST]\n","\n","model: togethercomputer/llama-2-7b-chat\n","  Hello! I'm here to help you with any questions or problems you might have. Could you please provide me with more information or context about what you need help with?\n"]}],"source":["context = \"\"\"\n","<paste context in here>\n","\"\"\"\n","query = \"<your query here>\"\n","\n","prompt = f\"\"\"\n","Given the following context,\n","{query}\n","\n","context: {context}\n","\"\"\"\n","response = llama(prompt,\n","                 verbose=True)\n","print(response)"]},{"cell_type":"markdown","id":"51371f2d-9204-41b1-930c-2bd99888c5ab","metadata":{"id":"51371f2d-9204-41b1-930c-2bd99888c5ab"},"source":["### ì—°ì‡„ì  ì‚¬ê³  í”„ë¡¬í”„íŠ¸\n","- ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ë¬¸ì œë¥¼ ë” ì‘ì€ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ í•´ê²°í•˜ë„ë¡ ìš”ì²­í•  ë•Œ ë” ë‚˜ì€ ì¶”ë¡ ê³¼ ë…¼ë¦¬ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ **ì—°ì‡„ì  ì‚¬ê³ ** í”„ë¡¬í”„íŠ¸ë¼ê³  í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"4883c94b-33ae-450c-a587-abb781b996ee","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4883c94b-33ae-450c-a587-abb781b996ee","executionInfo":{"status":"ok","timestamp":1722070233790,"user_tz":-540,"elapsed":1253,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"06a7e0db-ce88-44e6-c295-2b4c7a0c08c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Yes, all 15 people can get to the restaurant by car or motorcycle.\n","\n","Here's how:\n","\n","* Two people with cars can fit 5 people each, so they can take 10 people in total.\n","* Two people with motorcycles can fit 2 people each, so they can take 4 people in total.\n","\n","That means there are 10 people who can go by car and 4 people who can go by motorcycle, for a total of 14 people who can get to the restaurant.\n","\n","The remaining 1 person can either walk or find another mode of transportation.\n"]}],"source":["prompt = \"\"\"\n","15 of us want to go to a restaurant.\n","Two of them have cars\n","Each car can seat 5 people.\n","Two of us have motorcycles.\n","Each motorcycle can fit 2 people.\n","\n","Can we all get to the restaurant by car or motorcycle?\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"d3214335-2a49-4e52-b5c1-46b2674826ca","metadata":{"id":"d3214335-2a49-4e52-b5c1-46b2674826ca"},"source":["- ëª¨ë¸ì—ê²Œ ì œê³µí•œ ìˆ˜í•™ ë¬¸ì œë¥¼ \"ë‹¨ê³„ë³„ë¡œ ìƒê°í•´ ë³´ì„¸ìš”\"ë¼ê³  í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"2d049009-4b88-4dd3-9fb6-f81870a86425","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2d049009-4b88-4dd3-9fb6-f81870a86425","executionInfo":{"status":"ok","timestamp":1722070236252,"user_tz":-540,"elapsed":2467,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"3fa8d00e-d618-4e50-a286-851e4cdc9b9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Sure, let's break it down step by step to see if we can get everyone to the restaurant:\n","\n","1. Number of people who want to go to the restaurant: 15\n","2. Number of people who have cars: 2\n","3. Number of people who can fit in each car: 5\n","4. Number of motorcycles available: 2\n","5. Number of people who can fit in each motorcycle: 2\n","\n","Now, let's see if we can accommodate everyone:\n","\n","1. Car 1: 2 people who want to go to the restaurant (driver and passenger)\n","2. Car 2: 5 people who want to go to the restaurant (driver and 4 passengers)\n","3. Motorcycle 1: 2 people who want to go to the restaurant (driver and passenger)\n","4. Motorcycle 2: 2 people who want to go to the restaurant (driver and passenger)\n","\n","Total number of people who can get to the restaurant: 12 (6 from Car 1, 5 from Car 2, and 1 from Motorcycle 1)\n","\n","Unfortunately, we have 3 more people who want to go to the restaurant than we have available transportation. So, no, we cannot all get to the restaurant by car or motorcycle.\n"]}],"source":["prompt = \"\"\"\n","15 of us want to go to a restaurant.\n","Two of them have cars\n","Each car can seat 5 people.\n","Two of us have motorcycles.\n","Each motorcycle can fit 2 people.\n","\n","Can we all get to the restaurant by car or motorcycle?\n","\n","Think step by step.\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"1761a4f0-1806-4c9d-b2db-36a213b588c1","metadata":{"id":"1761a4f0-1806-4c9d-b2db-36a213b588c1"},"source":["- ì¶”ê°€ì ì¸ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ê³¼ í•¨ê»˜ ëª¨ë¸ì—ê²Œ ì œê³µí•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"id":"999a4468-5b1a-4a80-a3fb-b2add7912f99","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"999a4468-5b1a-4a80-a3fb-b2add7912f99","executionInfo":{"status":"ok","timestamp":1722070239282,"user_tz":-540,"elapsed":3041,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"8d13b2d8-aa96-4c0c-c0bd-a2c8aca53442"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Of course! Let's break down the problem step by step to determine if all 15 people can get to the restaurant by car or motorcycle:\n","\n","Step 1: Identify the number of people who can be accommodated by each car:\n","\n","* Two cars are available, and each car can seat 5 people.\n","* Therefore, a total of 10 people can be accommodated by the two cars.\n","\n","Step 2: Identify the number of people who can be accommodated by each motorcycle:\n","\n","* Two motorcycles are available, and each motorcycle can fit 2 people.\n","* Therefore, a total of 4 people can be accommodated by the two motorcycles.\n","\n","Step 3: Determine the total number of people who can be accommodated for the trip:\n","\n","* Add the number of people who can be accommodated by the cars (10) and the number of people who can be accommodated by the motorcycles (4):\n","\n","10 + 4 = 14\n","\n","Step 4: Check if the total number of people who can be accommodated is equal to the number of people who want to go to the restaurant:\n","\n","* 14 is less than 15 (the number of people who want to go to the restaurant)\n","\n","Therefore, it is not possible to accommodate all 15 people by car or motorcycle.\n","\n","Answer: No, it is not possible to take all 15 people to the restaurant by car or motorcycle.\n"]}],"source":["prompt = \"\"\"\n","15 of us want to go to a restaurant.\n","Two of them have cars\n","Each car can seat 5 people.\n","Two of us have motorcycles.\n","Each motorcycle can fit 2 people.\n","\n","Can we all get to the restaurant by car or motorcycle?\n","\n","Think step by step.\n","Explain each intermediate step.\n","Only when you are done with all your steps,\n","provide the answer based on your intermediate steps.\n","\"\"\"\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"b7ebad47-3202-45a6-97f3-3f693e43afeb","metadata":{"id":"b7ebad47-3202-45a6-97f3-3f693e43afeb"},"source":["- ì¸ìŠ¤íŠ¸ëŸ­ì…˜ì˜ ìˆœì„œê°€ ì¤‘ìš”í•©ë‹ˆë‹¤!\n","- ëª¨ë¸ì—ê²Œ \"ë¨¼ì € ë‹µë³€í•˜ê³ \" \"ë‚˜ì¤‘ì— ì„¤ëª…í•´ì¤˜\"ë¼ê³  ìš”ì²­í•˜ì—¬ ì¶œë ¥ ê²°ê³¼ê°€ ì–´ë–»ê²Œ ë‹¬ë¼ì§€ëŠ”ì§€ í™•ì¸í•´ ë³´ì„¸ìš”."]},{"cell_type":"code","execution_count":null,"id":"5756ee56-eaa7-43ab-8531-4f575014b26a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5756ee56-eaa7-43ab-8531-4f575014b26a","executionInfo":{"status":"ok","timestamp":1722070240490,"user_tz":-540,"elapsed":1220,"user":{"displayName":"ì •ìœ ì„","userId":"07427363317372764481"}},"outputId":"7be6a9bc-e64b-40c8-88d4-93290e5f173b"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Yes, all 15 people can get to the restaurant by car or motorcycle. Here's how:\n","\n","Step 1: Two people with cars can fit 10 people (5 people per car x 2 cars).\n","Step 2: Two people with motorcycles can fit 4 people (2 people per motorcycle x 2 motorcycles).\n","Step 3: Combine the people who can fit in cars and those who can fit in motorcycles: 10 + 4 = 14 people can get to the restaurant.\n","\n","Therefore, the answer is yes, all 15 people can get to the restaurant by car or motorcycle.\n"]}],"source":["prompt = \"\"\"\n","15 of us want to go to a restaurant.\n","Two of them have cars\n","Each car can seat 5 people.\n","Two of us have motorcycles.\n","Each motorcycle can fit 2 people.\n","\n","Can we all get to the restaurant by car or motorcycle?\n","Think step by step.\n","Provide the answer as a single yes/no answer first.\n","Then explain each intermediate step.\n","\"\"\"\n","\n","response = llama(prompt)\n","print(response)"]},{"cell_type":"markdown","id":"5166a63a-ad56-4ee9-92b8-b198ed9b172b","metadata":{"id":"5166a63a-ad56-4ee9-92b8-b198ed9b172b"},"source":["- ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ë‹µë³€ì„ í•œ ë²ˆì— í•˜ë‚˜ì˜ í† í°ì”© ì˜ˆì¸¡í•˜ë¯€ë¡œ, ë‹¨ê³„ë³„ë¡œ ìƒê°í•˜ë„ë¡ ìš”ì²­í•œ í›„ì— ë‹µë³€ì„ ì œê³µë°›ëŠ” ê²ƒì´ ìµœì„ ì˜ ë°©ë²•ì…ë‹ˆë‹¤."]},{"cell_type":"code","source":[],"metadata":{"id":"keYhXm7oQNQa"},"id":"keYhXm7oQNQa","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}