{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598c852c",
   "metadata": {},
   "source": [
    "# ReAct Prompting with Langchain Agents with Claude \n",
    "Reused from the [langchain handbook](https://github.com/pinecone-io/examples/tree/master/generation/langchain/handbook) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "uZR3iGJJtdDE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZR3iGJJtdDE",
    "outputId": "196a7da0-6099-4721-d8bc-9247fb852620",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -qU langchain sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wPdWz1IdxyBR",
   "metadata": {
    "id": "wPdWz1IdxyBR"
   },
   "source": [
    "To run this notebook, we will need to use an OpenAI LLM. Here we will setup the LLM we will use for the whole notebook, just input your openai api key when prompted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73bfcbb6",
   "metadata": {
    "id": "73bfcbb6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "boto3_bedrock = None #boto3.client('bedrock')\n",
    "\n",
    "\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "titan_llm = Bedrock(model_id=\"amazon.titan-tg1-large\", client=boto3_bedrock)\n",
    "antropic_llm = Bedrock(model_id=\"anthropic.claude-v1\", client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f31b4",
   "metadata": {
    "id": "6e1f31b4"
   },
   "source": [
    "## What is an agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b919c3a",
   "metadata": {
    "id": "5b919c3a"
   },
   "source": [
    "**Definition**: The key behind agents is giving LLM's the possibility of using tools in their workflow. This is where langchain departs from the popular chatgpt implementation and we can start to get a glimpse of what it offers us as builders. Until now, we covered several building blocks in isolation. Let's see them come to life.\n",
    "\n",
    "The official definition of agents is the following:\n",
    "\n",
    "\n",
    "> Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c13e9",
   "metadata": {
    "id": "6c9c13e9"
   },
   "source": [
    "In this edition we will cover what we may call 'generic' agents which really able to perform many meta tasks. There are other more specific agents that are tuned for different tasks (called 'agent-toolkits'), but we will cover those in a future edition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93dc920",
   "metadata": {
    "id": "a93dc920"
   },
   "source": [
    "## Create database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601f903",
   "metadata": {
    "id": "b601f903"
   },
   "source": [
    "We will use the agents to interact with a small sample database of stocks. We will not dive into the details because this is just a dummy tool we will build for illustrative purposes. Let's create it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61b1f17c",
   "metadata": {
    "id": "61b1f17c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData\n",
    "\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cc1d80e",
   "metadata": {
    "id": "3cc1d80e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, Table, Date, Float\n",
    "\n",
    "hotels = Table(\n",
    "    \"hotels\",\n",
    "    metadata_obj,\n",
    "\tColumn(\"hotel_id\", Integer, primary_key=True),\n",
    "\tColumn(\"city\", String(15), nullable=False),\n",
    "\tColumn(\"distance\", Float, nullable=True),\n",
    "\tColumn(\"stars\", Float, nullable=True),\n",
    "\tColumn(\"rating\", Float, nullable=True),\n",
    "\tColumn(\"country\", String(15), nullable=True),\n",
    "\tColumn(\"city_actual\", String(15), nullable=True),\n",
    "\tColumn(\"rating_reviewcount\", Integer, nullable=True),\n",
    "\tColumn(\"center1label\", String(20), nullable=True),\n",
    "\tColumn(\"center2label\", String(20), nullable=True),\n",
    "\tColumn(\"neighbourhood\", String(15), nullable=True),\n",
    "\tColumn(\"ratingta\", Float, nullable=True),\n",
    "\tColumn(\"ratingta_count\", Integer, nullable=True),\n",
    "\tColumn(\"distance_alter\", Float, nullable=True),\n",
    "\tColumn(\"accommodation_type\", String(15), nullable=True),\n",
    "    Column(\"timestamp\", Date, nullable=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9a9571a",
   "metadata": {
    "id": "c9a9571a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6cea3f79-245c-4772-9ece-f3ca7fd6494d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>city</th>\n",
       "      <th>distance</th>\n",
       "      <th>stars</th>\n",
       "      <th>rating</th>\n",
       "      <th>country</th>\n",
       "      <th>city_actual</th>\n",
       "      <th>rating_reviewcount</th>\n",
       "      <th>center1label</th>\n",
       "      <th>center2label</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>ratingta</th>\n",
       "      <th>ratingta_count</th>\n",
       "      <th>distance_alter</th>\n",
       "      <th>accommodation_type</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>City centre</td>\n",
       "      <td>Montelbaanstoren</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>2023-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>372.0</td>\n",
       "      <td>City centre</td>\n",
       "      <td>Montelbaanstoren</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>4.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Hostel</td>\n",
       "      <td>2023-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>165.0</td>\n",
       "      <td>City centre</td>\n",
       "      <td>Montelbaanstoren</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>4.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>2023-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>298.0</td>\n",
       "      <td>City centre</td>\n",
       "      <td>Montelbaanstoren</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>2023-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>4.0</td>\n",
       "      <td>City centre</td>\n",
       "      <td>Montelbaanstoren</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>4.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>2023-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22897</th>\n",
       "      <td>22898</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>36.0</td>\n",
       "      <td>City centre</td>\n",
       "      <td>Zagreb City Museum</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>3.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Hostel</td>\n",
       "      <td>2023-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22898</th>\n",
       "      <td>22899</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City centre</td>\n",
       "      <td>Zagreb City Museum</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>2023-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22899</th>\n",
       "      <td>22900</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>9.0</td>\n",
       "      <td>City centre</td>\n",
       "      <td>Zagreb City Museum</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>4.5</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>2023-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22900</th>\n",
       "      <td>22901</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>24.0</td>\n",
       "      <td>City centre</td>\n",
       "      <td>Zagreb City Museum</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>2023-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22901</th>\n",
       "      <td>22902</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>48.0</td>\n",
       "      <td>City centre</td>\n",
       "      <td>Zagreb City Museum</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>4.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>2023-06-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22902 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hotel_id       city  distance  stars  rating      country city_actual   \n",
       "0             1  Amsterdam       3.1    4.0     4.3  Netherlands   Amsterdam  \\\n",
       "1             2  Amsterdam       0.9    2.0     4.1  Netherlands   Amsterdam   \n",
       "2             3  Amsterdam       1.5    4.0     4.1  Netherlands   Amsterdam   \n",
       "3             4  Amsterdam       1.9    3.0     3.5  Netherlands   Amsterdam   \n",
       "4             5  Amsterdam       1.8    3.5     4.0  Netherlands   Amsterdam   \n",
       "...         ...        ...       ...    ...     ...          ...         ...   \n",
       "22897     22898     Zagreb       0.2    2.0     3.7      Croatia      Zagreb   \n",
       "22898     22899     Zagreb       4.0    3.0     NaN      Croatia      Zagreb   \n",
       "22899     22900     Zagreb       3.9    4.0     4.4      Croatia      Zagreb   \n",
       "22900     22901     Zagreb       3.3    3.0     3.5      Croatia      Zagreb   \n",
       "22901     22902     Zagreb       1.1    4.0     4.5      Croatia      Zagreb   \n",
       "\n",
       "       rating_reviewcount center1label        center2label neighbourhood   \n",
       "0                  1030.0  City centre    Montelbaanstoren     Amsterdam  \\\n",
       "1                   372.0  City centre    Montelbaanstoren     Amsterdam   \n",
       "2                   165.0  City centre    Montelbaanstoren     Amsterdam   \n",
       "3                   298.0  City centre    Montelbaanstoren     Amsterdam   \n",
       "4                     4.0  City centre    Montelbaanstoren     Amsterdam   \n",
       "...                   ...          ...                 ...           ...   \n",
       "22897                36.0  City centre  Zagreb City Museum        Zagreb   \n",
       "22898                 NaN  City centre  Zagreb City Museum        Zagreb   \n",
       "22899                 9.0  City centre  Zagreb City Museum        Zagreb   \n",
       "22900                24.0  City centre  Zagreb City Museum        Zagreb   \n",
       "22901                48.0  City centre  Zagreb City Museum        Zagreb   \n",
       "\n",
       "       ratingta  ratingta_count  distance_alter accommodation_type  timestamp  \n",
       "0           4.0          1115.0             3.6              Hotel 2023-06-28  \n",
       "1           4.0           999.0             0.8             Hostel 2023-06-28  \n",
       "2           4.0           674.0             1.4              Hotel 2023-06-28  \n",
       "3           3.5          1882.0             2.1              Hotel 2023-06-28  \n",
       "4           4.5            66.0             2.0              Hotel 2023-06-28  \n",
       "...         ...             ...             ...                ...        ...  \n",
       "22897       3.5            42.0             0.4             Hostel 2023-06-28  \n",
       "22898       NaN             NaN             4.0          Apartment 2023-06-28  \n",
       "22899       4.5           225.0             3.9              Hotel 2023-06-28  \n",
       "22900       3.0            14.0             3.3              Hotel 2023-06-28  \n",
       "22901       4.5            86.0             0.6              Hotel 2023-06-28  \n",
       "\n",
       "[22902 rows x 16 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "hotel_data = pd.read_csv(\"hotels-europe_features.csv\")\n",
    "hotel_data[\"timestamp\"] = datetime(2023, 6, 28)\n",
    "hotel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81c3081f",
   "metadata": {
    "id": "81c3081f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "observations = hotel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f3d8b29-c8e9-4aa0-8f1b-179036dba7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 'Amsterdam', 3.1, 4.0, 4.3, 'Netherlands', 'Amsterdam', 1030.0, 'City centre', 'Montelbaanstoren', 'Amsterdam', 4.0, 1115.0, 3.6, 'Hotel', Timestamp('2023-06-28 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "observations = hotel_data.values.tolist()\n",
    "print(observations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85fd20fa",
   "metadata": {
    "id": "85fd20fa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "def insert_obs(obs):\n",
    "    stmt = insert(hotels).values(\n",
    "    hotel_id=obs[0], \n",
    "    city=obs[1], \n",
    "    distance=obs[2],\n",
    "    stars=obs[3],\n",
    "    rating=obs[4],\n",
    "    country=obs[5],\n",
    "    city_actual=obs[6],\n",
    "    rating_reviewcount=obs[7],\n",
    "    center1label=obs[8],\n",
    "    center2label=obs[9],\n",
    "    neighbourhood=obs[10],\n",
    "    ratingta=obs[11],\n",
    "    ratingta_count=obs[12],\n",
    "    distance_alter=obs[13],\n",
    "    accommodation_type=obs[14],\n",
    "    timestamp=obs[15]\n",
    "    )\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6766f1f7",
   "metadata": {
    "id": "6766f1f7",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for obs in observations:\n",
    "    insert_obs(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9721648e",
   "metadata": {
    "id": "9721648e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain/chains/sql_database/base.py:63: UserWarning: Directly instantiating an SQLDatabaseChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.chains import SQLDatabaseChain\n",
    "\n",
    "db = SQLDatabase(engine)\n",
    "sql_chain = SQLDatabaseChain(llm=antropic_llm, database=db, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2af8c8",
   "metadata": {
    "id": "fe2af8c8"
   },
   "source": [
    "Finally, we will create a tool with this chain. To create a custom tool we need only three inputs:\n",
    "* name: the name of the tool (sent to the llm as context)\n",
    "* func: the function that will be applied on the LLM's request\n",
    "* description: the description of the tool, what it should be used for (sent to the llm as context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ef519b1",
   "metadata": {
    "id": "7ef519b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "sql_tool = Tool(\n",
    "    name='Hotels DB',\n",
    "    func=sql_chain.run,\n",
    "    description=\"Useful for when you need to answer questions about hotels \" \\\n",
    "                \"and their ratings.\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325f758",
   "metadata": {
    "id": "6325f758"
   },
   "source": [
    "## Agent types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d732b7a",
   "metadata": {
    "id": "4d732b7a"
   },
   "source": [
    "In this section we will review several agents and see how they 'think' and what they can do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee98631",
   "metadata": {
    "id": "8ee98631"
   },
   "source": [
    "Using one of langchain's pre-built agents involves three variables: \n",
    "* defining the tools\n",
    "* defining the llm\n",
    "* defining the agent type\n",
    "\n",
    "This is all really easy to do in langchain, as we will see in the following example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf306a",
   "metadata": {
    "id": "1eaf306a"
   },
   "source": [
    "### Agent type #1: Zero Shot React"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13951c49",
   "metadata": {
    "id": "13951c49"
   },
   "source": [
    "We will be using only a few tools but you can combine the ones you prefer. Remember that tools are only utility chains under the hood which are chains that serve one specific purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabcff15",
   "metadata": {
    "id": "aabcff15"
   },
   "source": [
    "We first need to initialize the tools we'll be using in this example. Here we will want our agent to do math so we will use 'llm-math', the tool we have for solving math problems. This is one of the several tools we can load with the `load_tools` utility - you can check out more by checking out the [docs](https://langchain.readthedocs.io/en/latest/modules/agents/tools.html?highlight=tools#tools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95c945b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = antropic_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c6bd290",
   "metadata": {
    "id": "0c6bd290",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"llm-math\"], \n",
    "    llm=llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fabc474d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools.append(sql_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2378356",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, handle_tool_error=False, func=<bound method Chain.run of LLMMathChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), llm=Bedrock(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<botocore.client.Bedrock object at 0x7f75d784c5b0>, region_name=None, credentials_profile_name=None, model_id='anthropic.claude-v1', model_kwargs=None), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}), llm=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), input_key='question', output_key='answer')>, coroutine=<bound method Chain.arun of LLMMathChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), llm=Bedrock(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<botocore.client.Bedrock object at 0x7f75d784c5b0>, region_name=None, credentials_profile_name=None, model_id='anthropic.claude-v1', model_kwargs=None), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}), llm=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), input_key='question', output_key='answer')>),\n",
       " Tool(name='Hotels DB', description='Useful for when you need to answer questions about hotels and their ratings.', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, handle_tool_error=False, func=<bound method Chain.run of SQLDatabaseChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, prompt=PromptTemplate(input_variables=['input', 'table_info', 'top_k'], output_parser=None, partial_variables={}, template='You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date(\\'now\\') function to get the current date, if the question involves \"today\".\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n{table_info}\\n\\nQuestion: {input}', template_format='f-string', validate_template=True), llm=Bedrock(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<botocore.client.Bedrock object at 0x7f75d784c5b0>, region_name=None, credentials_profile_name=None, model_id='anthropic.claude-v1', model_kwargs=None), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}), llm=Bedrock(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<botocore.client.Bedrock object at 0x7f75d784c5b0>, region_name=None, credentials_profile_name=None, model_id='anthropic.claude-v1', model_kwargs=None), database=<langchain.sql_database.SQLDatabase object at 0x7f75d78585e0>, prompt=None, top_k=5, input_key='query', output_key='result', return_intermediate_steps=False, return_direct=False, use_query_checker=False, query_checker_prompt=None)>, coroutine=None)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf01b924",
   "metadata": {
    "id": "bf01b924"
   },
   "source": [
    "To be able to search across our stock prices, we will also use the custom tool we built beforehand with the sql data ('Stock DB'). We will append this tool to our list of tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9bf6b5",
   "metadata": {
    "id": "bc9bf6b5"
   },
   "source": [
    "As the name suggests, we will use this agent to perform 'zero shot' tasks on the input. That means that we will not have several, interdependent interactions but only one. In other words, this agent will have no memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e51d51",
   "metadata": {
    "id": "a6e51d51"
   },
   "source": [
    "Now we are ready to initialize the agent! We will use `verbose` in `True` so we can see what is our agent's 'thinking' process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d95ce",
   "metadata": {
    "id": "ca2d95ce"
   },
   "source": [
    "**Important Note:** *When interacting with agents it is really important to set the `max_iterations` parameters because agents can get stuck in infinite loops that consume plenty of tokens. The default value is 15 to allow for many tools and complex reasoning but for most applications you should keep it much lower.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e4eb28c",
   "metadata": {
    "id": "5e4eb28c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\", \n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c239c0",
   "metadata": {
    "id": "28c239c0"
   },
   "source": [
    "Let's see our newly created agent in action! We will ask it a question that involves a math operation over the stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c63c2f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hotels_query=\"\"\"Search for 3 hotels in Madrid with 4 stars and highest rating\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd5ef465",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m To find hotels with high ratings, I should use the Hotels DB tool\n",
      "Action: Hotels DB\n",
      "Action Input: Location: Madrid; Stars: 4; Sort by: Rating (highest to lowest)\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Location: Madrid; Stars: 4; Sort by: Rating (highest to lowest)\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT * FROM hotels \n",
      "WHERE city = \"Madrid\" AND stars = 4 \n",
      "ORDER BY rating DESC\n",
      "LIMIT 5\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(9103, 'Madrid', 0.2, 4.0, 5.0, 'Spain', 'Madrid', 1, 'City centre', 'Casa Matesanz', 'Centro', 3.5, 25, 0.4, 'Apartment', '2023-06-28'), (8889, 'Madrid', 19.0, 4.0, 4.8, 'Spain', 'Alcala de Henares', 41, 'City centre', 'Casa Matesanz', 'Alcala de Henares', 4.5, 1062, 18.0, 'Hotel', '2023-06-28'), (9064, 'Madrid', 0.6, 4.0, 4.8, 'Spain', 'Madrid', 11, 'City centre', 'Casa Matesanz', 'Centro', None, None, 0.4, 'Apartment', '2023-06-28'), (9167, 'Madrid', 0.6, 4.0, 4.8, 'Spain', 'Madrid', 464, 'City centre', 'Casa Matesanz', 'Chueca', 5.0, 1985, 0.4, 'Hotel', '2023-06-28'), (9197, 'Madrid', 3.4, 4.0, 4.8, 'Spain', 'Madrid', 177, 'City centre', 'Casa Matesanz', 'Ciudad Lineal', 5.0, 511, 3.3, 'Hotel', '2023-06-28')]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThe 4-star hotels in Madrid with the highest rating are:\n",
      "9103 - Rating: 5.0\n",
      "8889 - Rating: 4.8  - In Alcala de Henares, 19 km from city centre\n",
      "9064 - Rating\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe 4-star hotels in Madrid with the highest rating are:\n",
      "9103 - Rating: 5.0\n",
      "8889 - Rating: 4.8  - In Alcala de Henares, 19 km from city centre\n",
      "9064 - Rating\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = zero_shot_agent(hotels_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3e50e81b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e50e81b",
    "outputId": "c1fb3eb0-01b5-46e1-f17b-d1df2bff2df3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "Hotels DB: Useful for when you need to answer questions about hotels and their ratings.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Calculator, Hotels DB]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(zero_shot_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b47ed",
   "metadata": {
    "id": "5b2b47ed"
   },
   "source": [
    "The question we must ask ourselves here is: how are agents different than chains?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73aaf07",
   "metadata": {
    "id": "f73aaf07"
   },
   "source": [
    "If we look at the agent's logic and the prompt we have just printed we will see some clear differences. First, we have the tools which are included in the prompt. Second we have a thought process which was before was immediate in chains but now involves a 'thought', 'action', 'action input', 'observation' sequence. What is this all about?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a698f78",
   "metadata": {
    "id": "3a698f78"
   },
   "source": [
    "Suffice it to say for now that **the LLM now has the ability to 'reason' on how to best use tools** to solve our query and can combine them in intelligent ways with just a brief description of each of them. If you want to learn more about this paradigm (MRKL) in detail, please refer to [this](https://arxiv.org/pdf/2205.00445.pdf) paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff9e65d",
   "metadata": {
    "id": "aff9e65d"
   },
   "source": [
    "Finally, let's pay attention to the 'agent_scratchpad'. What is that? Well, that is where we will be appending every thought or action that the agent has already performed. In this way, at each point in time, the agent will know what it has found out and will be able to continue its thought process. In other words, after using a tool it adds its thoughts and observations to the scratchpad and picks up from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d70642",
   "metadata": {
    "id": "04d70642"
   },
   "source": [
    "### Agent type #2: Conversational React"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec589b1",
   "metadata": {
    "id": "1ec589b1"
   },
   "source": [
    "The zero shot agent is really interesting but, as we said before, it has no memory. What if we want an assistant that remembers things we have talked about and can also reason about them and use tools? For that we have the conversational react agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c26c50f",
   "metadata": {
    "id": "5c26c50f"
   },
   "source": [
    "We will use the same tools as we specified earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11ae1e8e",
   "metadata": {
    "id": "11ae1e8e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = load_tools(\n",
    "    [\"llm-math\"], \n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b6faff3",
   "metadata": {
    "id": "4b6faff3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools.append(sql_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45b903",
   "metadata": {
    "id": "be45b903"
   },
   "source": [
    "The memory type being used here is a simple buffer memory to allow us to remember previous steps in the reasoning chain. For more information on memory, please refer to the 3rd chapter of this series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0aff4edf",
   "metadata": {
    "id": "0aff4edf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6579cef0",
   "metadata": {
    "id": "6579cef0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversational_agent = initialize_agent(\n",
    "    agent='conversational-react-description', \n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=1,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cabbea50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cabbea50",
    "outputId": "6bdd0b13-134f-4dfd-9fb7-66c746e5a07a",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Hotels DB \n",
      "Action Input: Madrid, 4 stars\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Madrid, 4 stars\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mselect * from hotels where city= \"Madrid\" and stars >= 4 ORDER BY stars DESC LIMIT 5\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(8949, 'Madrid', 2.4, 5.0, 4.0, 'Spain', 'Madrid', 70, 'City centre', 'Casa Matesanz', 'Avenida America', 4.0, 2740, 2.3, 'Hotel', '2023-06-28'), (8957, 'Madrid', 6.6, 5.0, 4.3, 'Spain', 'Madrid', 454, 'City centre', 'Casa Matesanz', 'Barajas', 4.5, 3126, 6.5, 'Hotel', '2023-06-28'), (9001, 'Madrid', 0.3, 5.0, 4.5, 'Spain', 'Madrid', 293, 'City centre', 'Casa Matesanz', 'Barrio de las Letras', 4.5, 2003, 0.3, 'Hotel', '2023-06-28'), (9009, 'Madrid', 0.5, 5.0, 4.3, 'Spain', 'Madrid', 210, 'City centre', 'Casa Matesanz', 'Barrio de las Letras', 4.5, 1430, 0.6, 'Hotel', '2023-06-28'), (9012, 'Madrid', 0.4, 5.0, 4.5, 'Spain', 'Madrid', 283, 'City centre', 'Casa Matesanz', 'Barrio de las Letras', 4.5, 1811, 0.4, 'Hotel', '2023-06-28')]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mHere are 5 4-star or higher hotels in Madrid:\n",
      "[hotel_id=8949,stars=5.0,rating=4.0]\n",
      "[hotel_id=8957,stars=5.0,rating=\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mHere are 5 4-star or higher hotels in Madrid:\n",
      "[hotel_id=8949,stars=5.0,rating=4.0]\n",
      "[hotel_id=8957,stars=5.0,rating=\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = conversational_agent(\"Please provide me a hotel with 4 stars near Madrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd9847",
   "metadata": {
    "id": "bdcd9847"
   },
   "source": [
    "As we can see below, the prompt is similar but it includes a great prelude of instructions that make it an effective assistant as well + a spot for including the chat history from the memory component:"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
