{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximizing AI Potentials: Leveraging Foundational Models from Amazon Bedrock and Amazon OpenSearch Serverless as Vector Engine\n",
    "\n",
    "### Context\n",
    "Amazon Bedrock is a fully managed service that provides access to FMs from third-party providers and Amazon; available via an API. With Bedrock, you can choose from a variety of models to find the one that’s best suited for your use case. On one hand Amazon Bedrock provides an option to generate vectors as well as summarizezation of texts, then on other hands vector engine for Amazon OpenSearch Serverless complements it by providing a machinsm to store those vectors and run semantic search against those vectors. \n",
    "\n",
    "In this sample notebook you will explore some of the most common usage patterns we are seeing with our customers for Generative AI such as generating text and images, creating value for organizations by improving productivity. This is achieved by leveraging foundation models to help in composing emails, summarizing text, answering questions, building chatbots, and creating images.\n",
    "\n",
    "### Challenges\n",
    "- How to manage large document(s) that exceed the token limit\n",
    "- How to find the document(s) relevant to the question being asked\n",
    "\n",
    "### Proposal\n",
    "To the above challenges, this notebook proposes the following strategy\n",
    "#### Prepare documents\n",
    "![Embeddings](./images/Embeddings_lang.png)\n",
    "\n",
    "Before being able to answer the questions, the documents must be processed and a stored in a document store index\n",
    "- Load the documents\n",
    "- Process and split them into smaller chunks\n",
    "- Create a numerical vector representation of each chunk using Amazon Bedrock Titan Embeddings model\n",
    "- Create an index using the chunks and the corresponding embeddings and store into OpenSearch Serverless\n",
    "#### Ask question\n",
    "![Question](./images/Chatbot_lang.png)\n",
    "\n",
    "When the documents index is prepared, you are ready to ask the questions and relevant documents will be fetched based on the question being asked. Following steps will be executed.\n",
    "- Create an embedding of the input question\n",
    "- Compare the question embedding with the embeddings stored in OpenSearch Serverless\n",
    "- Fetch the (top N) relevant document chunks using vector engine\n",
    "- Add those chunks as part of the context in the prompt\n",
    "- Send the prompt to the model under Amazon Bedrock\n",
    "- Get the contextual answer based on the documents retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usecase\n",
    "#### Dataset\n",
    "To explain this architecture pattern we are using the documents from IRS. These documents explain topics such as:\n",
    "- Original Issue Discount (OID) Instruments\n",
    "- Reporting Cash Payments of Over $10,000 to IRS\n",
    "- Employer's Tax Guide\n",
    "\n",
    "The model will try to answer from the documents in easy language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "In order to follow the RAG approach this notebook is using the LangChain framework where it has integrations with different services and tools that allow efficient building of patterns such as RAG. We will be using the following tools:\n",
    "\n",
    "- **LLM (Large Language Model)**: Anthropic Claude V1 available through Amazon Bedrock\n",
    "- **Vector Store**: vector engine for Amazon OpenSearch Serverless\n",
    "  In this notebook we are using OpenSearch Serverless as a vector-store to store both the embeddings and the documents. \n",
    "- **Index**: VectorIndex - This model will be used to understand the document chunks and provide an answer in human friendly manner.\n",
    "- **Embeddings Model**: Amazon Titan Embeddings available through Amazon Bedrock\n",
    "\n",
    "  This model will be used to generate a numerical representation of the textual documents\n",
    "- **Document Loader**: PDF Loader available through LangChain\n",
    "\n",
    "  This is the loader that can load the documents from a source, in this example we are loading the vector embeddings generated from those file chunks to OpenSearch Serverless. \n",
    "\n",
    "  The index helps to compare the input embedding and the document embeddings to find relevant document\n",
    "- **Wrapper**: wraps index, vector store, embeddings model and the LLM to abstract away the logic from the user.\n",
    "\n",
    "### Setup\n",
    "To run this notebook you would need to install dependencies such as, [PyPDF](https://pypi.org/project/pypdf/)\n",
    "\n",
    "\n",
    "\n",
    "Then begin with instantiating the LLM and the Embeddings model. Here we are using Amazon Titan to demonstrate the use case.\n",
    "\n",
    "Note: It is possible to choose other models available with Bedrock. You can replace the `model_id` as follows to change the model.\n",
    "\n",
    "`llm = Bedrock(model_id=\"amazon.titan-tg1-large\")`\n",
    "\n",
    "Available models under Bedrock have the following IDs:\n",
    "- `amazon.titan-tg1-large`\n",
    "- `ai21.j2-grande-instruct`\n",
    "- `ai21.j2-jumbo-instruct`\n",
    "- `anthropic.claude-instant-v1`\n",
    "- `anthropic.claude-v1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⚠️⚠️⚠️ Execute the following cells before running this notebook ⚠️⚠️⚠️\n",
    "\n",
    "For a detailed description on what the following cells do refer to [Bedrock boto3 setup](../00_Intro/bedrock_boto3_setup.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !./download-dependencies.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import subprocess\n",
    "\n",
    "# botocore_whl_filename = glob.glob(\"../dependencies/botocore-*-py3-none-any.whl\")[0]\n",
    "# boto3_whl_filename = glob.glob(\"../dependencies/boto3-*-py3-none-any.whl\")[0]\n",
    "\n",
    "# subprocess.Popen(['pip', 'install', botocore_whl_filename, boto3_whl_filename, '--force-reinstall'], bufsize=1, universal_newlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m      WARNING: Cannot remove entries from nonexistent file /opt/conda/lib/python3.10/site-packages/easy-install.pth\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "botocore 1.31.14 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.0.4 which is incompatible.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.2 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.0 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.0 which is incompatible.\n",
      "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.3.0 which is incompatible.\n",
      "notebook 6.5.5 requires pyzmq<25,>=17, but you have pyzmq 25.1.0 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.25.2 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.2.1 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "scipy 1.9.1 requires numpy<1.25.0,>=1.18.5, but you have numpy 1.25.2 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.14.0 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.0a6 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.14.0 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires jupyter-client<8,>=7.3.4; python_version >= \"3\", but you have jupyter-client 8.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you run `download-dependencies.sh` from the root of the repository to download the dependencies before running this cell\n",
    "%pip install langchain==0.0.254 --force-reinstall --quiet\n",
    "%pip install pypdf==3.8.1 --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting requests_aws4auth\n",
      "  Downloading requests_aws4auth-1.2.3-py2.py3-none-any.whl (24 kB)\n",
      "Collecting opensearch-py\n",
      "  Obtaining dependency information for opensearch-py from https://files.pythonhosted.org/packages/23/a1/18afd74d63ad21978d506b59f6d1bfa028463cff20bdd7dd59ff62087738/opensearch_py-2.3.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading opensearch_py-2.3.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from requests_aws4auth) (2.31.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from requests_aws4auth) (1.16.0)\n",
      "Collecting urllib3<2,>=1.21.1 (from opensearch-py)\n",
      "  Obtaining dependency information for urllib3<2,>=1.21.1 from https://files.pythonhosted.org/packages/c5/05/c214b32d21c0b465506f95c4f28ccbcba15022e000b043b72b3df7728471/urllib3-1.26.16-py2.py3-none-any.whl.metadata\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m209.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from opensearch-py) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /opt/conda/lib/python3.10/site-packages (from opensearch-py) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->requests_aws4auth) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->requests_aws4auth) (3.4)\n",
      "Downloading opensearch_py-2.3.1-py2.py3-none-any.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.3/327.3 kB\u001b[0m \u001b[31m144.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m287.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, requests_aws4auth, opensearch-py\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.4\n",
      "    Uninstalling urllib3-2.0.4:\n",
      "      Successfully uninstalled urllib3-2.0.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed opensearch-py-2.3.1 requests_aws4auth-1.2.3 urllib3-1.26.16\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you run `download-dependencies.sh` from the root of the repository to download the dependencies before running this cell\n",
    "#%pip install ./dependencies/botocore-1.29.162-py3-none-any.whl ./dependencies/boto3-1.26.162-py3-none-any.whl ./dependencies/awscli-1.27.162-py3-none-any.whl --force-reinstall\n",
    "# %pip install langchain==0.0.245 --quiet\n",
    "# %pip install pypdf==3.8.1 faiss-cpu==1.7.4 --quiet\n",
    "%pip install requests_aws4auth opensearch-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Un comment the following lines to run from your local environment outside of the AWS account with Bedrock access\n",
    "\n",
    "# import os\n",
    "# os.environ['BEDROCK_ASSUME_ROLE'] = '<enter role>'\n",
    "# os.environ['AWS_PROFILE'] = '<aws-profile>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# module_path = \"..\"\n",
    "# sys.path.append(os.path.abspath(module_path))\n",
    "# from utils import bedrock, print_ww\n",
    "\n",
    "# os.environ['AWS_DEFAULT_REGION'] = 'us-west-2'\n",
    "# boto3_bedrock = bedrock.get_bedrock_client(os.environ.get('BEDROCK_ASSUME_ROLE', None))\n",
    "# print (f\"bedrock client {boto3_bedrock}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## set up opensearch\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import json\n",
    "\n",
    "# create open search collection public endpoint from public preview in us-east-2\n",
    "#host = 'jobm91bhqffl30fsl22a.us-east-2.aoss.amazonaws.com' # OpenSearch Serverless collection endpoint\n",
    "\n",
    "#https://vbepafgvf5rx9n314te6.us-west-2.aoss.amazonaws.com\n",
    "host = 'nas3j63bxdjwni0aty0k.us-west-2.aoss.amazonaws.com'\n",
    "\n",
    "region = 'us-west-2'\n",
    "\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service,\n",
    "session_token=credentials.token)\n",
    "\n",
    "# Create an OpenSearch client\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': 443}],\n",
    "    http_auth = awsauth,\n",
    "    timeout = 300,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup langchain\n",
    "\n",
    "We create an instance of the Bedrock classes for the LLM and the embedding models. In this example we are showing an example with \"titan\" model from Amazon, and \"claude\" model from Anthropic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "# from langchain.embeddings import BedrockEmbeddings\n",
    "# from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "# # - create the Anthropic Model\n",
    "# claude_llm = Bedrock(model_id=\"anthropic.claude-v1\", client=boto3_bedrock, model_kwargs={'max_tokens_to_sample':200})\n",
    "# titan_llm = Bedrock(model_id= \"amazon.titan-tg1-large\", client=boto3_bedrock)\n",
    "# bedrock_embeddings = BedrockEmbeddings(client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Preparation\n",
    "Let's first download some of the files to build our document store. For this example we will be using public IRS documents from [here](https://www.irs.gov/publications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./data\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "metadata = [\n",
    "    dict(year=2022, source=filenames[0]),\n",
    "    dict(year=2021, source=filenames[1]),\n",
    "    dict(year=2020, source=filenames[2]),\n",
    "    dict(year=2019, source=filenames[3])]\n",
    "\n",
    "data_root = \"./data/\"\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root + filenames[idx]\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of Amazon's culture, the CEO always includes a copy of the 1997 Letter to Shareholders with every new release. This will cause repetition, take longer to generate embeddings, and may skew your results. In the next section you will take the downloaded data, trim the 1997 letter (last 3 pages) and overwrite them as processed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "\n",
    "local_pdfs = glob.glob(data_root + '*.pdf')\n",
    "\n",
    "for local_pdf in local_pdfs:\n",
    "    pdf_reader = PdfReader(local_pdf)\n",
    "    pdf_writer = PdfWriter()\n",
    "    for pagenum in range(len(pdf_reader.pages)-3):\n",
    "        page = pdf_reader.pages[pagenum]\n",
    "        pdf_writer.add_page(page)\n",
    "\n",
    "    with open(local_pdf, 'wb') as new_file:\n",
    "        new_file.seek(0)\n",
    "        pdf_writer.write(new_file)\n",
    "        new_file.truncate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading we can load the documents with the help of [DirectoryLoader from PyPDF available under LangChain](https://python.langchain.com/en/latest/reference/modules/document_loaders.html) and splitting them into smaller chunks.\n",
    "\n",
    "Note: The retrieved document/text should be large enough to contain enough information to answer a question; but small enough to fit into the LLM prompt. Also the embeddings model has a limit of the length of input tokens limited to 512 tokens, which roughly translates to ~2000 characters. For the sake of this use-case we are creating chunks of roughly 1000 characters with an overlap of 100 characters using [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 [Document(page_content='Dear shareholders:\\nAs I sit down to write my second annual shareholder letter as CEO, I find myself optimistic and energized\\nby what lies ahead for Amazon. Despite 2022 being one of the harder macroeconomic years in recent memory,and with some of our own operating challenges to boot, we still found a way to grow demand (on top ofthe unprecedented growth we experienced in the first half of the pandemic). We innovated in our largestbusinesses to meaningfully improve customer experience short and long term. And, we made importantadjustments in our investment decisions and the way in which we’ll invent moving forward, while stillpreserving the long-term investments that we believe can change the future of Amazon for customers,\\nshareholders, and employees.\\nWhile there were an unusual number of simultaneous challenges this past year, the reality is that if you\\noperate in large, dynamic, global market segments with many capable and well-funded competitors (theconditions in which Amazon operates all of its businesses), conditions rarely stay stagnant for long.\\nIn the 25 years I’ve been at Amazon, there has been constant change, much of which we’ve initiated ourselves.\\nWhen I joined Amazon in 1997, we had booked $15M in revenue in 1996, were a books-only retailer, didnot have a third-party marketplace, and only shipped to addresses in the US. Today, Amazon sells nearly everyphysical and digital retail item you can imagine, with a vibrant third-party seller ecosystem that accountsfor 60% of our unit sales, and reaches customers in virtually every country around the world. Similarly,building a business around a set of technology infrastructure services in the cloud was not obvious in 2003when we started pursuing AWS, and still wasn’t when we launched our first services in 2006. Having virtuallyevery book at your fingertips in 60 seconds, and then being able to store and retrieve them on a lightweightdigital reader was not “a thing”yet when we launched Kindle in 2007, nor was a voice-driven personal assistantlike Alexa (launched in 2014) that you could use to access entertainment, control your smart home, shop,and retrieve all sorts of information.\\nThere have also been times when macroeconomic conditions or operating inefficiencies have presented us\\nwith new challenges. For instance, in the 2001 dot-com crash, we had to secure letters of credit to buyinventory for the holidays, streamline costs to deliver better profitability for the business, yet still prioritizedthe long-term customer experience and business we were trying to build (if you remember, we actuallylowered prices in most of our categories during that tenuous 2001 period). Y ou saw this sort of balancingagain in 2008-2009 as we endured the recession provoked by the mortgage-backed securities financial crisis.We took several actions to manage the cost structure and efficiency of our Stores business, but we alsobalanced this streamlining with investment in customer experiences that we believed could be substantialfuture businesses with strong returns for shareholders. In 2008, AWS was still a fairly small, fledgling business.We knew we were on to something, but it still required substantial capital investment. There were voicesinside and outside of the company questioning why Amazon (known mostly as an online retailer then) wouldbe investing so much in cloud computing. But, we knew we were inventing something special that couldcreate a lot of value for customers and Amazon in the future. We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009 period.\\nChange is always around the corner. Sometimes, you proactively invite it in, and sometimes it just comes\\na-knocking. But, when you see it’s coming, you have to embrace it. And, the companies that do this well overa long period of time usually succeed. I’m optimistic about our future prospects because I like the way ourteam is responding to the changes we see in front of us.', metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}), Document(page_content='Over the last several months, we took a deep look across the company, business by business , invention by\\ninvention, and asked ourselves whether we had conviction about each initiative’s long-term potential to driveenough revenue, operating income, free cash flow, and return on invested capital. In some cases, it led to usshuttering certain businesses. For instance, we stopped pursuing physical store concepts like our Bookstoresand 4 Star stores, closed our Amazon Fabric and Amazon Care efforts, and moved on from some newerdevices where we didn’t see a path to meaningful returns. In other cases, we looked at some programs thatweren’t producing the returns we’d hoped (e.g. free shipping for all online grocery orders over $35) andamended them. We also reprioritized where to spend our resources, which ultimately led to the hard decisionto eliminate 27,000 corporate roles. There are a number of other changes that we’ve made over the lastseveral months to streamline our overall costs, and like most leadership teams, we’ll continue to evaluatewhat we’re seeing in our business and proceed adaptively.\\nWe also looked hard at how we were working together as a team and asked our corporate employees to come\\nback to the office at least three days a week , beginning in May. During the pandemic, our employees rallied to\\nget work done from home and did everything possible to keep up with the unexpected circumstances thatpresented themselves. It was impressive and I’m proud of the way our collective team came together toovercome unprecedented challenges for our customers, communities, and business. But, we don’t think it’s thebest long-term approach. We’ve become convinced that collaborating and inventing is easier and moreeffective when we’re working together and learning from one another in person. The energy and riffing onone another’s ideas happen more freely, and many of the best Amazon inventions have had their breakthroughmoments from people staying behind after a meeting and working through ideas on a whiteboard, orcontinuing the conversation on the walk back from a meeting, or just popping by a teammate’s office laterthat day with another thought. Invention is often messy. It wanders and meanders and marinates.Serendipitous interactions help it, and there are more of those in-person than virtually. It’s also significantlyeasier to learn, model, practice, and strengthen our culture when we’re in the office together most of thetime and surrounded by our colleagues. Innovation and our unique culture have been incredibly importantin our first 29 years as a company, and I expect it will be comparably so in the next 29.\\nA critical challenge we’ve continued to tackle is the rising cost to serve in our Stores fulfillment network (i.e.\\nthe cost to get a product from Amazon to a customer)—and we’ve made several changes that we believe will\\nmeaningfully improve our fulfillment costs and speed of delivery .\\nDuring the early part of the pandemic, with many physical stores shut down, our consumer business grew\\nat an extraordinary clip, with annual revenue increasing from $245B in 2019 to $434B in 2022. This meant thatwe had to double the fulfillment center footprint that we’d built over the prior 25 years and substantiallyaccelerate building a last-mile transportation network that’s now the size of UPS (along with a new sortationcenter network to assist with efficiency and speed when items needed to traverse long distances)—all in thespan of about two years. This was no easy feat, and hundreds of thousands of Amazonians worked very hardto make this happen. However, not surprisingly, with that rate and scale of change, there was a lot ofoptimization needed to yield the intended productivity. Over the last several months, we’ve scrutinized everyprocess path in our fulfillment centers and transportation network and redesigned scores of processes andmechanisms, resulting in steady productivity gains and cost reductions over the last few quarters. There’smore work to do, but we’re pleased with our trajectory and the meaningful upside in front of us.\\nWe also took this occasion to make larger structural changes that set us up better to deliver lower costs and\\nfaster speed for many years to come. A good example was reevaluating how our US fulfillment network wasorganized. Until recently, Amazon operated one national US fulfillment network that distributed inventoryfrom fulfillment centers spread across the entire country. If a local fulfillment center didn’t have the product acustomer ordered, we’d end up shipping it from other parts of the country, costing us more and increasingdelivery times. This challenge became more pronounced as our fulfillment network expanded to hundreds ofadditional nodes over the last few years, distributing inventory across more locations and increasing the\\ncomplexity of connecting the fulfillment center and delivery station nodes efficiently. Last year, we startedrearchitecting our inventory placement strategy and leveraging our larger fulfillment center footprint to movefrom a national fulfillment network to a regionalized network model. We made significant internal changes(e.g. placement and logistics software, processes, physical operations) to create eight interconnected regions insmaller geographic areas. Each of these regions has broad, relevant selection to operate in a largely self-sufficient way, while still being able to ship nationally when necessary. Some of the most meaningful and hard', metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}), Document(page_content='work came from optimizing the connections between this large amount of infrastructure. We also continue\\nto improve our advanced machine learning algorithms to better predict what customers in various parts of thecountry will need so that we have the right inventory in the right regions at the right time. We’ve recentlycompleted this regional roll out and like the early results. Shorter travel distances mean lower cost to serve,less impact on the environment, and customers getting their orders faster. On the latter, we’re excited aboutseeing more next day and same-day deliveries, and we’re on track to have our fastest Prime delivery speedsever in 2023. Overall, we remain confident about our plans to lower costs, reduce delivery times, and build a\\nmeaningfully larger retail business with healthy operating margins.\\nAWS has an $85B annualized revenue run rate, is still early in its adoption curve, but at a juncture where it’s\\ncritical to stay focused on what matters most to customers over the long-haul . Despite growing 29% year-over-\\nyear (“Y oY”) in 2022 on a $62B revenue base, AWS faces short-term headwinds right now as companiesare being more cautious in spending given the challenging, current macroeconomic conditions. While somecompanies might obsess over how they could extract as much money from customers as possible in these tighttimes, it’s neither what customers want nor best for customers in the long term, so we’re taking a differenttack. One of the many advantages of AWS and cloud computing is that when your business grows, you canseamlessly scale up; and conversely, if your business contracts, you can choose to give us back that capacityand cease paying for it. This elasticity is unique to the cloud, and doesn’t exist when you’ve already madeexpensive capital investments in your own on-premises datacenters, servers, and networking gear. In AWS,like all our businesses, we’re not trying to optimize for any one quarter or year. We’re trying to build customerrelationships (and a business) that outlast all of us; and as a result, our AWS sales and support teams arespending much of their time helping customers optimize their AWS spend so they can better weather thisuncertain economy. Many of these AWS customers tell us that they’re not cost-cutting as much as cost-optimizing so they can take their resources and apply them to emerging and inventive new customerexperiences they’re planning. Customers have appreciated this customer-focused, long-term approach, andwe think it’ll bode well for both customers and AWS.\\nWhile these short-term headwinds soften our growth rate, we like a lot of the fundamentals that we’re seeing\\nin AWS. Our new customer pipeline is robust, as are our active migrations. Many companies usediscontinuous periods like this to step back and determine what they strategically want to change, and wefind an increasing number of enterprises opting out of managing their own infrastructure, and preferring tomove to AWS to enjoy the agility, innovation, cost-efficiency, and security benefits. And most importantlyfor customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launchedin 2022), and invest in long-term inventions that change what’s possible.\\nChip development is a good example. In last year’s letter, I mentioned the investment we were making in our\\ngeneral-purpose CPU processors named Graviton. Graviton2-based compute instances deliver up to 40%better price-performance than the comparable latest generation x86-based instances; and in 2022, we deliveredour Graviton3 chips, providing 25% better performance than the Graviton2 processors. Further, as machinelearning adoption has continued to accelerate, customers have yearned for lower-cost GPUs (the chipsmost commonly used for machine learning). AWS started investing years ago in these specialized chips formachine learning training and inference (inferences are the predictions or answers that a machine learningmodel provides). We delivered our first training chip in 2022 (“Trainium”); and for the most commonmachine learning models, Trainium-based instances are up to 140% faster than GPU-based instances at upto 70% lower cost. Most companies are still in the training stage, but as they develop models that graduate tolarge-scale production, they’ll find that most of the cost is in inference because models are trainedperiodically whereas inferences are happening all the time as their associated application is being exercised.We launched our first inference chips (“Inferentia”) in 2019, and they have saved companies like Amazon overa hundred million dollars in capital expense already. Our Inferentia2 chip, which just launched, offers upto four times higher throughput and ten times lower latency than our first Inferentia processor. With theenormous upcoming growth in machine learning, customers will be able to get a lot more done with AWS’straining and inference chips at a significantly lower cost. We’re not close to being done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.\\nSimilarly high potential, Amazon’s Advertising business is uniquely effective for brands, which is part of why it\\ncontinues to grow at a brisk clip . Akin to physical retailers’ advertising businesses selling shelf space, end-\\ncaps, and placement in their circulars, our sponsored products and brands offerings have been an integral part', metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}), Document(page_content='of the Amazon shopping experience for more than a decade. However, unlike physical retailers, Amazon\\ncan tailor these sponsored products to be relevant to what customers are searching for given what we knowabout shopping behaviors and our very deep investment in machine learning algorithms. This leads toadvertising that’s more useful for customers; and as a result, performs better for brands. This is part of whyour Advertising revenue has continued to grow rapidly (23% Y oY in Q4 2022, 25% Y oY overall for 2022on a $31B revenue base), even as most large advertising-focused businesses’ growth have slowed over the lastseveral quarters.\\nWe strive to be the best place for advertisers to build their brands. We have near and long-term opportunities\\nthat will help us achieve that mission. We’re continuing to make large investments in machine learning tokeep honing our advertising selection algorithms. For the past couple of years, we’ve invested in buildingcomprehensive, flexible, and durable planning and measurement solutions, giving marketers greater insightinto advertising effectiveness. An example is Amazon Marketing Cloud (“AMC”). AMC is a “clean room”(i.e. secure digital environment) in which advertisers can run custom audience and campaign analyticsacross a range of first and third-party inputs, in a privacy-safe manner, to generate advertising and businessinsights to inform their broader marketing and sales strategies. The Advertising and AWS teams havecollaborated to enable companies to store their data in AWS, operate securely in AMC with Amazon andother third-party data sources, perform analytics in AWS, and have the option to activate advertising onAmazon or third-party publishers through the Amazon Demand-Side Platform. Customers really like thisconcerted capability. We also see future opportunity to thoughtfully integrate advertising into our video,live sports, audio, and grocery products. We’ll continue to work hard to help brands uniquely engage withthe right audience, and grow this part of our business.\\nWhile it’s tempting in turbulent times only to focus on your existing large businesses, to build a sustainable,\\nlong-lasting, growing company that helps customers across a large number of dimensions, you can’t stop\\ninventing and working on long-term customer experiences that can meaningfully impact customers andyour company.\\nWhen we look at new investment opportunities, we ask ourselves a few questions:\\n◦If we were successful, could it be big and have a reasonable return on invested capital?\\n◦Is the opportunity being well-served today?\\n◦Do we have a differentiated approach?\\n◦And, do we have competence in that area? And if not, can we acquire it quickly?\\nIf we like the answers to those questions, then we’ll invest. This process has led to some expansions that\\nseem straightforward, and others that some folks might not have initially guessed.\\nThe earliest example is when we chose to expand from just selling Books , to adding categories like Music,\\nVideo, Electronics, and Toys. Back then (1998-1999), it wasn’t universally applauded, but in retrospect, itseems fairly obvious.\\nThe same could be said for our international Stores expansion . In 2022, our international consumer segment\\ndrove $118B of revenue. In our larger, established international consumer businesses, we’re big enough tobe impacted by the slowing macroeconomic conditions; however, the growth in 2019-2021 on a large base wasremarkable—30% compound annual growth rate (“CAGR”) in the UK, 26% in Germany, and 21% inJapan (excluding the impact of FX). Over the past several years, we’ve invested in new internationalgeographies, including India, Brazil, Mexico, Australia, various European countries, the Middle East, andparts of Africa. These new countries take a certain amount of fixed investment to get started and to scale, butwe like the trajectory they’re on, and their growth patterns resemble what we’ve seen in North Americaand our established international geographies. Emerging countries sometimes lack some of the infrastructureand services that our business relies on (e.g. payment methods, transportation services, and internet/telecom infrastructure). To solve these challenges, we continue to work with various partners to deliversolutions for customers. Ultimately, we believe that this investment in serving a broader geographical footprintwill allow us to help more customers across the world, as well as build a larger free cash flow-generatingconsumer business.', metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}), Document(page_content='Beyond geographic expansion, we’ve been working to expand our customer offerings across some large,\\nunique product retail market segments. Grocery is an $800B market segment in the US alone, with the average\\nhousehold shopping three to four times per week. Amazon has built a somewhat unusual, but significantgrocery business over nearly 20 years. Similar to how other mass merchants entered the grocery space in the1980s, we began by adding products typically found in supermarket aisles that don’t require temperaturecontrol such as paper products, canned and boxed food, candy and snacks, pet care, health and personal care,and beauty. However, we offer more than three million items compared to a typical supermarket’s 30K forthe same categories. To date, we’ve also focused on larger pack sizes, given the current cost to serve onlinedelivery. While we’re pleased with the size and growth of our grocery business, we aspire to serve more ofour customers’ grocery needs than we do today. To do so, we need a broader physical store footprint given thatmost of the grocery shopping still happens in physical venues. Whole Foods Market pioneered the naturaland organic specialty grocery store concept 40 years ago. Today, it’s a large and growing business that continuesto raise the bar for healthy and sustainable food. Over the past year, we’ve continued to invest in thebusiness while also making changes to drive better profitability. Whole Foods is on an encouraging path,but to have a larger impact on physical grocery, we must find a mass grocery format that we believe is worthexpanding broadly. Amazon Fresh is the brand we’ve been experimenting with for a few years, and we’reworking hard to identify and build the right mass grocery format for Amazon scale. Grocery is a big growthopportunity for Amazon.\\nAmazon Business is another example of an investment where our ecommerce and logistics capabilities\\nposition us well to pursue this large market segment. Amazon Business allows businesses, municipalities,and organizations to procure products like office supplies and other bulk items easily and at great savings.While some areas of the economy have struggled over the past few years, Amazon Business has thrived. Why?Because the team has translated what it means to deliver selection, value, and convenience into a businessprocurement setting, constantly listening to and learning from customers, and innovating on their behalf.Some people have never heard of Amazon Business, but, our business customers love it. Amazon Businesslaunched in 2015 and today drives roughly $35B in annualized gross sales. More than six million activecustomers, including 96 of the global Fortune 100 companies, are enjoying Amazon Business’ one-stopshopping, real-time analytics, and broad selection on hundreds of millions of business supplies. We believethat we’ve only scratched the surface of what’s possible to date, and plan to keep building the features ourbusiness customers tell us they need and want.\\nWhile many brands and merchants successfully sell their products on Amazon’s marketplace, there are also\\na large number of brands and sellers who have launched their own direct-to-consumer websites. One of thechallenges for these merchants is driving conversion from views to purchases. We invented Buy with Prime\\nto help with this challenge. Buy with Prime allows third-party brands and sellers to offer their products ontheir own websites to our large Amazon Prime membership, and offer those customers fast, free Prime shippingand seamless checkout with their Amazon account. Buy with Prime provides merchants several additionalbenefits, including Amazon handling the product storage, picking, packing, delivery, payment, and anyreturns, all through Amazon Pay and Fulfillment by Amazon. Buy with Prime has recently been madeavailable to all US merchants; and so far, Buy with Prime has increased shopper conversion on third-partyshopping sites by 25% on average. Merchants are excited about converting more sales and fulfilling theseshipments more easily, Prime members love that they can use their Prime benefits on more destinations,and Buy with Prime allows us to improve the shopping experience across more of the web.\\nExpanding internationally, pursuing large retail market segments that are still nascent for Amazon, and\\nusing our unique assets to help merchants sell more effectively on their own websites are somewhat naturalextensions for us. There are also a few investments we’re making that are further from our core businesses, butwhere we see unique opportunity. In 2003, AWS would have been a classic example. In 2023, AmazonHealthcare and Kuiper are potential analogues.\\nOur initial efforts in Healthcare began with pharmacy, which felt less like a major departure from ecommerce.\\nFor years, Amazon customers had asked us when we’d offer them an online pharmacy as their frustrationsmounted with current providers. Launched in 2020, Amazon Pharmacy is a full-service, online pharmacy thatoffers transparent pricing, easy refills, and savings for Prime members. The business is growing quickly,and continues to innovate. An example is Amazon Pharmacy’s recent launch of RxPass, which for a $5 per', metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}), Document(page_content='month flat fee, enables Prime members to get as many of the eligible prescription medications as they need\\nfor dozens of common conditions, like high blood pressure, acid reflux, and anxiety. However, our customershave continued to express a strong desire for Amazon to provide a better alternative to the inefficient andunsatisfying broader healthcare experience. We decided to start with primary care as it’s a prevalent first stopin the patient journey. We evaluated and studied the existing landscape extensively, including some early\\nAmazon experiments like Amazon Care. During this process, we identified One Medical’s patient-focusedexperience as an excellent foundation upon which to build our future business; and in July 2022, we announcedour acquisition of One Medical. There are several elements that customers love about One Medical. It hasa fantastic digital app that makes it easy for patients to discuss issues with a medical practitioner via chat orvideo conference. If a physical visit is required, One Medical has offices in cities across the US wherepatients can book same or next day appointments. One Medical has relationships with specialty physiciansin each of its cities and works closely with local hospital systems to make seeing specialists easy, so OneMedical members can quickly access these resources when needed. Going forward, we strongly believethat One Medical and Amazon will continue to innovate together to change what primary care will look likefor customers.\\nKuiper is another example of Amazon innovating for customers over the long term in an area where there’s\\nhigh customer need. Our vision for Kuiper is to create a low-Earth orbit satellite system to deliver high-qualitybroadband internet service to places around the world that don’t currently have it. There are hundreds ofmillions of households and businesses who don’t have reliable access to the internet. Imagine what they’ll beable to do with reliable connectivity, from people taking online education courses, using financial services,starting their own businesses, doing their shopping, enjoying entertainment, to businesses and governmentsimproving their coverage, efficiency, and operations. Kuiper will deliver not only accessibility, butaffordability. Our teams have developed low-cost antennas (i.e. customer terminals) that will lower thebarriers to access. We recently unveiled the new terminals that will communicate with the satellites passingoverhead, and we expect to be able to produce our standard residential version for less than $400 each. They’resmall: 11 inches square, 1 inch thick, and weigh less than 5 pounds without their mounting bracket, butthey deliver speeds up to 400 megabits per second. And they’re powered by Amazon-designed baseband chips.We’re preparing to launch two prototype satellites to test the entire end-to-end communications networkthis year, and plan to be in beta with commercial customers in 2024. The customer reaction to what we’veshared thus far about Kuiper has been very positive, and we believe Kuiper represents a very large potentialopportunity for Amazon. It also shares several similarities to AWS in that it’s capital intensive at the start,but has a large prospective consumer, enterprise, and government customer base, significant revenue andoperating profit potential, and relatively few companies with the technical and inventive aptitude, as well asthe investment hypothesis to go after it.\\nOne final investment area that I’ll mention, that’s core to setting Amazon up to invent in every area of our\\nbusiness for many decades to come, and where we’re investing heavily is Large Language Models (“LLMs”)\\nand Generative AI . Machine learning has been a technology with high promise for several decades, but it’s\\nonly been the last five to ten years that it’s started to be used more pervasively by companies. This shift wasdriven by several factors, including access to higher volumes of compute capacity at lower prices than was everavailable. Amazon has been using machine learning extensively for 25 years, employing it in everythingfrom personalized ecommerce recommendations, to fulfillment center pick paths, to drones for Prime Air,to Alexa, to the many machine learning services AWS offers (where AWS has the broadest machine learningfunctionality and customer base of any cloud provider). More recently, a newer form of machine learning,called Generative AI, has burst onto the scene and promises to significantly accelerate machine learningadoption. Generative AI is based on very Large Language Models (trained on up to hundreds of billionsof parameters, and growing), across expansive datasets, and has radically general and broad recall andlearning capabilities. We have been working on our own LLMs for a while now, believe it will transform andimprove virtually every customer experience, and will continue to invest substantially in these modelsacross all of our consumer, seller, brand, and creator experiences. Additionally, as we’ve done for years inAWS, we’re democratizing this technology so companies of all sizes can leverage Generative AI. AWS isoffering the most price-performant machine learning chips in Trainium and Inferentia so small and largecompanies can afford to train and run their LLMs in production. We enable companies to choose fromvarious LLMs and build applications with all of the AWS security, privacy and other features that customersare accustomed to using. And, we’re delivering applications like AWS’s CodeWhisperer, which revolutionizes', metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}), Document(page_content='developer productivity by generating code suggestions in real time. I could write an entire letter on LLMs\\nand Generative AI as I think they will be that transformative, but I’ll leave that for a future letter. Let’s justsay that LLMs and Generative AI are going to be a big deal for customers, our shareholders, and Amazon.\\nSo, in closing, I’m optimistic that we’ll emerge from this challenging macroeconomic time in a stronger\\nposition than when we entered it. There are several reasons for it and I’ve mentioned many of them above.But, there are two relatively simple statistics that underline our immense future opportunity. While we have aconsumer business that’s $434B in 2022, the vast majority of total market segment share in global retailstill resides in physical stores (roughly 80%). And, it’s a similar story for Global IT spending, where we haveAWS revenue of $80B in 2022, with about 90% of Global IT spending still on-premises and yet to migrateto the cloud. As these equations steadily flip—as we’re already seeing happen—we believe our leading customerexperiences, relentless invention, customer focus, and hard work will result in significant growth in thecoming years. And, of course, this doesn’t include the other businesses and experiences we’re pursuing atAmazon, all of which are still in their early days.\\nI strongly believe that our best days are in front of us, and I look forward to working with my teammates at\\nAmazon to make it so.\\nSincerely,\\nAndy Jassy\\nPresident and Chief Executive OfficerAmazon.com, Inc.\\nP .S. As we have always done, our original 1997 Shareholder Letter follows. What’s written there is as true\\ntoday as it was in 1997.', metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'})]\n",
      "\n",
      "6 [Document(page_content='Dear shareholders:\\nOver the past 25 years at Amazon, I’ve had the opportunity to write many narratives, emails, letters, and\\nkeynotes for employees, customers, and partners. But, this is the first time I’ve had the honor of writing ourannual shareholder letter as CEO of Amazon. Jeff set the bar high on these letters, and I will try to keepthem worth reading.\\nWhen the pandemic started in early 2020, few people thought it would be as expansive or long-running as\\nit’s been. Whatever role Amazon played in the world up to that point became further magnified as mostphysical venues shut down for long periods of time and people spent their days at home. This meant thathundreds of millions of people relied on Amazon for PPE, food, clothing, and various other items thathelped them navigate this unprecedented time. Businesses and governments also had to shift, practicallyovernight, from working with colleagues and technology on-premises to working remotely. AWS played amajor role in enabling this business continuity. Whether companies saw extraordinary demand spikes, ordemand diminish quickly with reduced external consumption, the cloud’s elasticity to scale capacity up anddown quickly, as well as AWS’s unusually broad functionality helped millions of companies adjust to thesedifficult circumstances.\\nOur AWS and Consumer businesses have had different demand trajectories during the pandemic. In the\\nfirst year of the pandemic, AWS revenue continued to grow at a rapid clip—30% year over year (“Y oY”) in2020 on a $35 billion annual revenue base in 2019—but slower than the 37% Y oY growth in 2019. Thiswas due in part to the uncertainty and slowing demand that so many businesses encountered, but also inpart to our helping companies optimize their AWS footprint to save money. Concurrently, companies werestepping back and determining what they wanted to change coming out of the pandemic. Many concludedthat they didn’t want to continue managing their technology infrastructure themselves, and made thedecision to accelerate their move to the cloud. This shift by so many companies (along with the economyrecovering) helped re-accelerate AWS’s revenue growth to 37% Y oY in 2021.\\nConversely, our Consumer revenue grew dramatically in 2020. In 2020, Amazon’s North America and\\nInternational Consumer revenue grew 39% Y oY on the very large 2019 revenue base of $245 billion; and,this extraordinary growth extended into 2021 with revenue increasing 43% Y oY in Q1 2021. These areastounding numbers. We realized the equivalent of three years’ forecasted growth in about 15 months.\\nAs the world opened up again starting in late Q2 2021, and more people ventured out to eat, shop, and travel,\\nconsumer spending returned to being spread over many more entities. We weren’t sure what to expect in2021, but the fact that we continued to grow at double digit rates (with a two-year Consumer compoundedannual growth rate of 29%) was encouraging as customers appreciated the role Amazon played for themduring the pandemic, and started using Amazon for a larger amount of their household purchases.\\nThis growth also created short-term logistics and cost challenges. We spent Amazon’s first 25 years building\\na very large fulfillment network, and then had to double it in the last 24 months to meet customer demand.As we were bringing this new capacity online, the labor market tightened considerably, making it challengingboth to receive all of the inventory our vendors and sellers wanted to send us and to place that inventoryas close to customers as we typically do. Combined with ocean, air, and trucking capacity becoming scarcerand more expensive, this created extra transportation and productivity costs. Supply chains were disruptedin ways none of us had seen previously. We hoped that the major impact from COVID-19 would recede as2021 drew to a close, but then omicron reared its head in December, which had worldwide ramifications,including impacting people’s ability to work. And then in late February, with Russia’s invasion of Ukraine,fuel costs and inflation became bigger issues with which to contend.\\nSo, 2021 was a crazy and unpredictable year, continuing a trend from 2020. But, I’m proud of the incredible\\ncommitment and effort from our employees all over the world. I’m not sure any of us would have gotten', metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}), Document(page_content='through the pandemic the same way without the dedication and extraordinary efforts shown by our teams\\nduring this period, and I’m eternally grateful.\\nIt’s not normal for a company of any size to be able to respond to something as discontinuous and\\nunpredictable as this pandemic turned out to be. What is it about Amazon that made it possible for us to doso? It’s because we weren’t starting from a standing start. We had been iterating on and remaking ourfulfillment capabilities for nearly two decades. In every business we pursue, we’re constantly experimentingand inventing. We’re divinely discontented with customer experiences, whether they’re our own or not. Webelieve these customer experiences can always be better, and we strive to make customers’ lives better andeasier every day. The beauty of this mission is that you never run out of runway; customers always want better,and our job is both to listen to their feedback and to imagine what else is possible and invent on theirbehalf.\\nPeople often assume that the game-changing inventions they admire just pop out of somebody’s head, a\\nlight bulb goes off, a team executes to that idea, and presto—you have a new invention that’s a breakawaysuccess for a long time. That’s rarely, if ever, how it happens. One of the lesser known facts about innovativecompanies like Amazon is that they are relentlessly debating, re-defining, tinkering, iterating, andexperimenting to take the seed of a big idea and make it into something that resonates with customers andmeaningfully changes their customer experience over a long period of time.\\nLet me give you some Amazon examples.Our Fulfillment Network : Going back to the pandemic, there’s no way we could have started working on\\nour fulfillment network in March 2020 and satisfied anything close to what our customers needed. We’d beeninnovating in our fulfillment network for 20 years, constantly trying to shorten the time to get items to\\ncustomers. In the early 2000s, it took us an average of 18 hours to get an item through our fulfillment centersand on the right truck for shipment. Now, it takes us two. To deliver as reliably and cost-effectively as wedesire, and to serve Amazon Prime members expecting shipments in a couple of days, we spent years buildingout an expansive set of fulfillment centers, a substantial logistics and transportation capability, andreconfigured how we did virtually everything in our facilities. For perspective, in 2004, we had sevenfulfillment centers in the U.S. and four in other parts of the world, and we hadn’t yet added delivery stations,which connect our fulfillment and sortation centers to the last-mile delivery vans you see driving aroundyour neighborhood. Fast forward to the end of 2021, we had 253 fulfillment centers, 110 sortation centers,and 467 delivery stations in North America, with an additional 157 fulfillment centers, 58 sortation centers,and 588 delivery stations across the globe. Our delivery network grew to more than 260,000 driversworldwide, and our Amazon Air cargo fleet has more than 100 aircraft. This has represented a capitalinvestment of over $100 billion and countless iterations and small process improvements by over a millionAmazonians in the last decade and a half.\\nIronically, just before COVID started, we’d made the decision to invest billions of incremental dollars over\\nseveral years to deliver an increasing number of Prime shipments in one day. This initiative was slowed by thechallenges of the pandemic, but we’ve since resumed our focus here. Delivering a substantial amount ofshipments in one day is hard (especially across the millions of items that we offer) and initially expensive aswe build out the infrastructure to scale this efficiently. But, we believe our over 200 million Prime customers,who will tell you very clearly that faster is almost always better, will love this. So, this capability to shipmillions of items within a couple days (and increasingly one day) was not from one aha moment and notdeveloped in a year or two. It’s been hard-earned by putting ourselves in the shoes of our customers, knowingwhat they wanted, organizing Amazonians to work together to invent better solutions, and investing alarge amount of financial and people resources over 20 years (often well in advance of when it would payout). This type of iterative innovation is never finished and has periodic peaks in investment years, but leadsto better long-term customer experiences, customer loyalty, and returns for our shareholders.\\nAWS : As we were defining AWS and working backwards on the services we thought customers wanted, we\\nkept triggering one of the biggest tensions in product development—where to draw the line on functionality inV1. One early meeting in particular—for our core compute service called Elastic Compute Cloud (“EC2”)—was scheduled for an hour, and took three, as we animatedly debated whether we could launch a computeservice without an accompanying persistent block storage companion (a form of network attached storage).', metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}), Document(page_content='Everybody agreed that having a persistent block store was important to a complete compute service;\\nhowever, to have one ready would take an extra year. The question became could we offer customers auseful service where they could get meaningful value before we had all the features we thought they wanted?We decided that the initial launch of EC2 could be feature-poor if we also organized ourselves to listen tocustomers and iterate quickly. This approach works well if you indeed iterate quickly; but, is disastrous if youcan’t. We launched EC2 in 2006 with one instance size, in one data center, in one region of the world, withLinux operating system instances only (no Windows), without monitoring, load balancing, auto-scaling, oryes, persistent storage. EC2 was an initial success, but nowhere near the multi-billion-dollar service it’sbecome until we added the missing capabilities listed above, and then some.\\nIn the early days of AWS, people sometimes asked us why compute wouldn’t just be an undifferentiated\\ncommodity. But, there’s a lot more to compute than just a server. Customers want various flavors of compute(e.g. server configurations optimized for storage, memory, high-performance compute, graphics rendering,machine learning), multiple form factors (e.g. fixed instance sizes, portable containers, serverless functions),various sizes and optimizations of persistent storage, and a slew of networking capabilities. Then, there’sthe CPU chip that runs in your compute. For many years, the industry had used Intel or AMD x86 processors.We have important partnerships with these companies, but realized that if we wanted to push price andperformance further (as customers requested), we’d have to develop our own chips, too. Our first generalizedchip was Graviton, which we announced in 2018. This helped a subset of customer workloads run morecost-effectively than prior options. But, it wasn’t until 2020, after taking the learnings from Graviton and\\ninnovating on a new chip, that we had something remarkable with our Graviton2 chip, which provides up to40% better price-performance than the comparable latest generation x86 processors. Think about howmuch of an impact 40% improvement on compute is. Compute is used for every bit of technology. That’s ahuge deal for customers. And, while Graviton2 has been a significant success thus far (48 of the top 50 AWSEC2 customers have already adopted it), the AWS Chips team was already learning from what customerssaid could be better, and announced Graviton3 this past December (offering a 25% improvement on top ofGraviton2’s relative gains). The list of what we’ve invented and delivered for customers in EC2 (and AWS ingeneral) is pretty mind-boggling, and this iterative approach to innovation has not only given customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.\\nDevices : Our first foray into devices was the Kindle, released in 2007. It was not the most sophisticated\\nindustrial design (it was creamy white in color and the corners were uncomfortable for some people to hold),but revolutionary because it offered customers the ability to download any of over 90,000 books (nowmillions) in 60 seconds—and we got better and faster at building attractive designs. Shortly thereafter, welaunched a tablet, and then a phone (with the distinguishing feature of having front-facing cameras and agyroscope to give customers a dynamic perspective along with varied 3D experiences). The phone wasunsuccessful, and though we determined we were probably too late to this party and directed these resourceselsewhere, we hired some fantastic long-term builders and learned valuable lessons from this failure thathave served us well in devices like Echo and FireTV .\\nWhen I think of the first Echo device—and what Alexa could do for customers at that point—it was\\nnoteworthy, yet so much less capable than what’s possible today. Today, there are hundreds of millions ofAlexa-enabled devices out there (in homes, offices, cars, hotel rooms, Amazon Echo devices, and third-partymanufacturer devices); you can listen to music—or watch videos now; you can control your lights andhome automation; you can create routines like “Start My Day” where Alexa tells you the weather, yourestimated commute time based on current traffic, then plays the news; you can easily order retail items onAmazon; you can get general or customized news, updates on sporting events and related stats—and we’re stillquite early with respect to what Alexa and Alexa-related devices will do for customers. Our goal is forAlexa to be the world’s most helpful and resourceful personal assistant, who makes people’s lives meaningfullyeasier and better. We have a lot more inventing and iterating to go, but customers continue to indicate thatwe’re on the right path. We have several other devices at varying stages of evolution (e.g. Ring and Blinkprovide the leading digital home security solutions, Astro is a brand new home robot that we just launchedin late 2021), but it’s safe to say that every one of our devices, whether you’re talking about Kindle, FireTV,Alexa/Echo, Ring, Blink, or Astro is an invention-in-process with a lot more coming that will keepimproving customers’ lives.', metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}), Document(page_content='Prime Video : We started in 2006 with an offering called Amazon Unbox where customers could download\\nabout a thousand movies from major studios. This made sense as bandwidth was slower those days (it wouldtake an hour to download a video). But, as bandwidth got much faster to people’s homes and mobiledevices, along with the advent of connected TVs, streaming was going to be a much better customer solution,and we focused our efforts on streaming. In 2011, we started offering over 5,000 streaming movies andshows as part of customers’ Amazon Prime subscriptions. Initially, all of our content was produced by otherstudios and entertainment companies. These deals were expensive, country-specific, and only available tous for a limited period; so, to expand our options, we started creating our own original shows. Our early effortsincluded short-lived shows like Alpha House andBetas , before we had our first award-winning series in\\nTransparent , and eventually created multi-year franchises in The Marvelous Mrs. Maisel ,The Boys ,Bosch ,\\nandJack Ryan . Along the way, we’ve learned a lot about producing compelling entertainment with memorable\\nmoments and using machine learning and other inventive technology to provide a superior-quality streamingexperience (with useful, relevant data about actors, TV shows, movies, music, or sports stats a click awayin our unique X-Ray feature). Y ou might have seen some of this in action in our recent new hit series, Reacher ,\\nand you’ll hopefully see it in our upcoming Lord of the Rings series launch (coming Labor Day 2022). Wealso expect that you’ll see this iterative invention when we launch Thursday Night Football , the NFL’s first\\nweekly, prime time, streaming-only broadcast, airing exclusively on Prime Video starting in September2022. Our agreement with the NFL is for 11 years, and we will work relentlessly over the next several yearsto reinvent the NFL viewing experience for football fans.\\nThis track record of frequent invention is not only why more sports entities are choosing to work with\\nPrime Video, but also why so many large entertainment companies have become Prime Video Channelspartners. Channels is a program that enables entertainment companies to leverage Prime Video’s uniquetechnology and viewing experience, as well as its very large member base to offer monthly subscriptions totheir content. Companies like Warner Bros. Discovery, Paramount, Starz, Corus Entertainment, and Globohave found that they’re driving substantial incremental membership and better customer experiencethrough Channels. While there is so much progress in Prime Video from where we started, we have moreinvention in front of us in the next 15 years than the last 15—and our team is passionately committed toproviding customers with the most expansive collection of compelling content anywhere in the world.\\nThis same sort of iterative invention can be applied to efforts supporting people and communities. Last\\nsummer, we added two new Leadership Principles: Strive to be Earth’s Best Employer andSuccess and Scale\\nBring Broad Responsibility . These concepts were always implicit at Amazon, but explicit Leadership\\nPrinciples help us ask ourselves—and empower more Amazonians at all levels to ask—whether we’re livingup to these principles.\\nFor example, more than a million Amazonians work in our fulfillment network. In 2018, we championed\\nthe $15 minimum wage (which is more than double the federal minimum wage), but haven’t stopped there. Wecontinued to increase compensation such that our average starting hourly salary is currently over $18.Along with this compensation, we offer very robust benefits, including full health insurance, a 401K plan,up to 20 weeks of parental leave, and full tuition coverage for associates who want to get a college education(whether they remain with us or not). We’re not close to being done in how we improve the lives of ouremployees. We’ve researched and created a list of what we believe are the top 100 employee experience painpoints and are systematically solving them. We’re also passionate about further improving safety in ourfulfillment network, with a focus on reducing strains, sprains, falls, and repetitive stress injuries. Our injuryrates are sometimes misunderstood. We have operations jobs that fit both the “warehousing” and “courierand delivery” categories. In the last U.S. public numbers, our recordable incident rates were a little higherthan the average of our warehousing peers (6.4 vs. 5.5), and a little lower than the average of our courier anddelivery peers (7.6 vs. 9.1). This makes us about average relative to peers, but we don’t seek to be average.We want to be best in class. When I first started in my new role, I spent significant time in our fulfillmentcenters and with our safety team, and hoped there might be a silver bullet that could change the numbersquickly. I didn’t find that. At our scale (we hired over 300,000 people in 2021 alone, many of whom were newto this sort of work and needed training), it takes rigorous analysis, thoughtful problem-solving, and awillingness to invent to get to where you want. We’ve been dissecting every process path to discern how wecan further improve. We have a variety of programs in flight (e.g. rotational programs that help employeesavoid spending too much time doing the same repetitive motions, wearables that prompt employees when', metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}), Document(page_content='they’re moving in a dangerous way, improved shoes to provide better toe protection, training programs on\\nbody mechanics, wellness, and safety practices). But, we still have a ways to go, and we’ll approach it like wedo other customer experiences—we’ll keep learning, inventing, and iterating until we have moretransformational results. We won’t be satisfied until we do.\\nSimilarly, at our scale, we have a significant carbon footprint. It’s a big part of why we created The Climate\\nPledge a few years ago (a pledge to be net-zero carbon by 2040, ten years ahead of the Paris Agreement). We’remaking significant progress on this effort (we’re committed to powering our operations with 100% renewableenergy by 2025—five years ahead of our original target of 2030, we have ordered over 100,000 electricvans to deliver packages, and have over 300 companies who’ve joined us in The Climate Pledge). But, wehave a different challenge than most companies given the diversity and intensity of our operations (includingshipping billions of packages per year). We’re committed to the challenge, but it will take relentless invention.\\nWe also are trying to increase the amount of affordable housing in the communities in which we have a\\nlarge presence. Our more than $2 billion Housing Equity Fund that we started a year ago has already allocated$1.2 billion toward affordable housing initiatives in the areas around Washington state’s Puget Soundregion, Arlington (Virginia), and Nashville (Tennessee).\\nA final quick example is Kuiper, our low Earth orbit satellite network that we’re spending over $10 billion\\nto build in the next several years. Kuiper will serve customers with minimal to no fixed broadband connectivity,changing access to information and resources for many communities (analysts estimate approximately 300-400 million customers globally are in this category). We’re optimistic that there is a pretty good business modelfor us too, but we’ll see—and it’s a real game changer for underserved families and businesses that willunfold over many years as we keep evolving its capabilities.\\nThis type of iterative innovation is pervasive across every team at Amazon. I could have given comparable\\nexamples in Advertising, Grocery, Gaming, Amazon Music, Amazon Care (our telemedicine offering), orPharmacy, to name a few. All of these stories are still being written as we rapidly experiment, learn, andcontinue to try to make our customer experience better every day.\\nIf this approach sounds appealing, a natural question is what’s required to get good at it? It’s easier said\\nthan done, but here are some components that have helped us:\\n1/Hire the Right Builders : We disproportionately index in hiring builders. We think of builders as people\\nwho like to invent, who look at customer experiences, dissect what doesn’t work well about them, and seekto reinvent them. We want people who keep asking why can’t it be done? We want people who like toexperiment and tinker, and who realize launch is the starting line, not the finish line.\\n2/Organize Builders into Teams That Are as Separable and Autonomous as Possible : It’s hard for teams to be\\ndeep in what customers care about in multiple areas. It’s also hard to spend enough time on the newinitiatives when there’s resource contention with the more mature businesses; the surer bets usually win out.Single-threaded teams will know their customers’ needs better, spend all their waking work hours inventingfor them, and develop context and tempo to keep iterating quickly.\\n3/Give Teams the Right Tools and Permission to Move Fast : Speed is not pre-ordained. It’s a leadership\\nchoice. It has trade-offs, but you can’t wake up one day and start moving fast. It requires having the righttools to experiment and build fast (a major part of why we started AWS), allowing teams to make two-waydoor decisions themselves, and setting an expectation that speed matters. And, it does. Speed isdisproportionally important to every business at every stage of its evolution. Those that move slower thantheir competitive peers fall away over time.\\n4/You Need Blind Faith, But No False Hope : This is a lyric from one of my favorite Foo Fighters songs\\n(“Congregation”). When you invent, you come up with new ideas that people will reject because they haven’tbeen done before (that’s where the blind faith comes in), but it’s also important to step back and make sureyou have a viable plan that’ll resonate with customers (avoid false hope). We’re lucky that we have builderswho challenge each other, feedback loops that give us access to customer feedback, and a product', metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}), Document(page_content='development process of working backwards from the customer where having to write a Press Release (to\\nflesh out the customer benefits) and a Frequently Asked Questions document (to detail how we’d build it)helps us have blind faith without false hope (at least usually).\\n5/Define a Minimum Loveable Product (MLP), and Be Willing to Iterate Fast : Figuring out where to draw\\nthe line for launch is one of the most difficult decisions teams must make. Often, teams wait too long, andinsist on too many bells and whistles, before launching. And, they miss the first mover advantage oropportunity to build mindshare in fast-moving market segments before well-executing peers get too farahead. The launch product must be good enough that you believe it’ll be loved from the get-go (why we callit a “Minimum Loveable Product” vs. a “Minimum Viable Product”), but in newer market segments,teams are often better off getting this MLP to customers and iterating quickly thereafter.\\n6/Adopt a Long-term Orientation : We’re sometimes criticized at Amazon for not shutting much down. It’s\\ntrue that we have a longer tolerance for our investments than most companies. But, we know thattransformational invention takes multiple years, and if you’re making big bets that you believe couldsubstantially change customer experience (and your company), you have to be in it for the long-haul oryou’ll give up too quickly.\\n7/Brace Yourself for Failure : If you invent a lot, you will fail more often than you wish. Nobody likes this\\npart, but it comes with the territory. When it’s clear that we’ve launched something that won’t work, we makesure we’ve learned from what didn’t go well, and secure great landing places for team members whodelivered well—or your best people will hesitate to work on new initiatives.\\nAlbert Einstein is sometimes credited with describing compound interest as the eighth wonder of the world\\n(“He who understands it, earns it. He who doesn’t, pays it”). We think of iterative innovation in much thesame way. Iterative innovation creates magic for customers. Constantly inventing and improving products forcustomers has a compounding effect on the customer experience, and in turn on a business’s prospects.\\nTime is your friend when you are compounding gains. Amazon is a big company with some large businesses,\\nbut it’s still early days for us. We will continue to be insurgent—inventing in businesses that we’re in, in newbusinesses that we’ve yet to launch, and in new ideas that we haven’t even imagined yet. It remains Day 1.\\nSincerely,\\nAndy Jassy\\nPresident and Chief Executive OfficerAmazon.com, Inc.\\nP .S. As we have always done, our original 1997 Shareholder Letter follows. What’s written there is as true\\ntoday as it was in 1997.', metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'})]\n",
      "\n",
      "7 [Document(page_content='To our shareowners:\\nIn Amazon’s 1997 letter to shareholders, our first, I talked about our hope to create an “enduring franchise,”\\none that would reinvent what it means to serve customers by unlocking the internet’s power. I noted that\\nAmazon had grown from having 158 employees to 614, and that we had surpassed 1.5 million customer\\naccounts. We had just gone public at a split-adjusted stock price of $1.50 per share. I wrote that it was Day 1.\\nWe’ve come a long way since then, and we are working harder than ever to serve and delight customers.\\nLast year, we hired 500,000 employees and now directly employ 1.3 million people around the world. We have\\nmore than 200 million Prime members worldwide. More than 1.9 million small and medium-sized businesses\\nsell in our store, and they make up close to 60% of our retail sales. Customers have connected more than\\n100 million smart home devices to Alexa. Amazon Web Services serves millions of customers and ended 2020\\nwith a $50 billion annualized run rate. In 1997, we hadn’t invented Prime, Marketplace, Alexa, or AWS.\\nThey weren’t even ideas then, and none was preordained. We took great risk with each one and put sweat\\nand ingenuity into each one.\\nAlong the way, we’ve created $1.6 trillion of wealth for shareowners. Who are they? Y our Chair is one, and\\nmy Amazon shares have made me wealthy. But more than 7/8ths of the shares, representing $1.4 trillion of\\nwealth creation, are owned by others. Who are they? They’re pension funds, universities, and 401(k)s, and\\nthey’re Mary and Larry, who sent me this note out of the blue just as I was sitting down to write this\\nshareholder letter:\\n', metadata={'year': 2020, 'source': 'AMZN-2020-Shareholder-Letter.pdf'}), Document(page_content='I am approached with similar stories all the time. I know people who’ve used their Amazon money for\\ncollege, for emergencies, for houses, for vacations, to start their own business, for charity – and the list goes\\non. I’m proud of the wealth we’ve created for shareowners. It’s significant, and it improves their lives. But I\\nalso know something else: it’s not the largest part of the value we’ve created.\\nCreate More Than You Consume\\nIf you want to be successful in business (in life, actually), you have to create more than you consume. Y our\\ngoal should be to create value for everyone you interact with. Any business that doesn’t create value for those\\nit touches, even if it appears successful on the surface, isn’t long for this world. It’s on the way out.\\nRemember that stock prices are not about the past. They are a prediction of future cash flows discounted\\nback to the present. The stock market anticipates. I’m going to switch gears for a moment and talk about the\\npast. How much value did we create for shareowners in 2020? This is a relatively easy question to answer\\nbecause accounting systems are set up to answer it. Our net income in 2020 was $21.3 billion. If, instead of\\nbeing a publicly traded company with thousands of owners, Amazon were a sole proprietorship with a single\\nowner, that’s how much the owner would have earned in 2020.\\nHow about employees? This is also a reasonably easy value creation question to answer because we can look\\nat compensation expense. What is an expense for a company is income for employees. In 2020, employees\\nearned $80 billion, plus another $11 billion to include benefits and various payroll taxes, for a total of\\n$91 billion.\\nHow about third-party sellers? We have an internal team (the Selling Partner Services team) that works to\\nanswer that question. They estimate that, in 2020, third-party seller profits from selling on Amazon were\\nbetween $25 billion and $39 billion, and to be conservative here I’ll go with $25 billion.\\nFor customers, we have to break it down into consumer customers and AWS customers.\\nWe’ll do consumers first. We offer low prices, vast selection, and fast delivery, but imagine we ignore all of\\nthat for the purpose of this estimate and value only one thing: we save customers time.\\nCustomers complete 28% of purchases on Amazon in three minutes or less, and half of all purchases are\\nfinished in less than 15 minutes. Compare that to the typical shopping trip to a physical store – driving,\\nparking, searching store aisles, waiting in the checkout line, finding your car, and driving home. Research\\nsuggests the typical physical store trip takes about an hour. If you assume that a typical Amazon purchase\\ntakes 15 minutes and that it saves you a couple of trips to a physical store a week, that’s more than 75\\nhours a year saved. That’s important. We’re all busy in the early 21stcentury.\\nSo that we can get a dollar figure, let’s value the time savings at $10 per hour, which is conservative. Seventy-\\nfive hours multiplied by $10 an hour and subtracting the cost of Prime gives you value creation for each\\nPrime member of about $630. We have 200 million Prime members, for a total in 2020 of $126 billion of value\\ncreation.\\nAWS is challenging to estimate because each customer’s workload is so different, but we’ll do it anyway,\\nacknowledging up front that the error bars are high. Direct cost improvements from operating in the cloud\\nversus on premises vary, but a reasonable estimate is 30%. Across AWS’s entire 2020 revenue of $45 billion,\\nthat 30% would imply customer value creation of $19 billion (what would have cost them $64 billion on\\ntheir own cost $45 billion from AWS). The difficult part of this estimation exercise is that the direct cost\\nreduction is the smallest portion of the customer benefit of moving to the cloud. The bigger benefit is the\\nincreased speed of software development – something that can significantly improve the customer’s\\ncompetitiveness and top line. We have no reasonable way of estimating that portion of customer value\\nexcept to say that it’s almost certainly larger than the direct cost savings. To be conservative here (and\\nremembering we’re really only trying to get ballpark estimates), I’ll say it’s the same and call AWS customer\\nvalue creation $38 billion in 2020.\\nAdding AWS and consumer together gives us total customer value creation in 2020 of $164 billion.', metadata={'year': 2020, 'source': 'AMZN-2020-Shareholder-Letter.pdf'}), Document(page_content='Summarizing:\\nShareholders $21B\\nEmployees $91B\\n3P Sellers $25B\\nCustomers $164B\\nTotal $301B\\nIf each group had an income statement representing their interactions with Amazon, the numbers above\\nwould be the “bottom lines” from those income statements. These numbers are part of the reason why people\\nwork for us, why sellers sell through us, and why customers buy from us. We create value for them. And\\nthis value creation is not a zero-sum game. It is not just moving money from one pocket to another. Draw\\nthe box big around all of society, and you’ll find that invention is the root of all real value creation. And value\\ncreated is best thought of as a metric for innovation.\\nOf course, our relationship with these constituencies and the value we create isn’t exclusively dollars and\\ncents. Money doesn’t tell the whole story. Our relationship with shareholders, for example, is relatively simple.\\nThey invest and hold shares for a duration of their choosing. We provide direction to shareowners\\ninfrequently on matters such as annual meetings and the right process to vote their shares. And even then\\nthey can ignore those directions and just skip voting.\\nOur relationship with employees is a very different example. We have processes they follow and standards\\nthey meet. We require training and various certifications. Employees have to show up at appointed times. Our\\ninteractions with employees are many, and they’re fine-grained. It’s not just about the pay and the benefits.\\nIt’s about all the other detailed aspects of the relationship too.\\nDoes your Chair take comfort in the outcome of the recent union vote in Bessemer? No, he doesn’t. I think\\nwe need to do a better job for our employees. While the voting results were lopsided and our direct\\nrelationship with employees is strong, it’s clear to me that we need a better vision for how we create value for\\nemployees – a vision for their success.\\nIf you read some of the news reports, you might think we have no care for employees. In those reports, our\\nemployees are sometimes accused of being desperate souls and treated as robots. That’s not accurate. They’re\\nsophisticated and thoughtful people who have options for where to work. When we survey fulfillment\\ncenter employees, 94% say they would recommend Amazon to a friend as a place to work.\\nEmployees are able to take informal breaks throughout their shifts to stretch, get water, use the rest room,\\nor talk to a manager, all without impacting their performance. These informal work breaks are in addition to\\nthe 30-minute lunch and 30-minute break built into their normal schedule.\\nWe don’t set unreasonable performance goals. We set achievable performance goals that take into account\\ntenure and actual employee performance data. Performance is evaluated over a long period of time as we\\nknow that a variety of things can impact performance in any given week, day, or hour. If employees are on\\ntrack to miss a performance target over a period of time, their manager talks with them and provides\\ncoaching.\\nCoaching is also extended to employees who are excelling and in line for increased responsibilities. In fact,\\n82% of coaching is positive, provided to employees who are meeting or exceeding expectations. We terminate\\nthe employment of less than 2.6% of employees due to their inability to perform their jobs (and that\\nnumber was even lower in 2020 because of operational impacts of COVID-19).\\nEarth’s Best Employer and Earth’s Safest Place to Work\\nThe fact is, the large team of thousands of people who lead operations at Amazon have always cared deeply\\nfor our hourly employees, and we’re proud of the work environment we’ve created. We’re also proud of the\\nfact that Amazon is a company that does more than just create jobs for computer scientists and people with\\nadvanced degrees. We create jobs for people who never got that advantage.', metadata={'year': 2020, 'source': 'AMZN-2020-Shareholder-Letter.pdf'}), Document(page_content='Despite what we’ve accomplished, it’s clear to me that we need a better vision for our employees’ success.\\nWe have always wanted to be Earth’s Most Customer-Centric Company. We won’t change that. It’s what gotus here. But I am committing us to an addition. We are going to be Earth’s Best Employer and Earth’sSafest Place to Work.\\nIn my upcoming role as Executive Chair, I’m going to focus on new initiatives. I’m an inventor. It’s what I\\nenjoy the most and what I do best. It’s where I create the most value. I’m excited to work alongside the largeteam of passionate people we have in Ops and help invent in this arena of Earth’s Best Employer andEarth’s Safest Place to Work. On the details, we at Amazon are always flexible, but on matters of vision weare stubborn and relentless. We have never failed when we set our minds to something, and we’re not going tofail at this either.\\nWe dive deep into safety issues. For example, about 40% of work-related injuries at Amazon are related to\\nmusculoskeletal disorders (MSDs), things like sprains or strains that can be caused by repetitive motions.MSDs are common in the type of work that we do and are more likely to occur during an employee’s firstsix months. We need to invent solutions to reduce MSDs for new employees, many of whom might beworking in a physical role for the first time.\\nOne such program is WorkingWell – which we launched to 859,000 employees at 350 sites across North\\nAmerica and Europe in 2020 – where we coach small groups of employees on body mechanics, proactivewellness, and safety. In addition to reducing workplace injuries, these concepts have a positive impact onregular day-to-day activities outside work.\\nWe’re developing new automated staffing schedules that use sophisticated algorithms to rotate employees\\namong jobs that use different muscle-tendon groups to decrease repetitive motion and help protect employeesfrom MSD risks. This new technology is central to a job rotation program that we’re rolling out throughout2021.\\nOur increased attention to early MSD prevention is already achieving results. From 2019 to 2020, overall\\nMSDs decreased by 32%, and MSDs resulting in time away from work decreased by more than half.\\nWe employ 6,200 safety professionals at Amazon. They use the science of safety to solve complex problems\\nand establish new industry best practices. In 2021, we’ll invest more than $300 million into safety projects,including an initial $66 million to create technology that will help prevent collisions of forklifts and othertypes of industrial vehicles.\\nWhen we lead, others follow. Two and a half years ago, when we set a $15 minimum wage for our hourly\\nemployees, we did so because we wanted to lead on wages – not just run with the pack – and because webelieved it was the right thing to do. A recent paper by economists at the University of California-Berkeleyand Brandeis University analyzed the impact of our decision to raise our minimum starting pay to $15 perhour. Their assessment reflects what we’ve heard from employees, their families, and the communities theylive in.\\nOur increase in starting wage boosted local economies across the country by benefiting not only our own\\nemployees but also other workers in the same community. The study showed that our pay raise resulted in a4.7% increase in the average hourly wage among other employers in the same labor market.\\nAnd we’re not done leading. If we want to be Earth’s Best Employer, we shouldn’t settle for 94% of\\nemployees saying they would recommend Amazon to a friend as a place to work. We have to aim for 100%.And we’ll do that by continuing to lead on wages, on benefits, on upskilling opportunities, and in otherways that we will figure out over time.\\nIf any shareowners are concerned that Earth’s Best Employer and Earth’s Safest Place to Work might dilute\\nour focus on Earth’s Most Customer-Centric Company, let me set your mind at ease. Think of it this way.If we can operate two businesses as different as consumer ecommerce and AWS, and do both at the highest\\nlevel, we can certainly do the same with these two vision statements. In fact, I’m confident they willreinforce each other.', metadata={'year': 2020, 'source': 'AMZN-2020-Shareholder-Letter.pdf'}), Document(page_content='The Climate Pledge\\nIn an earlier draft of this letter, I started this section with arguments and examples designed to demonstrate\\nthat human-induced climate change is real. But, bluntly, I think we can stop saying that now. Y ou don’t\\nhave to say that photosynthesis is real, or make the case that gravity is real, or that water boils at 100 degrees\\nCelsius at sea level. These things are simply true, as is the reality of climate change.\\nNot long ago, most people believed that it would be good to address climate change, but they also thought\\nit would cost a lot and would threaten jobs, competitiveness, and economic growth. We now know better.\\nSmart action on climate change will not only stop bad things from happening, it will also make our\\neconomy more efficient, help drive technological change, and reduce risks. Combined, these can lead to\\nmore and better jobs, healthier and happier children, more productive workers, and a more prosperous future.\\nThis doesn’t mean it will be easy. It won’t be. The coming decade will be decisive. The economy in 2030 will\\nneed to be vastly different from what it is today, and Amazon plans to be at the heart of the change. We\\nlaunched The Climate Pledge together with Global Optimism in September 2019 because we wanted to\\nhelp drive this positive revolution. We need to be part of a growing team of corporations that understand\\nthe imperatives and the opportunities of the 21stcentury.\\nNow, less than two years later, 53 companies representing almost every sector of the economy have signed\\nThe Climate Pledge. Signatories such as Best Buy, IBM, Infosys, Mercedes-Benz, Microsoft, Siemens, and\\nVerizon have committed to achieve net-zero carbon in their worldwide businesses by 2040, 10 years ahead of\\nthe Paris Agreement. The Pledge also requires them to measure and report greenhouse gas emissions on a\\nregular basis; implement decarbonization strategies through real business changes and innovations; and\\nneutralize any remaining emissions with additional, quantifiable, real, permanent, and socially beneficial\\noffsets. Credible, quality offsets are precious, and we should reserve them to compensate for economic\\nactivities where low-carbon alternatives don’t exist.\\nThe Climate Pledge signatories are making meaningful, tangible, and ambitious commitments. Uber has a\\ngoal of operating as a zero-emission platform in Canada, Europe, and the U.S. by 2030, and Henkel plans to\\nsource 100% of the electricity it uses for production from renewable sources. Amazon is making progress\\ntoward our own goal of 100% renewable energy by 2025, five years ahead of our initial 2030 target. Amazon\\nis the largest corporate buyer of renewable energy in the world. We have 62 utility-scale wind and solar\\nprojects and 125 solar rooftops on fulfillment and sort centers around the globe. These projects have the\\ncapacity to generate over 6.9 gigawatts and deliver more than 20 million megawatt-hours of energy annually.\\nTransportation is a major component of Amazon’s business operations and the toughest part of our plan\\nto meet net-zero carbon by 2040. To help rapidly accelerate the market for electric vehicle technology, and to\\nhelp all companies transition to greener technologies, we invested more than $1 billion in Rivian – and\\nordered 100,000 electric delivery vans from the company. We’ve also partnered with Mahindra in India and\\nMercedes-Benz in Europe. These custom electric delivery vehicles from Rivian are already operational, and\\nthey first hit the road in Los Angeles this past February. Ten thousand new vehicles will be on the road as\\nearly as next year, and all 100,000 vehicles will be on the road by 2030 – saving millions of metric tons of\\ncarbon. A big reason we want companies to join The Climate Pledge is to signal to the marketplace that\\nbusinesses should start inventing and developing new technologies that signatories need to make good on\\nthe Pledge. Our purchase of 100,000 Rivian electric vans is a perfect example.\\nTo further accelerate investment in new technologies needed to build a zero-carbon economy, we introduced\\nthe Climate Pledge Fund last June. The investment program started with $2 billion to invest in visionary\\ncompanies that aim to facilitate the transition to a low-carbon economy. Amazon has already announced\\ninvestments in CarbonCure Technologies, Pachama, Redwood Materials, Rivian, Turntide Technologies,\\nZeroAvia, and Infinium – and these are just some of the innovative companies we hope will build the zero-\\ncarbon economy of the future.\\nI have also personally allocated $10 billion to provide grants to help catalyze the systemic change we will\\nneed in the coming decade. We’ll be supporting leading scientists, activists, NGOs, environmental justice\\norganizations, and others working to fight climate change and protect the natural world. Late last year, I made\\nmy first round of grants to 16 organizations working on innovative and needle-moving solutions. It’s going', metadata={'year': 2020, 'source': 'AMZN-2020-Shareholder-Letter.pdf'}), Document(page_content='to take collective action from big companies, small companies, nation states, global organizations, and\\nindividuals, and I’m excited to be part of this journey and optimistic that humanity can come together to\\nsolve this challenge.\\nDifferentiation is Survival and the Universe Wants You to be Typical\\nThis is my last annual shareholder letter as the CEO of Amazon, and I have one last thing of utmost\\nimportance I feel compelled to teach. I hope all Amazonians take it to heart.\\nHere is a passage from Richard Dawkins’ (extraordinary) book The Blind Watchmaker. It’s about a basic\\nfact of biology.\\n“Staving off death is a thing that you have to work at. Left to itself – and that is what it is when it\\ndies – the body tends to revert to a state of equilibrium with its environment. If you measure some\\nquantity such as the temperature, the acidity, the water content or the electrical potential in a living\\nbody, you will typically find that it is markedly different from the corresponding measure in the\\nsurroundings. Our bodies, for instance, are usually hotter than our surroundings, and in cold climates\\nthey have to work hard to maintain the differential. When we die the work stops, the temperature\\ndifferential starts to disappear, and we end up the same temperature as our surroundings. Not all\\nanimals work so hard to avoid coming into equilibrium with their surrounding temperature, but all\\nanimals do some comparable work. For instance, in a dry country, animals and plants work to\\nmaintain the fluid content of their cells, work against a natural tendency for water to flow from them\\ninto the dry outside world. If they fail they die. More generally, if living things didn’t work actively to\\nprevent it, they would eventually merge into their surroundings, and cease to exist as autonomous\\nbeings. That is what happens when they die.”\\nWhile the passage is not intended as a metaphor, it’s nevertheless a fantastic one, and very relevant to\\nAmazon. I would argue that it’s relevant to all companies and all institutions and to each of our individual\\nlives too. In what ways does the world pull at you in an attempt to make you normal? How much work does it\\ntake to maintain your distinctiveness? To keep alive the thing or things that make you special?\\nI know a happily married couple who have a running joke in their relationship. Not infrequently, the\\nhusband looks at the wife with faux distress and says to her, “Can’t you just be normal?” They both smile\\nand laugh, and of course the deep truth is that her distinctiveness is something he loves about her. But, at the\\nsame time, it’s also true that things would often be easier – take less energy – if we were a little more\\nnormal.\\nThis phenomenon happens at all scale levels. Democracies are not normal. Tyranny is the historical norm. If\\nwe stopped doing all of the continuous hard work that is needed to maintain our distinctiveness in that\\nregard, we would quickly come into equilibrium with tyranny.\\nWe all know that distinctiveness – originality – is valuable. We are all taught to “be yourself.” What I’m\\nreally asking you to do is to embrace and be realistic about how much energy it takes to maintain that\\ndistinctiveness. The world wants you to be typical – in a thousand ways, it pulls at you. Don’t let it happen.\\nY ou have to pay a price for your distinctiveness, and it’s worth it. The fairy tale version of “be yourself” is that\\nall the pain stops as soon as you allow your distinctiveness to shine. That version is misleading. Being\\nyourself is worth it, but don’t expect it to be easy or free. Y ou’ll have to put energy into it continuously.\\nThe world will always try to make Amazon more typical – to bring us into equilibrium with our environment.\\nIt will take continuous effort, but we can and must be better than that.\\n***\\nAs always, I attach our 1997 shareholder letter. It concluded with this: “We at Amazon.com are grateful to\\nour customers for their business and trust, to each other for our hard work, and to our shareholders for their\\nsupport and encouragement.” That hasn’t changed a bit. I want to especially thank Andy Jassy for agreeing\\nto take on the CEO role. It’s a hard job with a lot of responsibility. Andy is brilliant and has the highest', metadata={'year': 2020, 'source': 'AMZN-2020-Shareholder-Letter.pdf'}), Document(page_content='of high standards. I guarantee you that Andy won’t let the universe make us typical. He will muster the\\nenergy needed to keep alive in us what makes us special. That won’t be easy, but it is critical. I also predict it\\nwill be satisfying and oftentimes fun. Thank you, Andy.\\nTo all of you: be kind, be original, create more than you consume, and never, never, never let the universe\\nsmooth you into your surroundings. It remains Day 1.\\nSincerely,\\nJeffrey P . Bezos\\nFounder and Chief Executive Officer\\nAmazon.com, Inc.', metadata={'year': 2020, 'source': 'AMZN-2020-Shareholder-Letter.pdf'})]\n",
      "\n",
      "5 [Document(page_content='To our shareowners:\\nOne thing we’ve learned from the COVID-19 crisis is how important Amazon has become to our customers. We\\nwant you to know we take this responsibility seriously, and we’re proud of the work our teams are doing to helpcustomers through this difficult time.\\nAmazonians are working around the clock to get necessary supplies delivered directly to the doorsteps of people\\nwho need them. The demand we are seeing for essential products has been and remains high. But unlike apredictable holiday surge, this spike occurred with little warning, creating major challenges for our suppliers anddelivery network. We quickly prioritized the stocking and delivery of essential household staples, medicalsupplies, and other critical products.\\nOur Whole Foods Market stores have remained open, providing fresh food and other vital goods for customers.\\nWe are taking steps to help those most vulnerable to the virus, setting aside the first hour of shopping at WholeFoods each day for seniors. We have temporarily closed Amazon Books, Amazon 4-star, and Amazon Pop Upstores because they don’t sell essential products, and we offered associates from those closed stores theopportunity to continue working in other parts of Amazon.\\nCrucially, while providing these essential services, we are focused on the safety of our employees and contractors\\naround the world—we are deeply grateful for their heroic work and are committed to their health and well-being.Consulting closely with medical experts and health authorities, we’ve made over 150 significant process changesin our operations network and Whole Foods Market stores to help teams stay healthy, and we conduct dailyaudits of the measures we’ve put into place. We’ve distributed face masks and implemented temperature checksat sites around the world to help protect employees and support staff. We regularly sanitize door handles,stairway handrails, lockers, elevator buttons, and touch screens, and disinfectant wipes and hand sanitizer arestandard across our network.\\nWe’ve also introduced extensive social distancing measures to help protect our associates. We have eliminated\\nstand-up meetings during shifts, moved information sharing to bulletin boards, staggered break times, and spreadout chairs in breakrooms. While training new hires is challenging with new distancing requirements, we continueto ensure that every new employee gets six hours of safety training. We’ve shifted training protocols so we don’thave employees gathering in one spot, and we’ve adjusted our hiring processes to allow for social distancing.\\nA next step in protecting our employees might be regular testing of all Amazonians, including those showing no\\nsymptoms. Regular testing on a global scale, across all industries, would both help keep people safe and help getthe economy back up and running. For this to work, we as a society would need vastly more testing capacity thanis currently available. If every person could be tested regularly, it would make a huge difference in how we fightthis virus. Those who test positive could be quarantined and cared for, and everyone who tests negative couldre-enter the economy with confidence.\\nWe’ve begun the work of building incremental testing capacity. A team of Amazonians—from research scientists\\nand program managers to procurement specialists and software engineers—moved from their normal day jobsonto a dedicated team to work on this initiative. We have begun assembling the equipment we need to build ourfirst lab and hope to start testing small numbers of our frontline employees soon. We are not sure how far we willget in the relevant timeframe, but we think it’s worth trying, and we stand ready to share anything we learn.', metadata={'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}), Document(page_content='While we explore longer-term solutions, we are also committed to helping support employees now. We increased\\nour minimum wage through the end of April by $2 per hour in the U.S., $2 per hour in Canada, £2 per hour in theUK, and €2 per hour in many European countries. And we are paying associates double our regular rate for any\\novertime worked—a minimum of $34 an hour—an increase from time and a half. These wage increases will costmore than $500 million, just through the end of April, and likely more than that over time. While we recognizethis is expensive, we believe it’s the right thing to do under the circumstances. We also established the AmazonRelief Fund—with an initial $25 million in funding—to support our independent delivery service partners andtheir drivers, Amazon Flex participants, and temporary employees under financial distress.\\nIn March, we opened 100,000 new positions across our fulfillment and delivery network. Earlier this week, after\\nsuccessfully filling those roles, we announced we were creating another 75,000 jobs to respond to customerdemand. These new hires are helping customers who depend on us to meet their critical needs. We know thatmany people around the world have suffered financially as jobs are lost or furloughed. We are happy to havethem on our teams until things return to normal and either their former employer can bring them back or newjobs become available. We’ve welcomed Joe Duffy, who joined after losing his job as a mechanic at Newarkairport and learned about an opening from a friend who is an Amazon operations analyst. Dallas preschoolteacher Darby Griffin joined after her school closed on March 9\\nthand now helps manage new inventory. We’re\\nhappy to have Darby with us until she can return to the classroom.\\nAmazon is acting aggressively to protect our customers from bad actors looking to exploit the crisis. We’ve\\nremoved over half a million offers from our stores due to COVID-based price gouging, and we’ve suspendedmore than 6,000 selling accounts globally for violating our fair-pricing policies. Amazon turned over informationabout sellers we suspect engaged in price gouging of products related to COVID-19 to 42 state attorneys generaloffices. To accelerate our response to price-gouging incidents, we created a special communication channel forstate attorneys general to quickly and easily escalate consumer complaints to us.\\nAmazon Web Services is also playing an important role in this crisis. The ability for organizations to access\\nscalable, dependable, and highly secure computing power—whether for vital healthcare work, to help studentscontinue learning, or to keep unprecedented numbers of employees online and productive from home—is criticalin this situation. Hospital networks, pharmaceutical companies, and research labs are using AWS to care forpatients, explore treatments, and mitigate the impacts of COVID-19 in many other ways. Academic institutionsaround the world are transitioning from in-person to virtual classrooms and are running on AWS to help ensurecontinuity of learning. And governments are leveraging AWS as a secure platform to build out new capabilitiesin their efforts to end this pandemic.\\nWe are collaborating with the World Health Organization, supplying advanced cloud technologies and technical\\nexpertise to track the virus, understand the outbreak, and better contain its spread. WHO is leveraging our cloudto build large-scale data lakes, aggregate epidemiological country data, rapidly translate medical training videosinto different languages, and help global healthcare workers better treat patients. We are separately making apublic AWS COVID-19 data lake available as a centralized repository for up-to-date and curated informationrelated to the spread and characteristics of the virus and its associated illness so experts can access and analyzethe latest data in their battle against the disease.\\nWe also launched the AWS Diagnostic Development Initiative, a program to support customers working to bring\\nmore accurate diagnostic solutions to market for COVID-19. Better diagnostics help accelerate treatment andcontainment of this pandemic. We committed $20 million to accelerate this work and help our customers harnessthe cloud to tackle this challenge. While the program was established in response to COVID-19, we also arelooking toward the future, and we will fund diagnostic research projects that have the potential to blunt futureinfectious disease outbreaks.', metadata={'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}), Document(page_content='Customers around the world have leveraged the cloud to scale up services and stand up responses to COVID-19.\\nWe joined the New York City COVID-19 Rapid Response Coalition to develop a conversational agent to enableat-risk and elderly New Yorkers to receive accurate, timely information about medical and other important needs.In response to a request from the Los Angeles Unified School District to transition 700,000 students to remotelearning, AWS helped establish a call center to field IT questions, provide remote support, and enable staff toanswer calls. We are providing cloud services to the CDC to help thousands of public health practitioners andclinicians gather data related to COVID-19 and inform response efforts. In the UK, AWS provides the cloudcomputing infrastructure for a project that analyzes hospital occupancy levels, emergency room capacity, andpatient wait times to help the country’s National Health Service decide where best to allocate resources. InCanada, OTN—one of the world’s largest virtual care networks—is scaling its AWS-powered video service toaccommodate a 4,000% spike in demand to support citizens as the pandemic continues. In Brazil, AWS willprovide the São Paulo State Government with cloud computing infrastructure to guarantee online classes to1 million students in public schools across the state.\\nFollowing CDC guidance, our Alexa health team built an experience that lets U.S. customers check their risk\\nlevel for COVID-19 at home. Customers can ask, “Alexa, what do I do if I think I have COVID-19?” or “Alexa,what do I do if I think I have coronavirus?” Alexa then asks a series of questions about the person’s symptomsand possible exposure. Based on those responses, Alexa then provides CDC-sourced guidance. We created asimilar service in Japan, based on guidance from the Japanese Ministry of Health, Labor, and Welfare.\\nWe’re making it easy for customers to use Amazon.com or Alexa to donate directly to charities on the front lines\\nof the COVID-19 crisis, including Feeding America, the American Red Cross, and Save the Children. Echo usershave the option to say, “Alexa, make a donation to Feeding America COVID-19 Response Fund.” In Seattle,we’ve partnered with a catering business to distribute 73,000 meals to 2,700 elderly and medically vulnerableresidents in Seattle and King County during the outbreak, and we donated 8,200 laptops to help Seattle PublicSchools students gain access to a device while classes are conducted virtually.\\nBeyond COVID\\nAlthough these are incredibly difficult times, they are an important reminder that what we do as a company can\\nmake a big difference in people’s lives. Customers count on us to be there, and we are fortunate to be able tohelp. With our scale and ability to innovate quickly, Amazon can make a positive impact and be an organizingforce for progress.\\nLast year, we co-founded The Climate Pledge with Christiana Figueres, the UN’s former climate change chief\\nand founder of Global Optimism, and became the first signatory to the pledge. The pledge commits Amazon tomeet the goals of the Paris Agreement 10 years early—and be net zero carbon by 2040. Amazon faces significantchallenges in achieving this goal because we don’t just move information around—we have extensive physicalinfrastructure and deliver more than 10 billion items worldwide a year. And we believe if Amazon can get to netzero carbon ten years early, any company can—and we want to work together with all companies to make it areality.\\nTo that end, we are recruiting other companies to sign The Climate Pledge. Signatories agree to measure and\\nreport greenhouse gas emissions regularly, implement decarbonization strategies in line with the ParisAgreement, and achieve net zero annual carbon emissions by 2040. (We’ll be announcing new signatories soon.)\\nWe plan to meet the pledge, in part, by purchasing 100,000 electric delivery vans from Rivian—a Michigan-\\nbased producer of electric vehicles. Amazon aims to have 10,000 of Rivian’s new electric vans on the road asearly as 2022, and all 100,000 vehicles on the road by 2030. That’s good for the environment, but the promise iseven greater. This type of investment sends a signal to the marketplace to start inventing and developing newtechnologies that large, global companies need to transition to a low-carbon economy.', metadata={'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}), Document(page_content='We’ve also committed to reaching 80% renewable energy by 2024 and 100% renewable energy by 2030. (The\\nteam is actually pushing to get to 100% by 2025 and has a challenging but credible plan to pull that off.)Globally, Amazon has 86 solar and wind projects that have the capacity to generate over 2,300 MW and delivermore than 6.3 million MWh of energy annually—enough to power more than 580,000 U.S. homes.\\nWe’ve made tremendous progress cutting packaging waste. More than a decade ago, we created the Frustration-\\nFree Packaging program to encourage manufacturers to package their products in easy-to-open, 100% recyclablepackaging that is ready to ship to customers without the need for an additional shipping box. Since 2008, thisprogram has saved more than 810,000 tons of packaging material and eliminated the use of 1.4 billion shippingboxes.\\nWe are making these significant investments to drive our carbon footprint to zero despite the fact that shopping\\nonline is already inherently more carbon efficient than going to the store. Amazon’s sustainability scientists havespent more than three years developing the models, tools, and metrics to measure our carbon footprint. Theirdetailed analysis has found that shopping online consistently generates less carbon than driving to a store, since asingle delivery van trip can take approximately 100 roundtrip car journeys off the road on average. Our scientistsdeveloped a model to compare the carbon intensity of ordering Whole Foods Market groceries online versusdriving to your nearest Whole Foods Market store. The study found that, averaged across all basket sizes, onlinegrocery deliveries generate 43% lower carbon emissions per item compared to shopping in stores. Smaller basketsizes generate even greater carbon savings.\\nAWS is also inherently more efficient than the traditional in-house data center. That’s primarily due to two\\nthings—higher utilization, and the fact that our servers and facilities are more efficient than what mostcompanies can achieve running their own data centers. Typical single-company data centers operate at roughly18% server utilization. They need that excess capacity to handle large usage spikes. AWS benefits from multi-tenant usage patterns and operates at far higher server utilization rates. In addition, AWS has been successful inincreasing the energy efficiency of its facilities and equipment, for instance by using more efficient evaporativecooling in certain data centers instead of traditional air conditioning. A study by 451 Research found that AWS’sinfrastructure is 3.6 times more energy efficient than the median U.S. enterprise data center surveyed. Along withour use of renewable energy, these factors enable AWS to do the same tasks as traditional data centers with an88% lower carbon footprint. And don’t think we’re not going to get those last 12 points—we’ll make AWS 100%carbon free through more investments in renewable energy projects.\\nLeveraging scale for good\\nOver the last decade, no company has created more jobs than Amazon. Amazon directly employs 840,000\\nworkers worldwide, including over 590,000 in the U.S., 115,000 in Europe, and 95,000 in Asia. In total, Amazondirectly and indirectly supports 2 million jobs in the U.S., including 680,000-plus jobs created by Amazon’sinvestments in areas like construction, logistics, and professional services, plus another 830,000 jobs created bysmall and medium-sized businesses selling on Amazon. Globally, we support nearly 4 million jobs. We areespecially proud of the fact that many of these are entry-level jobs that give people their first opportunity toparticipate in the workforce.\\nAnd Amazon’s jobs come with an industry-leading $15 minimum wage and comprehensive benefits. More than\\n40 million Americans—many making the federal minimum wage of $7.25 an hour—earn less than the lowest-paid Amazon associate. When we raised our starting minimum wage to $15 an hour in 2018, it had an immediateand meaningful impact on the hundreds of thousands of people working in our fulfillment centers. We want otherbig employers to join us by raising their own minimum pay rates, and we continue to lobby for a $15 federalminimum wage.', metadata={'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}), Document(page_content='We want to improve workers’ lives beyond pay. Amazon provides every full-time employee with health\\ninsurance, a 401(k) plan, 20 weeks paid maternity leave, and other benefits. These are the same benefits thatAmazon’s most senior executives receive. And with our rapidly changing economy, we see more clearly thanever the need for workers to evolve their skills continually to keep up with technology. That’s why we’respending $700 million to provide more than 100,000 Amazonians access to training programs, at their places ofwork, in high-demand fields such as healthcare, cloud computing, and machine learning. Since 2012, we haveoffered Career Choice, a pre-paid tuition program for fulfillment center associates looking to move into high-demand occupations. Amazon pays up to 95% of tuition and fees toward a certificate or diploma in qualifiedfields of study, leading to enhanced employment opportunities in high-demand jobs. Since its launch, more than25,000 Amazonians have received training for in-demand occupations.\\nTo ensure that future generations have the skills they need to thrive in a technology-driven economy, we started a\\nprogram last year called Amazon Future Engineer, which is designed to educate and train low-income anddisadvantaged young people to pursue careers in computer science. We have an ambitious goal: to help hundredsof thousands of students each year learn computer science and coding. Amazon Future Engineer currently fundsIntroduction to Computer Science and AP Computer Science classes for more than 2,000 schools in underservedcommunities across the country. Each year, Amazon Future Engineer also gives 100 four-year, $40,000 collegescholarships to computer science students from low-income backgrounds. Those scholarship recipients alsoreceive guaranteed, paid internships at Amazon after their first year of college. Our program in the UK funds 120engineering apprenticeships and helps students from disadvantaged backgrounds pursue technology careers.\\nFor now, my own time and thinking continues to be focused on COVID-19 and how Amazon can help while\\nwe’re in the middle of it. I am extremely grateful to my fellow Amazonians for all the grit and ingenuity they areshowing as we move through this. You can count on all of us to look beyond the immediate crisis for insights andlessons and how to apply them going forward.\\nReflect on this from Theodor Seuss Geisel:\\n“When something bad happens you have three choices. You can either let it define you, let it\\ndestroy you, or you can let it strengthen you.”\\nI am very optimistic about which of these civilization is going to choose.Even in these circumstances, it remains Day 1. As always, I attach a copy of our original 1997 letter.\\nSincerely,\\nJeffrey P. Bezos\\nFounder and Chief Executive OfficerAmazon.com, Inc.', metadata={'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'})]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "documents = []\n",
    "\n",
    "for idx, file in enumerate(filenames):\n",
    "    loader = PyPDFLoader(data_root + file)\n",
    "    document = loader.load()\n",
    "    for document_fragment in document:\n",
    "        document_fragment.metadata = metadata[idx]\n",
    "        \n",
    "    print(f'{len(document)} {document}\\n')\n",
    "    documents += document\n",
    "\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we are proceeding we are looking into some interesting statistics regarding the document preprocessing we just performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length among 25 documents loaded is 4131 characters.\n",
      "After the split we have 151 documents as opposed to the original 25.\n",
      "Average length among 151 documents (after split) is 699 characters.\n"
     ]
    }
   ],
   "source": [
    "avg_doc_length = lambda documents: sum([len(doc.page_content) for doc in documents])//len(documents)\n",
    "print(f'Average length among {len(documents)} documents loaded is {avg_doc_length(documents)} characters.')\n",
    "print(f'After the split we have {len(docs)} documents as opposed to the original {len(documents)}.')\n",
    "print(f'Average length among {len(docs)} documents (after split) is {avg_doc_length(docs)} characters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy Model for Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections you will need to deploy a set of ML Models, one for Embeddings and a LLM for Language Generation. This example assumes you are working inside of SageMaker studio, so you can deploy them yourself or through SageMaker Jumpstart.\n",
    "\n",
    "For these examples, you will use `All MiniLM L6 v2` as the embedding model, and `LLaMa-2-7B-chat` as the LLM for language generation. \n",
    "\n",
    "__Note:__ If you choose other options, you may have to adjust the `transform_input` and `transform_output` functions in future sections for embedding and llm to match the models you've selected.\n",
    "\n",
    "Refer to the [SageMaker Jumpstart Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html) for details on how to deploy models via Jumpstart.\n",
    "\n",
    "If you already have an embedding endpoint deployed, you can skip the following cell, and modify the `embedding_model_endpoint_name` value to match your endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note: running the following cell will deploy a SageMaker endpoint. You will need to delete the endpoint to stop charges from accumulating. See the clean up step at the end of this notebook.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "embedding_model_id, embedding_model_version = \"huggingface-textembedding-all-MiniLM-L6-v2\", \"*\"\n",
    "model = JumpStartModel(model_id=embedding_model_id, model_version=embedding_model_version)\n",
    "embedding_predictor = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this is the model endpoint NAME, not the ARN\n",
    "embedding_model_endpoint_name = embedding_predictor.endpoint_name\n",
    "embedding_model_endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use your SageMaker model endpoints, you need to have a set of credentials. This section will assume them from your SageMaker Studio session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "aws_region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Populating the Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you need to set up how to process the embeddings for the input documents.\n",
    "\n",
    "The provided CustomEmbeddingsContentHandler class has a set of functions, transform_input and transform_output, for porcessing data going into and out of the embedding model.\n",
    "\n",
    "With the content handler defined, you will then use the SageMakerEndpointEmbeddings class from LangChain to create an embeddings object that corresponds to your hosted embeddings model along with the appropriate content handler for processing its inputs/outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "import json\n",
    "\n",
    "\n",
    "class CustomEmbeddingsContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"embedding\"]\n",
    "\n",
    "\n",
    "embeddings_content_handler = CustomEmbeddingsContentHandler()\n",
    "\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddings(\n",
    "    endpoint_name=embedding_model_endpoint_name,\n",
    "    region_name=aws_region,\n",
    "    content_handler=embeddings_content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir data\n",
    "\n",
    "# from urllib.request import urlretrieve\n",
    "# files = [\n",
    "#     'https://www.irs.gov/pub/irs-pdf/p1544.pdf',\n",
    "#     'https://www.irs.gov/pub/irs-pdf/p15.pdf',\n",
    "#     'https://www.irs.gov/pub/irs-pdf/p1212.pdf'\n",
    "# ]\n",
    "# for url in files:\n",
    "#     file_path = './data/' + url.split('/')[-1]\n",
    "#     urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading we can load the documents with the help of [DirectoryLoader from PyPDF available under LangChain](https://python.langchain.com/en/latest/reference/modules/document_loaders.html) and splitting them into smaller chunks.\n",
    "\n",
    "Note: The retrieved document/text should be large enough to contain enough information to answer a question; but small enough to fit into the LLM prompt. Also the embeddings model has a limit of the length of input tokens limited to 512 tokens, which roughly translates to ~2000 characters. For the sake of this use-case we are creating chunks of roughly 1000 characters with an overlap of 100 characters using [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had 3 PDF documents which have been split into smaller ~500 chunks.\n",
    "\n",
    "Now we can see how a sample embedding would look like for one of those chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_embedding = np.array(embeddings.embed_query(docs[0].page_content))\n",
    "np.array(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "The below function will establish a connection with OpenSearch Serverless, create a new index, create embeddings for the documents and then store the embeddings in OpenSearch serverless. For details on documentation refer this link: https://python.langchain.com/docs/integrations/vectorstores/opensearch\n",
    "\n",
    "*Note: Wait for a minute or two after the below command to excute, before the new index can be queried.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO - Direct langchain integration with version 0.0.245 gives timeout error, therefore, commenting the following code. \n",
    "\n",
    "# from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "# docsearch = OpenSearchVectorSearch.from_documents(\n",
    "#     docs,\n",
    "#     bedrock_embeddings,\n",
    "#     opensearch_url=host,\n",
    "#     http_auth=awsauth,\n",
    "#     timeout = 300,\n",
    "#     use_ssl = True,\n",
    "#     verify_certs = True,\n",
    "#     connection_class = RequestsHttpConnection,\n",
    "#     index_name=\"bedrock-aos-irs-index2\",\n",
    "#     engine=\"faiss\",\n",
    "#     bulk_size=len(docs)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = \"sagemaker-opensearch-serverless-demo\"\n",
    "vector_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a new index\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True\n",
    "  },\n",
    "  'mappings': {\n",
    "    'properties': {\n",
    "      \"title\": { \"type\": \"text\", \"fields\": { \"keyword\": { \"type\": \"keyword\" } } }, #the field will be title.keyword and the data type will be keyword, this will act as sub field for\n",
    "      \"v_title\": { \"type\": \"knn_vector\", \"dimension\": vector_size },\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "client.indices.create(\n",
    "  index=index_name, \n",
    "  body=index_body\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# python code to view schema for OpenSearch Serverless. \n",
    "client.indices.get_mapping(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actions =[]\n",
    "bulk_size = 0\n",
    "action = {\"index\": {\"_index\": index_name}}\n",
    "\n",
    "\n",
    "# # Prepare bulk request\n",
    "# actions.append(action)\n",
    "# actions.append(json_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bulk API to ingest documents in OSS.\n",
    "# it will take about 5 mins to ingest the 503 vectors\n",
    "for document in docs: \n",
    "    sample_embedding = np.array(embeddings.embed_query(document.page_content))\n",
    "    actions.append(action)\n",
    "    json_data = {\n",
    "             \"title\" : document.page_content,\n",
    "            \"v_title\" : sample_embedding\n",
    "        }\n",
    "    actions.append(json_data)\n",
    "    bulk_size+=1\n",
    "    if(bulk_size > 200 ):\n",
    "        client.bulk(body=actions)\n",
    "        print(f\"bulk request sent with size: {bulk_size}\")\n",
    "        bulk_size = 0\n",
    "\n",
    "#ingest remaining documents\n",
    "print(\"remaining documents: \", bulk_size)\n",
    "client.bulk(body=actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the similar pattern embeddings could be generated for the entire corpus and stored in a vector store.\n",
    "**⚠️⚠️⚠️ NOTE: it might take few minutes to run the following cell ⚠️⚠️⚠️**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Answering\n",
    "\n",
    "Now that we have our vector store in place, we can start asking questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"Is it possible that I get sentenced to jail due to failure in filings?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step would be to create an embedding of the query such that it could be compared with the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_embedding = np.array(bedrock_embeddings.embed_query(query))\n",
    "np.array(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_os = {\n",
    "  \"size\": 3,\n",
    "  \"fields\": [\"title\"],\n",
    "  \"_source\": False,\n",
    "  \"query\": {\n",
    "    \"knn\": {\n",
    "      \"v_title\": {\n",
    "        \"vector\": query_embedding,\n",
    "        \"k\": vector_size\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "relevant_documents = client.search(\n",
    "body = query_os,\n",
    "index = index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relevant_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this embedding of the query to then fetch relevant documents.\n",
    "Now our query is represented as embeddings we can do a similarity search of our query against our data store providing us with the most relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(relevant_documents[\"hits\"][\"hits\"]))\n",
    "print(\"--------------------\")\n",
    "context = \" \"\n",
    "for i, rel_doc in enumerate(relevant_documents[\"hits\"][\"hits\"]):\n",
    "    print_ww(f'## Document {i+1}: {relevant_documents[\"hits\"][\"hits\"][i][\"fields\"][\"title\"][0]}.......')\n",
    "    print('---')\n",
    "    context += relevant_documents[\"hits\"][\"hits\"][i][\"fields\"][\"title\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"maxTokenCount\":512,\n",
    "    \"stopSequences\":[],\n",
    "    \"temperature\":0,\n",
    "    \"topP\":0.9\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data_claude = f\"\"\"Human: Answer the question based only on the information provided. If the answer is not in the context, say \"I don't know, answer not found in the documents. Provide quote from the document.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "<question>\n",
    "{query}\n",
    "</question>\n",
    "Assistant:\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_text_claude = claude_llm(prompt_data_claude)\n",
    "\n",
    "print (\"########## Ouput from Claude Model #################\\n\")\n",
    "print(output_text_claude)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data_titan = f\"\"\"Answer the below question based on the context provided. If the answer is not in the context, say \"I don't know, answer not found in the documents\".\n",
    "{context}\n",
    "{query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_text_titan = titan_llm(prompt_data_titan)\n",
    "print (\"########## Ouput from Titan Model ################\\n\")\n",
    "print(output_text_titan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this moduel on retrieval augmented generation! This is an important technique that combines the power of large language models with the precision of retrieval methods. By augmenting generation with relevant retrieved examples, the responses we recieved become more coherent, consistent and grounded. You should feel proud of learning this innovative approach. I'm sure the knowledge you've gained will be very useful for building creative and engaging language generation systems. Well done!\n",
    "\n",
    "In the above implementation of RAG based Question Answering we have explored the following concepts and how to implement them using Amazon Bedrock and it's LangChain integration.\n",
    "\n",
    "- Loading documents and generating embeddings to create a vector store\n",
    "- Retrieving documents to the question\n",
    "- Preparing a prompt which goes as input to the LLM\n",
    "- Present an answer in a human friendly manner\n",
    "\n",
    "### Take-aways\n",
    "- Experiment with different Vector Stores\n",
    "- Leverage various models available under Amazon Bedrock to see alternate outputs\n",
    "- Explore options such as persistent storage of embeddings and document chunks\n",
    "- Integration with enterprise data stores\n",
    "\n",
    "# Thank You"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
