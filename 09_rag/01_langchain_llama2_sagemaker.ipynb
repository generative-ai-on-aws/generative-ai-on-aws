{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e85f55-9a35-4d97-9917-bef3f6e8a627",
   "metadata": {},
   "source": [
    "# 랭체인을 활용한 검색 증강 생성(Retrieval Augmented Generation; RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89353535-16f4-438a-8613-be3d698f0a96",
   "metadata": {},
   "source": [
    "이 노트북 예제에서는 아마존사의 주주서한 데이터를 활용한 RAG를 실행하여 기본적인 Q&A를 실행 해보겠습니다.\n",
    "\n",
    "이 노트북은 특별한 CPU/GPU 사양이 필요없으며, '파이썬 3 데이터사이언스 3.0' 커널을 통해 빌드되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335cbce-a8a6-443d-804b-c6bc4d0d8c54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 의존성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174bd3f-7ea6-4e40-9617-a7d263cc0f11",
   "metadata": {},
   "source": [
    "이 예제를 위한 의존성 설치:\n",
    "- 랭체인: RAG 워크플로를 오케스트레이션하기 위한 프레임워크\n",
    "- FAISS: 문서 임베딩을 저장하기 위한 인메모리 벡터 데이터베이스\n",
    "- PyPDF: PDF 문서를 처리하기 위한 파이썬 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e49456-bad8-40b3-b266-87a3935f7aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.0.309 --quiet --root-user-action=ignore\n",
    "%pip install faiss-cpu==1.7.4 --quiet --root-user-action=ignore\n",
    "%pip install pypdf==3.15.1 --quiet --root-user-action=ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582419ab-471e-4bdf-8b6a-a49c57f2a882",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 샘플 데이터 수집과 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8063d9f-0c5d-4e33-9e01-dce73b45c2ab",
   "metadata": {},
   "source": [
    "다음으로, 이 예제를 위한 샘플 데이터를 가져옵니다. 이 섹션에서는 매년 아마존사의 \"연간 리뷰 (Year in Review)\"로 제공되는 공개적으로 이용 가능한 아마존사 주주서한을 다운로드합니다.\n",
    "\n",
    "PDF 파일을 로컬로 다운로드하여 이 노트북의 `data` 디렉토리에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb4b3c4-4eea-4a4e-87cc-2401830ef953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./data\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "metadata = [\n",
    "    dict(year=2022, source=filenames[0]),\n",
    "    dict(year=2021, source=filenames[1]),\n",
    "    dict(year=2020, source=filenames[2]),\n",
    "    dict(year=2019, source=filenames[3])]\n",
    "\n",
    "data_root = \"./data/\"\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root + filenames[idx]\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1137c-ecfa-4d54-ba0e-843de52c1c5b",
   "metadata": {},
   "source": [
    "아마존사의 독특한 문화로, CEO는 항상 현재의 주주들에게 보내는 편지에 1997년의 원본 편지를 첨부합니다. 처리해야 할 양을 줄이고 해당 연도에 대한 편향을 줄이며 출력 품질을 개선하기 위해, PyPDF를 사용하여 각 파일에서 해당 페이지를 제거한 후 원본 파일에 덮어쓰겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d1ff002-8c3e-4c19-92b4-d333b9919fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pypdf import PdfReader, PdfWriter\n",
    "import glob\n",
    "\n",
    "local_pdfs = glob.glob(data_root + '*.pdf')\n",
    "\n",
    "for local_pdf in local_pdfs:\n",
    "    pdf_reader = PdfReader(local_pdf)\n",
    "    pdf_writer = PdfWriter()\n",
    "    for pagenum in range(len(pdf_reader.pages)-3):\n",
    "        page = pdf_reader.pages[pagenum]\n",
    "        pdf_writer.add_page(page)\n",
    "\n",
    "    with open(local_pdf, 'wb') as new_file:\n",
    "        new_file.seek(0)\n",
    "        pdf_writer.write(new_file)\n",
    "        new_file.truncate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7c20b-45c3-4de5-8352-bb8991074a4d",
   "metadata": {},
   "source": [
    "이제 작업할 수 있는 정리된 PDF 파일이 준비되었으므로, RAG 워크플로 상에서 LLM에 가장 관련 있는 섹션을 제공할 수 있도록 이를 적절한 크기로 분할해야 합니다. 여기에서는 모든 문서를 반복 처리하여 512자 크기로 나누고, 100자씩 곂쳐서 분할합니다.\n",
    "\n",
    "`chunk_size`는 임베딩되어 벡터 데이터베이스에 저장될 청크의 크기를 나타냅니다. \n",
    "'chunk_size' dictates the size of the documents that will be embedded and stored in the vector database.\n",
    "\n",
    "`chunk_overlap`은 청크를 분리할때 이전 청크에서 중복해서 사용된 테스트의 양을 나타냅니다. 이는 청크간 맥락을 유지할 수 있도록 해줍니다.\n",
    "\n",
    "`RecursiveCharacterTextSplitter`는 `[\"\\n\\n\", \"\\n\", \" \", \"\"]`와 같은 구분자를 사용하여 원하는 청크 크기가 만들어질때까지 반복적으로 분할하려고 시도합니다. 이러한 시도는 문단/문장/단어를 유지함으로써 더 나은 의도분석을 가능하게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd66b0d4-dc7e-4283-a7f7-e1b793f0dc4a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Document Pages 25\n",
      "# of Document Chunks: 299\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "documents = []\n",
    "\n",
    "for idx, file in enumerate(filenames):\n",
    "    loader = PyPDFLoader(data_root + file)\n",
    "    document = loader.load()\n",
    "    for document_fragment in document:\n",
    "        document_fragment.metadata = metadata[idx]\n",
    "        \n",
    "    documents += document\n",
    "\n",
    "# - 테스트 결과 PDF 데이터셋에서 텍스트 분리가 잘됨\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # 내용을 보기위해 매우 작은 청크사이즈로 설정\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f'# of Document Pages {len(documents)}')\n",
    "print(f'# of Document Chunks: {len(docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e640ff1f-b6c5-48ae-86ab-a69b629f7c1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 임베딩 모델 배포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f48b4-0155-46e4-9165-b8faf5d70096",
   "metadata": {},
   "source": [
    "다음 섹션에서는 ML모델 세트를 배포하게 되는데, 하나는 임베딩을 위한것이고, 다른 하나는 언어 생성을 위한 LLM입니다. 이 예제는 SageMaker Studio 내에서 작업하고 있다고 가정하며, 직접 배포하거나 SageMaker Jumpstart를 통해 배포할 수 있습니다.\n",
    "\n",
    "이 예제에서는 임베딩 모델로 `All MiniLM L6 v2`를 사용하고, 언어 생성을 위한 LLM으로 `LLaMa-2-7B-chat`을 사용할 것입니다.e generation. \n",
    "\n",
    "__노트:__ 다른 옵션을 선택할 경우, 선택한 모델과 임베딩 및 LLM을 맞추기 위해 이후 섹션의 `transform_input`과 `transform_output` 함수를 조정해야 할 수도 있습니다.\n",
    "\n",
    "점프스타트로 모델을 배포하는 방법에 대해서는 [세이지메이커 점프스타트 문서](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html)를 참고하세요.\n",
    "\n",
    "만약 이미 배포된 임베딩 엔드포인트가 있다면 다음 셀은 넘어가도 되며, `embedding_model_endpoint_name` 값만 엔드포인트에 맞춰서 수정하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59583752-0a04-4fda-a3fa-3d30be3c4df5",
   "metadata": {},
   "source": [
    "__노트: 다음 셀을 실행하면 세이지메이커 엔드포인트를 배포하게 됩니다. 과도한 과금을 피하기 위해서는 테스트 후 엔드포인트를 삭제해야 합니다. 이 노트북 마지막에 있는 클린업 단계를 살펴 보세요.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c44af9-fb91-4773-bc5f-c8d7459db772",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'huggingface-textembedding-all-MiniLM-L6-v2' with wildcard version identifier '*'. You can pin to version '1.0.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "embedding_model_id, embedding_model_version = \"huggingface-textembedding-all-MiniLM-L6-v2\", \"*\"\n",
    "model = JumpStartModel(model_id=embedding_model_id, model_version=embedding_model_version)\n",
    "embedding_predictor = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e75dcdf-141a-4e2a-8e1b-1b1e039bb907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hf-textembedding-all-minilm-l6-v2-2023-12-26-20-58-21-407'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ARN이 아니라 모델 엔드포인트 이름임\n",
    "embedding_model_endpoint_name = embedding_predictor.endpoint_name\n",
    "embedding_model_endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84cacf-fffe-4500-ace2-bef19b7694e3",
   "metadata": {},
   "source": [
    "세이지메이커 모델 엔드포인트를 사용하려면 자격증명이 필요합니다. 이번 섹션에서는 SageMaker Studio 세션으로 가정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd7c3fa-0c39-4876-925f-ee3918e9bdb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "aws_region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7696e9d-1d95-45fb-b575-76018d08e2ac",
   "metadata": {},
   "source": [
    "## 벡터 데이터베이스 생성과 데이터 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70bd413-4a32-4ab9-92d4-1bcfd6854933",
   "metadata": {},
   "source": [
    "다음으로 입력된 문서에 대한 임베딩을 처리하는 방법을 설정해야 합니다.\n",
    "\n",
    "제공된 CustomEmbeddingsContentHandler 클래스에는 임베딩 모델로 들어가고 나오는 데이터를 처리하기 위한 transform_input과 transform_output 함수가 포함되어 있습니다.\n",
    "\n",
    "콘텐츠 핸들러를 정의한 후에는 랭체인의 SageMakerEndpointEmbeddings 클래스를 사용하여, 호스팅된 임베딩 모델과 입력/출력을 처리할 적절한 콘텐츠 핸들러로 임베딩 객체를 생성하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5aa464-6e62-4e4f-83aa-ea08545a93d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "import json\n",
    "\n",
    "\n",
    "class CustomEmbeddingsContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"embedding\"]\n",
    "\n",
    "\n",
    "embeddings_content_handler = CustomEmbeddingsContentHandler()\n",
    "\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddings(\n",
    "    endpoint_name=embedding_model_endpoint_name,\n",
    "    region_name=aws_region,\n",
    "    content_handler=embeddings_content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c536f-4a3d-423a-8711-d3aed5f7a08c",
   "metadata": {},
   "source": [
    "임베딩이 준비되면 다음 단계는 문서 청크를 벡터로 만들어 어딘가에 저장하는 것입니다. 이 예제는 FAISS 인메모리 벡터 데이터베이스를 사용하지만 다른 여러가지 다른 옵션들도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6feb6fba-9e9e-4880-860a-2c0c8f61c9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a2b4c55-056e-4922-a7fa-4786b0d1dbcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a7597-abc0-4a14-8d6e-810893ff4a78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 벡터 쿼리 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bae5fdb-6881-4b9d-ba42-ed07f980183e",
   "metadata": {},
   "source": [
    "이제 벡터 데이터베이스가 만들어졌으니, 관련된 문서 청크를 찾기위해 쿼리를 실행할 수 있습니다. \n",
    "\n",
    "자료에 대한 단순한 쿼리부터 시작해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b119c2c4-3dbe-41a0-87d2-1b85fcb0abb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"How has AWS evolved?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8897cbb-7ce8-4b37-bb30-41d1c8ea887b",
   "metadata": {
    "tags": []
   },
   "source": [
    "`similarity_search_with_score` API에서 받은 결과는 점수의 오름차순으로 정렬됩니다. 점수값은 각 결과의 [L-squared (or L2)](https://en.wikipedia.org/wiki/Lp_space) 거리로 표현됩니다. 더 작은 점수가 더 좋은, 즉 벡터간 거리가 짧은 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2a0069d-d864-49d4-90eb-c588fba0f9b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.5685306191444397\n",
      "\n",
      "\n",
      "Content: customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launchedin 2022), and invest in long-term inventions that change what’s possible.\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.7789842486381531\n",
      "\n",
      "\n",
      "Content: We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.7893760204315186\n",
      "\n",
      "\n",
      "Content: back and determining what they wanted to change coming out of the pandemic. Many concludedthat they didn’t want to continue managing their technology infrastructure themselves, and made thedecision to accelerate their move to the cloud. This shift by so many companies (along with the economyrecovering) helped re-accelerate AWS’s revenue growth to 37% Y oY in 2021.\n",
      "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
      "Score: 0.7898486852645874\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_with_scores = db.similarity_search_with_score(query)\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff8e58e5-baff-4d2f-b3d7-614016b13f74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.5685306191444397\n",
      "\n",
      "\n",
      "Content: customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launchedin 2022), and invest in long-term inventions that change what’s possible.\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.7789842486381531\n",
      "\n",
      "\n",
      "Content: We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.7893760204315186\n",
      "\n",
      "\n",
      "Content: much as cost-optimizing so they can take their resources and apply them to emerging and inventive new customerexperiences they’re planning. Customers have appreciated this customer-focused, long-term approach, andwe think it’ll bode well for both customers and AWS.\n",
      "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "Score: 0.8272767066955566\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter={\"year\": 2022}\n",
    "\n",
    "results_with_scores = db.similarity_search_with_score(query,\n",
    "  filter=filter)\n",
    "\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9bd43-f485-4acd-bf4a-aa2661f3ad2b",
   "metadata": {},
   "source": [
    "## 프롬프트 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad27408-6e86-4469-88d9-410c8784c6f9",
   "metadata": {},
   "source": [
    "벡터 데이터베이스에서 결과를 얻었지만, 현재는 원본 문서의 청크일 뿐이며, 그 중 일부는 원래 쿼리에 대한 답변으로 제공하고자 하는 정보를 포함하지 않을 수도 있습니다.\n",
    "\n",
    "적절한 답변을 생성하기 위해, 원래 질문과 벡터 데이터베이스에서 가져온 관련 청크를 사용하여 언어 생성 모델로부터 새로운 응답을 생성하는 프롬프트 템플릿을 활용할 것입니다.\n",
    "\n",
    "랭체인은 프롬프트 템플릿을 더 쉽게 생성할 수 있는 기능을 제공합니다. 아래 템플릿은 LLaMa-2-chat에 대한 특정 마크업을 포함하고 있으며, 템플릿을 채우기위해 제공하는 `{context}`와 `{question}` 위치 표시자를 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80de40d9-4525-4e6a-8af0-f4a567a8fc5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "Use the context provided to answer the question at the end. If you dont know the answer just say that you don't know, don't try to make up an answer.\n",
    "<</SYS>>\n",
    "\n",
    "Context:\n",
    "----------------\n",
    "{context}\n",
    "----------------\n",
    "\n",
    "Question: {question} [/INST]\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7a714-e1bc-4c75-8316-c56a47a21353",
   "metadata": {},
   "source": [
    "## LLM 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e7a61-132a-4b1f-ba39-5b9e2d577141",
   "metadata": {},
   "source": [
    "다음 단계는 임베딩 모델을 위해 앞서 수행한 것과 유사한 작업이지만 이번에는 LLM에 대한 것입니다.\n",
    "\n",
    "QAContentHandler 클래스에는 LLM의 입력과 출력을 처리하는 `transform_input`과 `transform_output` 함수가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "949f5a8a-581d-43a6-8c1d-2a7eb998dbf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from langchain import PromptTemplate, SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "import json\n",
    "\n",
    "\n",
    "class QAContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps(\n",
    "            {\"inputs\" : [\n",
    "                [\n",
    "                    {\n",
    "                        \"role\" : \"system\",\n",
    "                        \"content\" : \"\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\" : \"user\",\n",
    "                        \"content\" : prompt\n",
    "                    }\n",
    "                ]],\n",
    "                \"parameters\" : {**model_kwargs}\n",
    "            })\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generation\"][\"content\"]\n",
    "\n",
    "qa_content_handler = QAContentHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065bc98-ddd4-4c2d-bb92-8572f7483c63",
   "metadata": {},
   "source": [
    "이제 언어 생성 LLM을 위한 세이지메이커 엔드포인트를 배포할 것입니다. 이후, 해당 엔드포인트를 가리키는 객체를 생성하고, 엔드포인트와 모델에 추론 매개변수를 제공하게 됩니다.\n",
    "\n",
    "이미 배포된 LLM 엔드포인트가 있다면, 다음 셀은 넘어가도 되며 `llm_model_endpoint_name` 값을 엔드포인트와 맞는 값으로 수정해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386fdd6-7aee-4cde-a601-521007b31c3c",
   "metadata": {},
   "source": [
    "__Note: 다음 셀을 실행하면 세이지메이커 엔드포인트를 배포하는데 수 분이 걸립니다. 과도한 과금을 피하기 위해서는 테스트 후 엔드포인트를 삭제해야 합니다. 이 노트북 마지막에 있는 클린업 단계를 살펴 보세요.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f21bd6-2616-4c54-8e61-7f587861e94e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_model_id, llm_model_version = \"meta-textgeneration-llama-2-7b-f\", \"2.*\"\n",
    "llm_model = JumpStartModel(model_id=llm_model_id, model_version=llm_model_version)\n",
    "llm_predictor = llm_model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b369788d-da6f-4f55-8b5f-10a82fe7e7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-textgeneration-llama-2-7b-f-2023-12-26-21-03-42-236'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ARN이 아니라 모델 엔드포인트 이름임\n",
    "llm_model_endpoint_name = llm_predictor.endpoint_name\n",
    "llm_model_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fe31a83-9892-4751-b6d9-30c69a3ef0f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = SagemakerEndpoint(\n",
    "        endpoint_name=llm_model_endpoint_name,\n",
    "        region_name=aws_region,\n",
    "        model_kwargs={\"max_new_tokens\": 1000, \"top_p\": 0.9, \"temperature\": 1e-11},\n",
    "        endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
    "        content_handler=qa_content_handler\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0594e6-0c4d-4564-9da6-74e5b8b44b91",
   "metadata": {},
   "source": [
    "기본적인 응답을 받기위해서는 어떠한 맥락 정보도 없이 LLM 객체를 직접 호출할 수도 있습니다. `AWS가 어떻게 발전해 왔는가?`라는 질문에 대한 답변에 AWS가 내부적인 관점에서 어떻게 발전했는지 보다는 __무엇__ 을 했는지에 대한 내용이 주를 이룬다는 것을 알 수 있습니다. 이는 LLM을 훈련한 데이터 집합에 인터넷에서 수집된 많은 기사들이 포함되어 있기 때문일 가능성이 큽니다.\n",
    "\n",
    "이 답변이 결코 나쁜 것은 아니지만, 기대했던 답변과는 다를 수 있습니다.\n",
    "\n",
    "그럼 콘텍스트가 어떻게 답변을 개선시킬 수 있는지 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab06b378-162d-41c7-bac3-80fae801d1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" AWS (Amazon Web Services) has evolved significantly since its launch in 2006. Here are some key milestones and developments in AWS's evolution:\\n\\n1. 2006: Amazon Web Services (AWS) is launched as a separate business unit within Amazon, offering a limited set of cloud computing services, including Elastic Compute Cloud (EC2), Simple Storage Service (S3), and Simple Queue Service (SQS).\\n2. 2008: AWS introduces its first virtual private cloud (VPC), allowing customers to launch AWS resources in a dedicated virtual network.\\n3. 2010: AWS launches its first data center outside of the United States, in Ireland.\\n4. 2011: AWS introduces the Elastic Block Store (EBS), providing block-level storage volumes for EC2 instances.\\n5. 2012: AWS launches its CloudFormation service, allowing customers to define and manage AWS infrastructure using templates.\\n6. 2013: AWS introduces the Amazon Elastic Container Service (ECS), providing a highly scalable, high-performance container orchestration service.\\n7. 2014: AWS launches its first data center in Asia, in Singapore.\\n8. 2015: AWS introduces the Amazon Elastic Container Service for Kubernetes (EKS), providing a managed service for deploying and managing containerized applications using Kubernetes.\\n9. 2016: AWS launches its first data center in Australia, in Sydney.\\n10. 2017: AWS introduces the Amazon Neptune database service, providing a highly scalable, fully managed graph database service.\\n11. 2018: AWS launches its first data center in India, in Mumbai.\\n12. 2019: AWS introduces the Amazon SageMaker machine learning platform, providing a fully managed service for building, training, and deploying machine learning models.\\n13. 2020: AWS launches its first data center in South Africa, in Johannesburg.\\n\\nIn addition to these major milestones, AWS has continued to expand its service offerings and capabilities, including the introduction of new services such as AWS Lambda, AWS Glue, and AWS Transfer for FSx. AWS has also continued to invest in its infrastructure, expanding its global footprint and adding new regions and availability zones to its network.\\n\\nOverall, AWS has evolved from a small set of cloud computing services to a comprehensive cloud platform offering a wide range of services and capabilities, including computing, storage, database, analytics, machine learning, and more. AWS has established itself as a leader in the cloud computing market and continues to innovate and expand its offerings to meet the growing demands of its customers.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How has AWS evolved?\"\n",
    "llm.predict(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ea03c-83fb-4ef4-a4cb-cc6d3b26c2c3",
   "metadata": {},
   "source": [
    "생성한 LLM 엔드포인트 객체를 통해 첫번째 체인을 생성할 준비가 되었습니다.\n",
    "\n",
    "이 체인은 랭체인의 RetrievalQA 체인을 사용한 간단한 예제입니다: \n",
    "- 입력으로 쿼리를 받습니다.\n",
    "- 쿼리 임베딩을 생성합니다.\n",
    "- 쿼리 임베딩과 관련된 문서 청크를 벡터 데이터베이스에서 찾습니다.\n",
    "- 콘텍스트와 원본 쿼리를 프롬프트 템플릿에 입력합니다.\n",
    "- 완성된 프롬프트로 LLM을 호출합니다.\n",
    "- LLM 결과를 리턴합니다.\n",
    "\n",
    "[`stuff` 체인 유형](https://python.langchain.com/docs/modules/chains/document/stuff)은 단순히 컨텍스트 문서를 프롬프트에 삽입합니다.\n",
    "\n",
    "`return_source_documents`를 `True`로 설정함으로써, LLM 응답에 벡터 데이터베이스에서 가져온 문서 청크도 포함하어, 컨텍스트가 어디에서 왔는지 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6565df76-1c3f-4d5a-a78d-928766d6586b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=db.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78919b-9019-4a06-95b2-c209fbdce562",
   "metadata": {
    "tags": []
   },
   "source": [
    "이제 체인이 준비되었으니 쿼리를 전달하여 원천 문서를 기반으로 답변이 생성되도록 할 수 있습니다. \n",
    "\n",
    "몇가지 예제가 제공됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "473c77f3-a42f-407f-9231-07b2bb71fc76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How has AWS evolved?\n",
      "\n",
      "Result:  Based on the provided context, AWS has evolved in the following ways:\n",
      "\n",
      "1. Rapid innovation: AWS continues to deliver new capabilities rapidly, launching over 3,300 new features and services in 2022 alone.\n",
      "2. Long-term investment: AWS has made a long-term decision to continue investing in its infrastructure, even during challenging times such as the 2008-2009 recession.\n",
      "3. Expansion of services: AWS has expanded its offerings beyond just computing and storage, now providing a wide range of services including analytics, machine learning, and security.\n",
      "4. Increased profitability: Despite continued investment in innovation, AWS has achieved strong profitability, with an $85B annual revenue run rate business.\n",
      "5. Shift to cloud adoption: The pandemic has accelerated the shift to cloud adoption, with many companies deciding to move their technology infrastructure to the cloud. This has helped re-accelerate AWS's revenue growth to 37% YoY in 2021.\n",
      "\n",
      "Overall, AWS has evolved from a niche player in the cloud computing market to a dominant force, with a strong track record of innovation and investment in its infrastructure.\n",
      "\n",
      "Context Documents: \n",
      "page_content='done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launchedin 2022), and invest in long-term inventions that change what’s possible.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='back and determining what they wanted to change coming out of the pandemic. Many concludedthat they didn’t want to continue managing their technology infrastructure themselves, and made thedecision to accelerate their move to the cloud. This shift by so many companies (along with the economyrecovering) helped re-accelerate AWS’s revenue growth to 37% Y oY in 2021.' metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How has AWS evolved?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "      print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8ba6252-103e-4d12-936f-4ce91f139aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=db.as_retriever(\n",
    "        search_type=\"mmr\", # 최대 한계 관련성 (Maximum Marginal Relevance; MMR)\n",
    "        search_kwargs={\"k\": 3, \"lambda_mult\": 0.1}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d2e45-eb62-4790-81c1-ece18f4b7151",
   "metadata": {
    "tags": []
   },
   "source": [
    "다시 체인이 준비되었으니 쿼리를 전달하여 원천 문서를 기반으로 답변이 생성되도록 할 수 있습니다. \n",
    "\n",
    "몇가지 예제가 제공됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4816efb-1d74-433b-adaa-61ed50caff04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How has AWS evolved?\n",
      "\n",
      "Result:  Based on the context provided, AWS has evolved in the following ways:\n",
      "\n",
      "1. Innovation: AWS has continued to innovate and invest in new technologies and services to meet the changing needs of its customers.\n",
      "2. Growth: AWS is expected to experience unusual growth in the next decade, particularly in the areas of virtual classrooms and government efforts to combat the pandemic.\n",
      "3. Efficiency: AWS is more efficient than traditional in-house data centers due to its institutional advantages and the transition to virtual classrooms and government use.\n",
      "\n",
      "I don't know the answer to the question \"What are the specific areas of innovation for AWS?\" as the context does not provide that information.\n",
      "\n",
      "Context Documents: \n",
      "page_content='done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='AWS is also inherently more efficient than the traditional in-house data center. That’s primarily due to two' metadata={'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='institutionsaround the world are transitioning from in-person to virtual classrooms and are running on AWS to help ensurecontinuity of learning. And governments are leveraging AWS as a secure platform to build out new capabilitiesin their efforts to end this pandemic.' metadata={'year': 2019, 'source': 'AMZN-2019-Shareholder-Letter.pdf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How has AWS evolved?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "      print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a826123-5998-45dd-9dda-c71386c89491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Why is Amazon successful?\n",
      "\n",
      "Result:  Based on the provided context, Amazon's success can be attributed to several factors:\n",
      "\n",
      "1. Early Mover Advantage: Amazon has been iterating and remaking its fulfillment capabilities for nearly two decades, giving it a significant head start over its competitors. This early mover advantage has allowed Amazon to develop a robust and efficient logistics network, which has been critical in its success.\n",
      "2. Customer Obsession: Amazon is divinely discontented with customer experiences, whether they are its own or not. The company is constantly experimenting and inventing to make customers' experiences better. This customer-centric approach has helped Amazon build a loyal customer base and differentiate itself from its competitors.\n",
      "3. Innovation: Amazon is known for its innovative approach to business. The company is always looking for new ways to improve its operations and customer experiences. This innovative spirit has allowed Amazon to stay ahead of the competition and adapt to changing market conditions.\n",
      "4. Scale: Amazon's large scale has been a significant factor in its success. With over a million Amazonians working in its fulfillment network, the company has the resources and capacity to handle a large volume of orders and meet customer demand.\n",
      "5. Strategic Acquisitions: Amazon has made several strategic acquisitions over the years, including the purchase of Whole Foods Market and the acquisition of Twitch. These acquisitions have helped Amazon expand its reach and offer a wider range of products and services to its customers.\n",
      "\n",
      "Overall, Amazon's success can be attributed to a combination of its early mover advantage, customer obsession, innovation, scale, and strategic acquisitions.\n",
      "\n",
      "Context Documents: \n",
      "page_content='position us well to pursue this large market segment. Amazon Business allows businesses, municipalities,and organizations to procure products like office supplies and other bulk items easily and at great savings.While some areas of the economy have struggled over the past few years, Amazon Business has thrived. Why?Because the team has translated what it means to deliver selection, value, and convenience into a businessprocurement setting, constantly listening to and learning from customers, and innovating' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='unpredictable as this pandemic turned out to be. What is it about Amazon that made it possible for us to doso? It’s because we weren’t starting from a standing start. We had been iterating on and remaking ourfulfillment capabilities for nearly two decades. In every business we pursue, we’re constantly experimentingand inventing. We’re divinely discontented with customer experiences, whether they’re our own or not. Webelieve these customer experiences can always be better, and we strive to make customers’' metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='For example, more than a million Amazonians work in our fulfillment network. In 2018, we championed' metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Why is Amazon successful?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "      print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2418da7b-0bfc-4ef6-a64a-17b4ccb12174",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What business challenges has Amazon experienced?\n",
      "\n",
      "Result:  Based on the provided context, Amazon has experienced the following business challenges:\n",
      "\n",
      "1. Rising cost to serve in their Stores fulfillment network (i.e. the cost to get a product from Amazon to a customer).\n",
      "2. Unusual number of simultaneous challenges this past year.\n",
      "3. Operating in large, dynamic, global market segments with many capable and well-funded competitors.\n",
      "\n",
      "It is important to note that the context only provides information about the challenges Amazon has experienced, and does not provide information about the company's overall performance or success.\n",
      "\n",
      "Context Documents: \n",
      "page_content='shareholders, and employees.\\nWhile there were an unusual number of simultaneous challenges this past year, the reality is that if you\\noperate in large, dynamic, global market segments with many capable and well-funded competitors (theconditions in which Amazon operates all of its businesses), conditions rarely stay stagnant for long.\\nIn the 25 years I’ve been at Amazon, there has been constant change, much of which we’ve initiated ourselves.' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='This type of iterative innovation is pervasive across every team at Amazon. I could have given comparable\\nexamples in Advertising, Grocery, Gaming, Amazon Music, Amazon Care (our telemedicine offering), orPharmacy, to name a few. All of these stories are still being written as we rapidly experiment, learn, andcontinue to try to make our customer experience better every day.\\nIf this approach sounds appealing, a natural question is what’s required to get good at it? It’s easier said' metadata={'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
      "\n",
      "page_content='A critical challenge we’ve continued to tackle is the rising cost to serve in our Stores fulfillment network (i.e.\\nthe cost to get a product from Amazon to a customer)—and we’ve made several changes that we believe will\\nmeaningfully improve our fulfillment costs and speed of delivery .\\nDuring the early part of the pandemic, with many physical stores shut down, our consumer business grew' metadata={'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What business challenges has Amazon experienced?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "      print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8bd21-c18f-43c8-bc1a-02380b4c928b",
   "metadata": {},
   "source": [
    "# 클린업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee483c-e1d8-499f-a707-82dafd3bd0cb",
   "metadata": {},
   "source": [
    "`delete_endpoint` 호출의 커멘트를 해제하여 생성한 리소스들을 제거하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276e6b3-788a-49f4-960e-8856dbf22a37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "# #임베딩 엔드포인트 삭제\n",
    "# sagemaker_client.delete_endpoint(EndpointName=embedding_model_endpoint_name)\n",
    "\n",
    "# #LLM 엔드포인트 삭제\n",
    "# sagemaker_client.delete_endpoint(EndpointName=llm_model_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e6b028-4b2b-4f76-9d52-56d7e56dc4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
