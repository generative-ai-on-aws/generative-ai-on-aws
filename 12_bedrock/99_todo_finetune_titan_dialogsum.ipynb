{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308a0e04-6066-4405-8a13-8b060e552a8a",
   "metadata": {},
   "source": [
    "# Introduction to Bedrock - Fine-Tuning\n",
    "\n",
    "> *If you see errors, you may need to be allow-listed for the Bedrock models used by this notebook*\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9a3e6-4d64-4da4-8a85-d5c12ae70978",
   "metadata": {},
   "source": [
    "In this demo notebook, we demonstrate how to use the Bedrock Python SDK for fine-tuning Bedrock models with your own data. If you have text samples to train and want to adapt the Bedrock models to your domain, you can further fine-tune the Bedrock foundation models by providing your own training datasets. You can upload your datasets to Amazon S3, and provide the S3 bucket path while configuring a Bedrock fine-tuning job. You can also adjust hyper parameters (learning rate, epoch, and batch size) for fine-tuning. After the fine-tuning job of the model with your dataset has completed, you can start using the model for inference in the Bedrock playground application. You can select the fine-tuned model and submit a prompt to the fine-tuned model along with a set of model parameters. The fine-tuned model should generate texts to be more alike your text samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca26768f-3775-436d-8b77-dee584420aff",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a0821c-2d18-4698-8efc-df81030bcdc8",
   "metadata": {},
   "source": [
    "1. Setup\n",
    "2. Fine-tuning\n",
    "3. Testing the fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b889b27f-7d55-4c07-81fc-3f00d55e5544",
   "metadata": {},
   "source": [
    " Note: This notebook was tested in Amazon SageMaker Studio with Python 3 (Data Science 2.0) kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8bb89f-2b60-41e4-8ea7-8cace718bed5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335c5e24-b7c8-4932-b8d1-729ff52c6fb1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17f96e1-7c93-44be-9e4c-542fa0254673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "awscli 1.29.63 requires botocore==1.31.63, but you have botocore 1.31.70 which is incompatible.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.3 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "notebook 6.5.6 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.4.0 which is incompatible.\n",
      "notebook 6.5.6 requires pyzmq<25,>=17, but you have pyzmq 25.1.1 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.16.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires jupyter-client<8,>=7.3.4; python_version >= \"3\", but you have jupyter-client 8.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U boto3 botocore --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dfaf752-e11b-4e69-ba9f-c934537360dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3                                1.28.70\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list | grep boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d966521-f63a-4c96-8494-68d6d2367938",
   "metadata": {},
   "source": [
    "#### Now let's set up our connection to the Amazon Bedrock SDK using Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "785b3b10-2c66-4adc-a4ac-747c214fd9cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Un comment the following lines to run from your local environment outside of the AWS account with Bedrock access\n",
    "\n",
    "#import os\n",
    "#os.environ['BEDROCK_ASSUME_ROLE'] = '<YOUR_VALUES>'\n",
    "#os.environ['AWS_PROFILE'] = '<YOUR_VALUES>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ad566f-2a15-46ac-aeeb-346f9db0a10e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-west-2\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "bedrock_client = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    runtime=False  # Needed for control plane\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4a497-d0f3-4be1-8c67-04cd1f0a6d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_client.list_foundation_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48703d82-bb32-44fa-916e-6cc5040a67cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa6614-7080-4dbb-af08-cd67ce6a8706",
   "metadata": {},
   "source": [
    "### Preview custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba565f-dc5b-4cd0-be0b-11bf496c31e6",
   "metadata": {},
   "source": [
    "Our custom data in JSON line file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "215843b6-9c4e-4c82-b3c1-c8cc99d01488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = \"data/train.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de721f4-3f65-4aa4-84ce-19f7a7c47778",
   "metadata": {},
   "source": [
    "Read the JSON line file into an object like any normal file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa423f6-7827-45fc-bd49-39c1b6f9759a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(data) as f:\n",
    "    lines = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c2ea85-a95b-4cfb-9463-692b9a642897",
   "metadata": {},
   "source": [
    "#### Load the ‘lines’ object into a pandas Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da61e9b-ac1f-4f69-8cb6-b525a737cba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_inter = pd.DataFrame(lines)\n",
    "df_inter.columns = ['json_element']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf4879-a796-4359-ba80-f7a54dc05cd6",
   "metadata": {},
   "source": [
    "This intermediate data frame will have only one column with each json object in a row. A sample output is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75a8528c-d478-48a9-acef-ac135b3090d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'output': 'Positive', 'input': 'the rock is d...\n",
       "1     {'output': 'Positive', 'input': 'the gorgeousl...\n",
       "2     {'output': 'Positive', 'input': 'effective but...\n",
       "3     {'output': 'Positive', 'input': 'if you someti...\n",
       "4     {'output': 'Positive', 'input': 'emerges as so...\n",
       "5     {'output': 'Positive', 'input': 'the film prov...\n",
       "6     {'output': 'Positive', 'input': 'offers that r...\n",
       "7     {'output': 'Positive', 'input': 'perhaps no pi...\n",
       "8     {'output': 'Positive', 'input': 'steers turns ...\n",
       "9     {'output': 'Positive', 'input': 'take care of ...\n",
       "10    {'output': 'Negative', 'input': 'no worse than...\n",
       "11    {'output': 'Negative', 'input': 'the plot is s...\n",
       "12    {'output': 'Negative', 'input': 'at first , th...\n",
       "13    {'output': 'Negative', 'input': 'never again s...\n",
       "14    {'output': 'Negative', 'input': 'the story its...\n",
       "15    {'output': 'Negative', 'input': 'technically ,...\n",
       "16    {'output': 'Negative', 'input': 'the title's l...\n",
       "17    {'output': 'Negative', 'input': 'the parts are...\n",
       "18    {'output': 'Negative', 'input': 'while the fil...\n",
       "19    {'output': 'Negative', 'input': 'the humor is ...\n",
       "Name: json_element, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter['json_element'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc711d5-6522-47be-b4b6-fe292d70e6e8",
   "metadata": {},
   "source": [
    "Now we will apply json loads function on each row of the ‘json_element’ column. ‘json.loads’ is a decoder function in python which is used to decode a json object into a dictionary. ‘apply’ is a popular function in pandas that takes any function and applies to each row of the pandas dataframe or series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600eac79-5830-4422-a39a-19b6770827a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = pd.json_normalize(df_inter['json_element'].apply(json.loads))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2430c-c36f-43a7-8ce6-e17b0efdbd20",
   "metadata": {},
   "source": [
    "Once decoding is done we will apply the json normalize function to the above result. json normalize will convert any semi-structured json data into a flat table. Here it converts the JSON ‘keys’ to columns and its corresponding values to row elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2061f7a-eb1a-4089-96c1-7bfc8dd3d741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>the gorgeously elaborate continuation of the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>the film provides some great insight into the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Positive</td>\n",
       "      <td>offers that rare combination of entertainment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Positive</td>\n",
       "      <td>perhaps no picture ever made has more literall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Positive</td>\n",
       "      <td>steers turns in a snappy screenplay that curls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Positive</td>\n",
       "      <td>take care of my cat offers a refreshingly diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Negative</td>\n",
       "      <td>no worse than a lot of the crap we've been off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Negative</td>\n",
       "      <td>the plot is so predictable and sentimental tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Negative</td>\n",
       "      <td>at first , the sight of a blind man directing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Negative</td>\n",
       "      <td>never again swings between false sentiment and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Negative</td>\n",
       "      <td>the story itself is uninteresting , and the so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Negative</td>\n",
       "      <td>technically , the film is about as interesting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Negative</td>\n",
       "      <td>the title's lameness should clue you in on how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Negative</td>\n",
       "      <td>the parts are better than the whole ( bizarre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Negative</td>\n",
       "      <td>while the film shuns the glamour or glitz that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Negative</td>\n",
       "      <td>the humor is hinged on the belief that knees i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      output                                              input\n",
       "0   Positive  the rock is destined to be the 21st century's ...\n",
       "1   Positive  the gorgeously elaborate continuation of the l...\n",
       "2   Positive                     effective but too-tepid biopic\n",
       "3   Positive  if you sometimes like to go to the movies to h...\n",
       "4   Positive  emerges as something rare , an issue movie tha...\n",
       "5   Positive  the film provides some great insight into the ...\n",
       "6   Positive  offers that rare combination of entertainment ...\n",
       "7   Positive  perhaps no picture ever made has more literall...\n",
       "8   Positive  steers turns in a snappy screenplay that curls...\n",
       "9   Positive  take care of my cat offers a refreshingly diff...\n",
       "10  Negative  no worse than a lot of the crap we've been off...\n",
       "11  Negative  the plot is so predictable and sentimental tha...\n",
       "12  Negative  at first , the sight of a blind man directing ...\n",
       "13  Negative  never again swings between false sentiment and...\n",
       "14  Negative  the story itself is uninteresting , and the so...\n",
       "15  Negative  technically , the film is about as interesting...\n",
       "16  Negative  the title's lameness should clue you in on how...\n",
       "17  Negative  the parts are better than the whole ( bizarre ...\n",
       "18  Negative  while the film shuns the glamour or glitz that...\n",
       "19  Negative  the humor is hinged on the belief that knees i..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546f2e9-000b-4c87-807e-2a63554bcc8c",
   "metadata": {},
   "source": [
    "### Uploading data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91c8bc-cb24-4b04-8de8-25c03c3490df",
   "metadata": {},
   "source": [
    "Next, we need to upload our training dataset to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e9547f-127d-444e-89ed-6403781c83a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_location = f\"s3://{sagemaker_session_bucket}/bedrock/finetuning/train.jsonl\"\n",
    "s3_output = f\"s3://{sagemaker_session_bucket}/bedrock/finetuning/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb873b6-c50b-46fb-bd1f-a050bf523221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/train.jsonl to s3://sagemaker-us-west-2-079002598131/bedrock/finetuning/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp data/train.jsonl $s3_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb85e28-aec1-46bc-aa6c-ba9b04cbc106",
   "metadata": {},
   "source": [
    "Now we can create the fine-tuning job. \n",
    "\n",
    "### ^^ **Note:** Make sure the IAM role you're using has these [IAM policies](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-iam-role.html) attached that allow Amazon Bedrock access to the specified S3 buckets ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c04f82b-a918-4226-bf88-3ce567e50bcc",
   "metadata": {},
   "source": [
    "## 2. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "093e54cf-f0f3-403f-8ef5-84e0cbb40d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab860a48-46b2-4b8e-a72c-d52a343c8555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_id = \"amazon.titan-text-express-v1\"\n",
    "#base_model_id = \"amazon.titan-text-lite-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdc3af82-7cd6-44bd-bf14-e3e455c15e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titan-1698257909'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = \"titan-{}\".format(timestamp)\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adfbd806-cb7e-4414-97a6-9239e98e5604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom-titan-1698257909'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model_name = \"custom-{}\".format(job_name)\n",
    "custom_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4f0ead8-31d2-4146-82c8-2d4d5fa07397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'dd128903-efdf-4d5a-8f52-41c3d80ae065',\n",
       "  'HTTPStatusCode': 201,\n",
       "  'HTTPHeaders': {'date': 'Wed, 25 Oct 2023 18:20:20 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '122',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'dd128903-efdf-4d5a-8f52-41c3d80ae065'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/ycbprb70zy42'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_client.create_model_customization_job(\n",
    "    jobName=job_name,\n",
    "    customModelName=custom_model_name,\n",
    "    roleArn=role,\n",
    "    baseModelIdentifier=base_model_id,\n",
    "    hyperParameters = {\n",
    "        \"epochCount\": \"1\",\n",
    "        \"batchSize\": \"1\",\n",
    "        \"learningRate\": \"0.005\",\n",
    "        \"learningRateWarmupSteps\": \"0\"\n",
    "    },\n",
    "    trainingDataConfig={\"s3Uri\": s3_location},\n",
    "    outputDataConfig={\"s3Uri\": s3_output},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b1a6b37-6a22-4f63-8729-185642acc1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InProgress'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status = bedrock_client.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e0489-c5e3-4cc7-981b-6706497c6527",
   "metadata": {},
   "source": [
    "# Let's periodically check in on the progress.\n",
    "### The next cell might run for ~40min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f87f790-8ee0-4485-b090-1be7af0f0554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "status = bedrock_client.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "\n",
    "while status == \"InProgress\":\n",
    "    print(status)\n",
    "    time.sleep(30)\n",
    "    status = bedrock_client.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "    \n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9813589e-901f-49d5-9a1b-82609a405da9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '87c0673f-969c-458d-b413-9b95ae61ed42',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 25 Oct 2023 19:57:12 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '1209',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '87c0673f-969c-458d-b413-9b95ae61ed42'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/ycbprb70zy42',\n",
       " 'jobName': 'titan-1698257909',\n",
       " 'outputModelName': 'custom-titan-1698257909',\n",
       " 'outputModelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/a3ne5s6g0xc4',\n",
       " 'clientRequestToken': 'c6f03e80-2903-4e34-b7a9-f7584415047a',\n",
       " 'roleArn': 'arn:aws:iam::079002598131:role/service-role/AmazonSageMaker-ExecutionRole-20220804T150518',\n",
       " 'status': 'Completed',\n",
       " 'creationTime': datetime.datetime(2023, 10, 25, 18, 20, 20, 815000, tzinfo=tzlocal()),\n",
       " 'lastModifiedTime': datetime.datetime(2023, 10, 25, 19, 56, 45, 178000, tzinfo=tzlocal()),\n",
       " 'endTime': datetime.datetime(2023, 10, 25, 19, 56, 44, 695000, tzinfo=tzlocal()),\n",
       " 'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       " 'hyperParameters': {'batchSize': '1',\n",
       "  'epochCount': '1',\n",
       "  'learningRate': '0.005',\n",
       "  'learningRateWarmupSteps': '0'},\n",
       " 'trainingDataConfig': {'s3Uri': 's3://sagemaker-us-west-2-079002598131/bedrock/finetuning/train.jsonl'},\n",
       " 'outputDataConfig': {'s3Uri': 's3://sagemaker-us-west-2-079002598131/bedrock/finetuning/output'},\n",
       " 'validationMetrics': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_job = bedrock_client.get_model_customization_job(jobIdentifier=job_name)\n",
    "completed_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b47ec7-9933-45d1-9ad6-67be8fb318f9",
   "metadata": {},
   "source": [
    "## 3. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13364c0-17a8-4a30-b354-100c7b43a81b",
   "metadata": {},
   "source": [
    "Now we can test the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42f5bdf2-29a9-4041-8a62-b1f69ddbf129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f8dc45ac-f08d-41ca-ada8-943a1257b474',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 25 Oct 2023 19:57:12 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '657',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'f8dc45ac-f08d-41ca-ada8-943a1257b474'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/a3ne5s6g0xc4',\n",
       "   'modelName': 'custom-titan-1698257909',\n",
       "   'creationTime': datetime.datetime(2023, 10, 25, 18, 20, 20, 815000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/rfs7atdiuu9m',\n",
       "   'modelName': 'my-finetuned-model-small-10',\n",
       "   'creationTime': datetime.datetime(2023, 10, 14, 15, 56, 53, 673000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'baseModelName': ''}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_client.list_custom_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7be0a01-1a4a-41e9-8c39-89f4d36942f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/ycbprb70zy42\n",
      "jobName: titan-1698257909\n",
      "status: Completed\n",
      "customModelName: custom-titan-1698257909\n",
      "-----\n",
      "jobArn: arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/qogsvgm6j43o\n",
      "jobName: finetune-small-10\n",
      "status: Completed\n",
      "customModelName: my-finetuned-model-small-10\n"
     ]
    }
   ],
   "source": [
    "for job in bedrock_client.list_model_customization_jobs()[\"modelCustomizationJobSummaries\"]:\n",
    "    print(\"-----\\n\" + \"jobArn: \" + job[\"jobArn\"] + \"\\njobName: \" + job[\"jobName\"] + \"\\nstatus: \" + job[\"status\"] + \"\\ncustomModelName: \" + job[\"customModelName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf92c4-e2d3-48d4-83ab-592770e6aa61",
   "metadata": {},
   "source": [
    "## GetCustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0456a56-8bc3-47d2-8d69-4205ad0b1cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'a5c7fef6-669d-491d-bccf-477e23938a52',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 25 Oct 2023 19:57:13 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '866',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'a5c7fef6-669d-491d-bccf-477e23938a52'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/a3ne5s6g0xc4',\n",
       " 'modelName': 'custom-titan-1698257909',\n",
       " 'jobArn': 'arn:aws:bedrock:us-west-2:079002598131:model-customization-job/amazon.titan-text-express-v1:0:8k/ycbprb70zy42',\n",
       " 'baseModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       " 'hyperParameters': {'batchSize': '1',\n",
       "  'epochCount': '1',\n",
       "  'learningRate': '0.005',\n",
       "  'learningRateWarmupSteps': '0'},\n",
       " 'trainingDataConfig': {'s3Uri': 's3://sagemaker-us-west-2-079002598131/bedrock/finetuning/train.jsonl'},\n",
       " 'outputDataConfig': {'s3Uri': 's3://sagemaker-us-west-2-079002598131/bedrock/finetuning/output'},\n",
       " 'trainingMetrics': {'trainingLoss': 10.75},\n",
       " 'validationMetrics': [],\n",
       " 'creationTime': datetime.datetime(2023, 10, 25, 18, 20, 20, 815000, tzinfo=tzlocal())}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_client.get_custom_model(modelIdentifier=custom_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03bb02cd-0624-43f1-b3bc-2369333640d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/a3ne5s6g0xc4'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model_arn = bedrock_client.get_custom_model(modelIdentifier=custom_model_name)['modelArn']\n",
    "custom_model_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a6a7e0b-2ee9-4c58-9db7-9d504b35d67e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_arn = bedrock_client.get_custom_model(modelIdentifier=custom_model_name)['baseModelArn']\n",
    "base_model_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e23e8-c4ee-4598-95ec-65620abb3631",
   "metadata": {},
   "source": [
    "## **Note:** To invoke custom models, you need to first create a provisioned throughput resource and make requests using that resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd028a6c-f13b-4d58-9b4f-ce8a18aecd66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provisioned_model_name = \"{}-provisioned\".format(custom_model_name)\n",
    "provisioned_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d7cbf-f391-4436-953e-70eaa987e3aa",
   "metadata": {},
   "source": [
    "## !! **Note:** SDK currently only supports 1 month and 6 months commitment terms. Go to Bedrock console to manually purchase no commitment term option for testing !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531afd39-5bde-4ead-a342-bea7c972c39c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bedrock_client.create_provisioned_model_throughput(\n",
    "#     modelUnits = 1,\n",
    "#     commitmentDuration = \"OneMonth\", ## Note: SDK is currently missing No Commitment option\n",
    "#     provisionedModelName = provisioned_model_name,\n",
    "#     modelId = base_model_arn\n",
    "# ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828ec02-d7ae-43d3-afcb-060c95d4f4fd",
   "metadata": {},
   "source": [
    "## ListProvisionedModelThroughputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "269b30af-8167-4c70-be70-ec0050fca906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'provisionedModelName': 'custom-titan-1698257909-provisioned',\n",
       "  'provisionedModelArn': 'arn:aws:bedrock:us-west-2:079002598131:provisioned-model/fas0m0hl45m0',\n",
       "  'modelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/a3ne5s6g0xc4',\n",
       "  'desiredModelArn': 'arn:aws:bedrock:us-west-2:079002598131:custom-model/amazon.titan-text-express-v1:0:8k/a3ne5s6g0xc4',\n",
       "  'foundationModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "  'modelUnits': 0,\n",
       "  'desiredModelUnits': 1,\n",
       "  'status': 'Creating',\n",
       "  'creationTime': datetime.datetime(2023, 10, 25, 20, 1, 3, 688000, tzinfo=tzlocal()),\n",
       "  'lastModifiedTime': datetime.datetime(2023, 10, 25, 20, 1, 29, 333000, tzinfo=tzlocal())}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_client.list_provisioned_model_throughputs()[\"provisionedModelSummaries\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d9e7b-68f8-4162-97d6-fe8f43e3b421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GetProvisionedModelThroughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1308145-1e5a-474e-ad82-138de065f16e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#provisioned_model_name = \"<YOUR_PROVISIONED_MODEL_NAME>\" # e.g. custom-titan-1698257909-provisioned\n",
    "provisioned_model_name = \"custom-titan-1698257909-provisioned\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61669df7-a58d-4f86-bb8c-a9319ca52c46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:bedrock:us-west-2:079002598131:provisioned-model/fas0m0hl45m0'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provisioned_model_arn = bedrock_client.get_provisioned_model_throughput(\n",
    "     provisionedModelId=provisioned_model_name)[\"provisionedModelArn\"]\n",
    "provisioned_model_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b15e071-9f84-4a0b-af8c-2f94875fbefe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creating'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_status = bedrock_client.get_provisioned_model_throughput(\n",
    "    provisionedModelId=provisioned_model_name)[\"status\"]\n",
    "deployment_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93817fcb-22d3-4c85-9ab5-c78fd67b5a16",
   "metadata": {},
   "source": [
    "## The next cell might run for ~10min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22987e2-82fe-4550-9ecd-d13004f0919f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "deployment_status = bedrock_client.get_provisioned_model_throughput(\n",
    "    provisionedModelId=provisioned_model_name)[\"status\"]\n",
    "\n",
    "while deployment_status == \"Creating\":\n",
    "    \n",
    "    print(deployment_status)\n",
    "    time.sleep(30)\n",
    "    deployment_status = bedrock_client.get_provisioned_model_throughput(\n",
    "        provisionedModelId=provisioned_model_name)[\"status\"]  \n",
    "    \n",
    "print(deployment_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c83fce-596f-47a2-8b8d-89f62c7ffba2",
   "metadata": {},
   "source": [
    "### Invoke Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "052840a2-142b-4bea-a25a-4f7a88309dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-west-2\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# module_path = \"..\"\n",
    "# sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "bedrock_client = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    runtime=True  # Default. Needed for invoke_model() on the data plane\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "864c491a-e308-41d5-8939-81e1d7fdb743",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"inputTextTokenCount\":20,\"results\":[{\"tokenCount\":3,\"outputText\":\"\\nNegative\",\"completionReason\":\"FINISH\"}]}\n",
      "\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_client.invoke_model(\n",
    "    # modelId needs to be Provisioned Throughput Model ARN\n",
    "    modelId=provisioned_model_arn,\n",
    "    body=\"\"\"\n",
    "{\n",
    "  \"inputText\": \"Classify this as Positive, Neutral, or Negative:\\\\n'I really don't like this!'\",\n",
    "  \"textGenerationConfig\":{\n",
    "    \"maxTokenCount\": 50, \n",
    "    \"stopSequences\": [],\n",
    "    \"temperature\": 1,\n",
    "    \"topP\": 0.9\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "response_body = response[\"body\"].read().decode('utf8')\n",
    "print(response_body)\n",
    "\n",
    "print(json.loads(response_body)[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5364ddd6-8ad2-47c8-90b3-e518be36a329",
   "metadata": {},
   "source": [
    "# Qualitative Results with Zero Shot Inference AFTER Fine-Tuning\n",
    "\n",
    "As with many GenAI applications, a qualitative approach where you ask yourself the question \"is my model behaving the way it is supposed to?\" is usually a good starting point. In the example below (the same one we started this notebook with), you can see how the fine-tuned model is able to create a reasonable summary of the dialogue compared to the original inability to understand what is being asked of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef4202-e6e8-4f65-bb06-4c2309e1823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_client.invoke_model(\n",
    "    # modelId needs to be Provisioned Throughput Model ARN\n",
    "    modelId=provisioned_model_arn,\n",
    "    body=\"\"\"\n",
    "{\"inputText\": \"Classify this as Positive, Neutral, or Negative:\\\\n'I really don't like this!'\",\n",
    " \"textGenerationConfig\":{\n",
    "  \"maxTokenCount\":50,\n",
    "  \"stopSequences\":[],\n",
    "  \"temperature\":1,\n",
    "  \"topP\":0.9\n",
    " }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "response_body = response[\"body\"].read().decode('utf8')\n",
    "print(response_body)\n",
    "\n",
    "print(json.loads(response_body)[\"results\"][0][\"outputText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89470400-b667-4815-8bc7-64460b842bd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "--------------------------\n",
      "Summarize the following conversation. \n",
      "#Person1#: Hello. My name is John Sandals, and I've got a reservation. \n",
      "#Person2#: May I see some identification, sir, please? \n",
      "#Person1#: Sure. Here you are. \n",
      "#Person2#: Thank you so much. Have you got a credit card, Mr. Sandals? \n",
      "#Person1#: I sure do. How about American Express? \n",
      "#Person2#: Unfortunately, at the present time we take only MasterCard or VISA. \n",
      "#Person1#: No American Express? Okay, here's my VISA. \n",
      "#Person2#: Thank you, sir. You'll be in room 507, nonsmoking, with a queen-size bed. Do you approve, sir? \n",
      "#Person1#: Yeah, that'll be fine. \n",
      "#Person2#: That's great. This is your key, sir. If you need anything at all, anytime, just dial zero. Summary: \n",
      "--------------------------\n",
      "Flan-T5 response: John Sandals has a reservation for a room at the Venetian Hotel in Las Vegas.\n",
      "Our instruct-tuned response (on top of Flan-T5): John Sandals has a reservation and checks in with his VISA. #Person2# helps him to check in and approves his reservation.\n",
      "Baseline summary from original dataset: John Sandals has got a reservation. #Person1# asks for his identification and credit card and helps his check-in.\n"
     ]
    }
   ],
   "source": [
    "# idx = 2\n",
    "# diag = tokenizer.decode(tokenized_dataset['test'][idx]['input_ids'], skip_special_tokens=True)\n",
    "# model_input = tokenizer(diag, return_tensors=\"pt\").input_ids\n",
    "# summary = tokenizer.decode(tokenized_dataset['test'][idx]['labels'], skip_special_tokens=True)\n",
    "\n",
    "# original_outputs = model.to('cpu').generate(\n",
    "#     model_input,\n",
    "#     GenerationConfig(max_new_tokens=200, num_beams=1),\n",
    "# )\n",
    "# outputs = tuned_model.to('cpu').generate(\n",
    "#     model_input,\n",
    "#     GenerationConfig(max_new_tokens=200, num_beams=1,),\n",
    "# )\n",
    "# text_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# diag_print = diag.replace(' #',' \\n#')\n",
    "# print(f\"Prompt:\\n--------------------------\\n{diag_print}\\n--------------------------\")\n",
    "# print(f'Flan-T5 response: {original_text_output}')\n",
    "# print(f'Our instruct-tuned response (on top of Flan-T5): {text_output}')\n",
    "# print(f'Baseline summary from original dataset: {summary}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ebff7f-9afc-461c-ac89-016d3642dfbc",
   "metadata": {},
   "source": [
    "# Quantitative Results with ROUGE Metric\n",
    "\n",
    "The [ROUGE metric](https://en.wikipedia.org/wiki/ROUGE_(metric)) helps quantify the validity of summarizations produced by models. It compares summarizations to a \"baseline\" summary which is usually created by a human. While not perfect, it does give an indication to the overall increase in summarization effectiveness that we have accomplished by fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95b47270-ccfc-480a-8168-713b7e975523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9aea8243f54bbab43011976f5a444b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daff5bf-312c-461b-a5bb-410fd40f4cdd",
   "metadata": {},
   "source": [
    "## Evaluate a Subsection of Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41e75d59-6ba5-40f0-a92f-e3346bdd6b98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# again, for the sake of time, we will only be generating a few summaries with each model\n",
    "# outside of the lab, a good exercise is to increase the number of validation summaries generated\n",
    "\n",
    "# TODO:  what is the tokenized\n",
    "\n",
    "#dialogues = tokenized_dataset['test'][0:10]['input_ids']\n",
    "#baseline_summaries = tokenized_dataset['test'][0:10]['labels']\n",
    "\n",
    "dialogues = dataset\n",
    "\n",
    "# decode the original summaries\n",
    "human_baseline_summaries = []\n",
    "for base_summary in baseline_summaries:\n",
    "    human_baseline_summaries.append(tokenizer.decode(base_summary, skip_special_tokens=True))\n",
    "\n",
    "# generate the summaries\n",
    "original_outputs = model.generate(dialogues, GenerationConfig(max_new_tokens=200))\n",
    "tuned_outputs = tuned_model.generate(dialogues, GenerationConfig(max_new_tokens=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8df0d700-92d2-441b-ba41-aad207d19a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store the summaries in lists\n",
    "original_model_summaries = []\n",
    "tuned_model_summaries = []\n",
    "\n",
    "# decode all the summaries\n",
    "for original_summary, tuned_summary in zip(original_outputs, tuned_outputs):\n",
    "    original_model_summaries.append(tokenizer.decode(original_summary, skip_special_tokens=True))\n",
    "    tuned_model_summaries.append(tokenizer.decode(tuned_summary, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a0344a3-ea31-4aea-87f6-766652e578bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries,\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e7c2711-07b1-457d-8dd4-b56a9d1ff47b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuned_results = rouge.compute(\n",
    "    predictions=tuned_model_summaries,\n",
    "    references=human_baseline_summaries,\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95144a23-8216-4fa0-bbd0-0ec19e5832b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.23899693678641046,\n",
       " 'rouge2': 0.08932806324110672,\n",
       " 'rougeL': 0.21776705653021444,\n",
       " 'rougeLsum': 0.21325132275132275}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba5bff47-6cd4-4c01-88dd-bb155841642c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.5243400833160587,\n",
       " 'rouge2': 0.240785255433749,\n",
       " 'rougeL': 0.3960164115550142,\n",
       " 'rougeLsum': 0.396040090323604}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9f3599-86a3-42f4-8d5f-fef195e83693",
   "metadata": {},
   "source": [
    "## Evalute the Full Dataset\n",
    "\n",
    "The file called \"diag-summary-training-results.csv\" contains a pre-populated list of all model results which we can use to evaluate on a larger section of data. The results show substantial improvement in all ROUGE metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06f063e9-6d89-4c5d-98b6-748af57e8ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"diag-summary-training-results.csv\")\n",
    "original_model_summaries = results['original_model_summaries'].values\n",
    "tuned_model_summaries = results['tuned_model_summaries'].values\n",
    "human_baseline_summaries = results['human_baseline_summaries'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fac125ef-e239-4b9f-8d41-e303d6483a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbe4694b-32e3-4dd5-aa2c-b68d4668e353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuned_results = rouge.compute(\n",
    "    predictions=tuned_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(tuned_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2e3f6e2-a7eb-405c-ad93-e03be9533bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.2334158581572823,\n",
       " 'rouge2': 0.07603964187010573,\n",
       " 'rougeL': 0.20145520923859048,\n",
       " 'rougeLsum': 0.20145899339006135}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93b32c1b-7ca6-408a-8bb6-b58fb26c9e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.42161291557556113,\n",
       " 'rouge2': 0.18035380596301792,\n",
       " 'rougeL': 0.3384439349963909,\n",
       " 'rougeLsum': 0.33835653595561666}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4359086e-767b-43a5-84e3-9c475a8c4635",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 absolute percentage improvement after instruct fine-tuning: 18.82%\n",
      "rouge2 absolute percentage improvement after instruct fine-tuning: 10.43%\n",
      "rougeL absolute percentage improvement after instruct fine-tuning: 13.70%\n",
      "rougeLsum absolute percentage improvement after instruct fine-tuning: 13.69%\n"
     ]
    }
   ],
   "source": [
    "improvement = (np.array(list(tuned_results.values())) - np.array(list(original_results.values())))\n",
    "for key, value in zip(tuned_results.keys(), improvement):\n",
    "    print(f'{key} absolute percentage improvement after instruct fine-tuning: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f62c91-c793-439d-b3b4-66f6eb0b0c1b",
   "metadata": {},
   "source": [
    "## Delete Provisioned Throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdbf87-b454-410a-9f11-fb42c17ed159",
   "metadata": {},
   "source": [
    "When you're done testing, you can delete Provisioned Throughput to stop charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e597d17-c319-4abf-a367-9c5c6588f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bedrock_client = bedrock.get_bedrock_client(\n",
    "#     assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "#     region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "#     runtime=False  # Default. Needed for invoke_model() on the data plane\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad633b8-db9c-43a9-b2ab-b39bc7b3ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bedrock_client.delete_provisioned_model_throughput(\n",
    "#     provisionedModelId = provisioned_model_name\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "forced_instance_type": "ml.t3.medium",
  "forced_lcc_arn": "",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
