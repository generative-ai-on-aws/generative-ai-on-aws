{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fded102b",
   "metadata": {},
   "source": [
    "# 아마존 타이탄을 활용한 작은 파일의 텍스트 요약\n",
    "\n",
    "> *이 노트북에서 사용하는 베드록 모델에 대한 허용 목록에 포함되어 있지 않다면 오류가 발생할 수 있습니다*\n",
    "\n",
    "> *이 노트북은 세이지메이커 스튜디오의 **`Data Science 3.0`** 커널에서 잘 작동할 것입니다*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8b2cf",
   "metadata": {},
   "source": [
    "## 개요\n",
    "\n",
    "이 예시에서는 소량의 데이터(문자열 데이터)를 아마존 베드록 API(아마존 타이탄 모델 사용)에 직접 입력하고 해당 텍스트를 요약하는 인스트럭션을 내릴 것입니다.\n",
    "\n",
    "### 아키텍처\n",
    "\n",
    "![](./images/41-text-simple-1.png)\n",
    "\n",
    "이 아키텍처에서\n",
    "\n",
    "1. 작은 텍스트 조각(또는 작은 파일)이 로드됩니다.\n",
    "1. 파운데이션 모델이 해당 데이터를 처리합니다.\n",
    "1. 모델이 입력된 텍스트의 요약과 함께 응답을 반환합니다.\n",
    "\n",
    "### 활용 사례\n",
    "\n",
    "이 접근 방식은 통화 기록, 회의 기록, 책, 기사, 블로그 게시물 및 기타 관련 콘텐츠를 요약하는 데 사용할 수 있습니다.\n",
    "\n",
    "### 과제\n",
    "이 접근 방식은 입력 텍스트나 파일이 모델 컨텍스트 길이 내에 맞을 때 사용할 수 있습니다. `02.long-text-summarization-titan.ipynb` 노트북에서는 사용자가 토큰 제한을 초과하는 대용량 문서를 가지고 있을 때 이 과제를 해결하는 접근 방식을 탐구할 것입니다.\n",
    "\n",
    "\n",
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3c832e8-71c6-4b85-b78d-6ffc04e3592e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.3 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "notebook 6.5.6 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.4.0 which is incompatible.\n",
      "notebook 6.5.6 requires pyzmq<25,>=17, but you have pyzmq 25.1.1 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.16.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires jupyter-client<8,>=7.3.4; python_version >= \"3\", but you have jupyter-client 8.4.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U boto3 botocore --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5087fdb1-019d-493a-bef1-8792c9997627",
   "metadata": {},
   "source": [
    "#### 이제 Boto3를 사용하여 아마존 베드록 SDK에 대한 연결을 설정해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad12942-77ab-484f-9be5-977820bb476b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json \n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342796d0",
   "metadata": {},
   "source": [
    "## Boto3를 사용한 짧은 텍스트 요약\n",
    " \n",
    "아마존 베드록에 대한 API 요청의 세부 사항을 알아보기 위해, 이 노트북에서는 Boto3 작업을 감싸서 더 간단한 API를 제공하는 langchain에 의존하기보다는 Boto3를 통해 API 요청을 생성하고 전송하는 방법을 소개합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4d9ee",
   "metadata": {},
   "source": [
    "### Boto3의 InvokeModel 요청 구문\n",
    "\n",
    "\n",
    "파운데이션 모델에 요청을 보내기 위해 `InvokeModel` API를 사용합니다. 다음은 아마존 타이탄 텍스트 라지에 텍스트를 보내는 API 요청의 예시입니다. `textGenerationConfig`의 추론 매개변수는 사용하려는 모델에 따라 다릅니다. 아마존 타이탄 텍스트의 추론 매개변수는 다음과 같습니다.\n",
    "- **maxTokenCount**는 생성된 응답에서 사용할 최대 토큰 수를 구성합니다. (정수, 기본값 512)\n",
    "- **stopSequences**는 문장이나 목록의 끝과 같은 원하는 지점에서 모델을 중지시키는 데 사용됩니다. 반환된 응답에는 중지 시퀀스가 포함되지 않습니다.\n",
    "- **temperature**는 다음 토큰에 대한 확률 밀도 함수를 조절하여 temperature 샘플링 기법을 구현합니다. 이 매개변수를 사용하여 밀도 함수 곡선을 깊게 하거나 평평하게 만들 수 있습니다. 낮은 값은 더 가파른 곡선과 더 결정론적인 응답을 만들고, 높은 값은 더 평평한 곡선과 더 무작위적인 응답을 만듭니다. (부동 소수점, 기본값 0, 최대값 1.5)\n",
    "- **topP**는 잠재적 선택의 확률을 기반으로 토큰 선택을 제어합니다. Top P를 1.0 미만으로 설정하면 모델은 가장 확률이 높은 옵션만 고려하고 확률이 낮은 옵션은 무시합니다. 결과적으로 더 안정적이고 반복적인 완성이 됩니다.\n",
    "\n",
    "```python\n",
    "response = bedrock_runtime.invoke_model(body={\n",
    "                                   \"inputText\": \"this is where you place your input text\",\n",
    "                                   \"textGenerationConfig\": {\n",
    "                                       \"maxTokenCount\": 4096,\n",
    "                                       \"stopSequences\": [],\n",
    "                                       \"temperature\":0,\n",
    "                                       \"topP\":1\n",
    "                                       },\n",
    "                                },\n",
    "                                modelId=\"amazon.titan-text-express-v1\", \n",
    "                                accept=accept, \n",
    "                                contentType=contentType)\n",
    "\n",
    "```\n",
    "\n",
    "### 요약할 텍스트와 함께 프롬프트 작성하기\n",
    "\n",
    "이 노트북에서는 토큰 수가 파운데이션 모델의 최대 토큰 수보다 적은 모든 짧은 텍스트를 사용할 수 있습니다. 짧은 텍스트의 예시로, 아마존 베드록 발표에 관한 [AWS 블로그 게시물](https://aws.amazon.com/jp/blogs/machine-learning/announcing-new-tools-for-building-with-generative-ai-on-aws/)의 한 단락을 사용해 보겠습니다.\n",
    "\n",
    "프롬프트는 `Please provide a summary of the following text.`라는 지시로 시작하고, `<text>` 태그로 둘러싸인 텍스트를 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece0c069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Please provide a summary of the following text. Do not add any information that is not mentioned in the text below.\n",
    "\n",
    "<text>\n",
    "AWS took all of that feedback from customers, and today we are excited to announce Amazon Bedrock, \\\n",
    "a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. \\\n",
    "Bedrock is the easiest way for customers to build and scale generative AI-based applications using FMs, \\\n",
    "democratizing access for all builders. Bedrock will offer the ability to access a range of powerful FMs \\\n",
    "for text and images—including Amazons Titan FMs, which consist of two new LLMs we’re also announcing \\\n",
    "today—through a scalable, reliable, and secure AWS managed service. With Bedrock’s serverless experience, \\\n",
    "customers can easily find the right model for what they’re trying to get done, get started quickly, privately \\\n",
    "customize FMs with their own data, and easily integrate and deploy them into their applications using the AWS \\\n",
    "tools and capabilities they are familiar with, without having to manage any infrastructure (including integrations \\\n",
    "with Amazon SageMaker ML features like Experiments to test different models and Pipelines to manage their FMs at scale).\n",
    "</text>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efddbb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 프롬프트와 추론 매개변수로 요청 본문 생성하기\n",
    "\n",
    "`invoke_model`의 요청 구문에 따라, 위의 프롬프트와 추론 매개변수를 사용하여 요청 본문을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d191eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "body = json.dumps({\"inputText\": prompt, \n",
    "                   \"textGenerationConfig\":{\n",
    "                       \"maxTokenCount\":4096,\n",
    "                       \"stopSequences\":[],\n",
    "                       \"temperature\":0,\n",
    "                       \"topP\":1\n",
    "                   },\n",
    "                  }) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f3326",
   "metadata": {},
   "source": [
    "## Boto3를 통해 파운데이션 모델 호출하기\n",
    "\n",
    "여기서는 `modelId`, `accept`, `contentType`과 같은 요청 매개변수를 지정하여 아마존 베드록에 API 요청을 보냅니다. 프롬프트에 따라 아마존 베드록의 파운데이션 모델이 텍스트를 요약합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f400d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS has announced Amazon Bedrock, a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. It will offer the ability to access a range of powerful FMs for text and images through a scalable, reliable, and secure AWS managed service. Customers can easily find the right model for what they're trying to get done, get started quickly, privately customize FMs with their own data, and easily integrate and deploy them into their applications using the AWS tools and capabilities they are familiar with, without having to manage any infrastructure.\n"
     ]
    }
   ],
   "source": [
    "modelId = 'amazon.titan-text-express-v1' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "print(response_body.get('results')[0].get('outputText'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c527882",
   "metadata": {},
   "source": [
    "위의 예시에서 베드록 서비스는 주어진 프롬프트에 대한 전체 요약을 단일 출력으로 생성합니다. 이는 출력에 많은 양의 토큰이 포함된 경우 느릴 수 있습니다.\n",
    "\n",
    "아래에서는 베드록을 사용하여 출력을 스트리밍하는 방법을 탐색해 보겠습니다. 이를 통해 사용자는 모델이 생성하는 대로 출력을 소비하기 시작할 수 있습니다. 이를 위해 베드록은 `invoke_model_with_response_stream` API를 지원하며, 이는 출력을 청크 형태로 스트리밍하는 `ResponseStream`을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62787950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk': {'bytes': b'{\"outputText\":\"AWS has announced Amazon Bedrock, a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. It will offer the ability to access a range of powerful F\",\"index\":0,\"totalOutputTextTokenCount\":null,\"completionReason\":null,\"inputTextTokenCount\":255}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"Ms for text and images through a scalable, reliable, and secure AWS managed service. Customers can easily find the right model for what they\\'re trying to get done, get started quickly, privately customize FMs with their own data, and easily integrate and deploy them into their applications using the AWS tools and capabilities they are familiar with, without having to manage any infrastructure.\",\"index\":0,\"totalOutputTextTokenCount\":119,\"completionReason\":\"FINISH\",\"inputTextTokenCount\":null,\"amazon-bedrock-invocationMetrics\":{\"inputTokenCount\":255,\"outputTokenCount\":119,\"invocationLatency\":3573,\"firstByteLatency\":2162}}'}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = list(stream)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4a584",
   "metadata": {},
   "source": [
    "전체 출력을 한 번에 생성하는 대신, 베드록은 모델로부터 더 작은 청크를 보냅니다. 이는 사용자가 소비할 수 있는 방식으로 표시될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc08b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown, Markdown, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b84ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS has announced Amazon Bedrock, a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. It will offer the ability to access a range of powerful FMs for text and images through a scalable, reliable, and secure AWS managed service. Customers can easily find the right model for what they're trying to get done, get started quickly, privately customize FMs with their own data, and easily integrate and deploy them into their applications using the AWS tools and capabilities they are familiar with, without having to manage any infrastructure.\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = []\n",
    "i = 1\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "            text = chunk_obj['outputText']\n",
    "            clear_output(wait=True)\n",
    "            output.append(text)\n",
    "            display_markdown(Markdown(''.join(output)))\n",
    "            i+=1\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(''.join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a93aeb",
   "metadata": {},
   "source": [
    "## 결론\n",
    "이제 아마존 베드록 API에 대한 기본적인 접근을 제공하는 `boto3` SDK를 사용하는 실험을 해보았습니다. 이 API를 사용하여 아마존 베드록에 관한 AWS 뉴스의 요약을 전체 출력 생성과 스트리밍 출력 생성이라는 두 가지 다른 방식으로 생성하는 사용 사례를 보았습니다.\n",
    "\n",
    "### 주요 내용\n",
    "- 이 노트북 수정을 통한 앤트로픽 클로드와 AI21 Labs의 Jurassic 모델과 같은 아마존 베드록의 다양한 모델 실험\n",
    "- 특정 사용 사례에 맞는 프롬프트 변경 및 다양한 모델 출력 평가\n",
    "- 토큰 길이 조정을 통한 서비스의 처리 속도와 반응성 이해\n",
    "- 더 나은 출력을 위한 다양한 프롬프트 엔지니어링 원칙 적용"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
