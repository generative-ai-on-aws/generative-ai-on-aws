{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15f81e3-0976-4ff7-8ae1-ddb5fbdf1d94",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bedrock Prompt Examples for Travel\n",
    "\n",
    "In this notebook, we include different example use cases for Travel & Hospitality using Amazon Bedrock.\n",
    "\n",
    "These sample use cases involve different tasks and prompt engeering techniques, as follows:\n",
    "1. **Generate recommendations based on metadata**\n",
    "    - **Task:** Text Generation\n",
    "    - **Prompt Technique:** Zero-shot\n",
    "2. **Estimate capacity for airlines or hotel properties based on historical data**\n",
    "    - **Task:** Complex Reasoning\n",
    "    - **Prompt Technique:** Chain-of-Thoughts (CoT)\n",
    "3. **Create a question answering assistant for customer service**\n",
    "    - **Task:** Question Answering with Dialogue Asistant (without memory)\n",
    "    - **Prompt Technique:** Few-shot\n",
    "4. **Summarize and classify content from media files transcription**\n",
    "    - **Task:** Text Summarization & Text Classification\n",
    "    - **Prompt Technique:** Zero-shot\n",
    "5. **Create splash pages describing upcoming promotions**\n",
    "    - **Task:** Code Generation\n",
    "    - **Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d5cb2-3c3a-4091-a11f-1df62d9e0d1d",
   "metadata": {},
   "source": [
    "Let's start by ensuring the Bedrock SDK is properly installed.\n",
    "\n",
    "We'll also install a few libraries required in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800edbd3-f31c-436c-93e4-a3e791c85549",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!unzip ../bedrock-preview-documentation/SDK/bedrock-python-sdk.zip -d /root/bedrock\n",
    "\n",
    "#!pip install --upgrade pip\n",
    "#!pip install scikit-learn seaborn\n",
    "\n",
    "#!pwd\n",
    "#!python3 -m pip install /root/bedrock/boto3-1.26.142-py3-none-any.whl\n",
    "#!python3 -m pip install /root/bedrock/botocore-1.29.142-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3767a6-e9bb-4de4-a325-9d346b082402",
   "metadata": {},
   "source": [
    "Now we can import the libraries and setup the Bedrock client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d82998-f5d1-4624-a54f-f9d04422b8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "bedrock = boto3.client(\n",
    " service_name='bedrock',\n",
    " region_name='us-east-1',\n",
    " endpoint_url='https://bedrock.us-east-1.amazonaws.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5ecac-8a9d-42b8-b1c7-8ecad5610314",
   "metadata": {},
   "source": [
    "Let's get the list of Foundational Models supported in Bedrock at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c10722be-2f83-4f8c-89a4-7d9b181029f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f0d858da-ce48-42af-9236-79d0aab293f8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Tue, 27 Jun 2023 11:11:50 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '861',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'f0d858da-ce48-42af-9236-79d0aab293f8'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large',\n",
       "   'modelId': 'amazon.titan-tg1-large'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-e1t-medium',\n",
       "   'modelId': 'amazon.titan-e1t-medium'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl',\n",
       "   'modelId': 'stability.stable-diffusion-xl'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-grande-instruct',\n",
       "   'modelId': 'ai21.j2-grande-instruct'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-jumbo-instruct',\n",
       "   'modelId': 'ai21.j2-jumbo-instruct'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1',\n",
       "   'modelId': 'anthropic.claude-instant-v1'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v1',\n",
       "   'modelId': 'anthropic.claude-v1'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b05c03-98a6-4fc1-a288-1e43326383fe",
   "metadata": {},
   "source": [
    "We will define an utility function for calling Bedrock.\n",
    "\n",
    "This will help passing the proper body depending on the model invoked, and will store the results in a CSV file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968017bf-c186-4897-8a38-ecdbe276b6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_bedrock(modelId, prompt_data):\n",
    "    if 'amazon' in modelId:\n",
    "        body = json.dumps({\n",
    "            \"inputText\": prompt_data,\n",
    "            \"textGenerationConfig\":\n",
    "            {\n",
    "                \"maxTokenCount\":4096,\n",
    "                \"stopSequences\":[],\n",
    "                \"temperature\":0,\n",
    "                \"topP\":0.9\n",
    "            }\n",
    "        })\n",
    "        #modelId = 'amazon.titan-tg1-large'\n",
    "    elif 'anthropic' in modelId:\n",
    "        body = json.dumps({\n",
    "            \"prompt\": prompt_data,\n",
    "            \"max_tokens_to_sample\": 4096,\n",
    "            \"stop_sequences\":[],\n",
    "            \"temperature\":0,\n",
    "            \"top_p\":0.9\n",
    "        })\n",
    "        #modelId = 'anthropic.claude-instant-v1'\n",
    "    elif 'ai21' in modelId:\n",
    "        body = json.dumps({\n",
    "            \"prompt\": prompt_data,\n",
    "            \"maxTokens\":4096,\n",
    "            \"stopSequences\":[],\n",
    "            \"temperature\":0,\n",
    "            \"topP\":0.9\n",
    "        })\n",
    "        #modelId = 'ai21.j2-grande-instruct'\n",
    "    elif 'stability' in modelId:\n",
    "        body = json.dumps({\"text_prompts\":[{\"text\":prompt_data}]}) \n",
    "        #modelId = 'stability.stable-diffusion-xl'\n",
    "    else:\n",
    "        print('Parameter model must be one of titan, claude, j2, or sd')\n",
    "        return\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    before = datetime.now()\n",
    "    response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    latency = (datetime.now() - before)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    if 'amazon' in modelId:\n",
    "        response = response_body.get('results')[0].get('outputText')\n",
    "    elif 'anthropic' in modelId:\n",
    "        response = response_body.get('completion')\n",
    "    elif 'ai21' in modelId:\n",
    "        response = response_body.get('completions')[0].get('data').get('text')\n",
    "\n",
    "    #Add interaction to the local CSV file...\n",
    "    #column_name = [\"timestamp\", \"modelId\", \"prompt\", \"response\", \"latency\"] #The name of the columns\n",
    "    #data = [datetime.now(), modelId, prompt_data, response, latency] #the data\n",
    "    #with open('./prompt-data/prompt-data.csv', 'a') as f:\n",
    "    #    writer = csv.writer(f)\n",
    "    #    #writer.writerow(column_name)\n",
    "    #    writer.writerow(data)\n",
    "    \n",
    "    return response, latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa97f20-81c4-426c-b867-8400be5aea33",
   "metadata": {},
   "source": [
    "Now we are ready for running our examples with different models.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad9ab5-e0ef-4741-b305-36053150e2c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Generate recommendations based on metadata\n",
    "\n",
    "**Use Case:** A company wants to generate recommendations of flight destinations for their users based on some metadata, e.g. country, age-range, and interests.\n",
    "\n",
    "**Task:** Text Generation\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "382d9a5e-bb64-4af1-95dc-56f8a6ff3990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Human:\n",
    "Generate a list of 10 recommended destinations for traveling considering the information in the <metadata></metadata> XML tags, and include a very brief description of each recommendation.\n",
    "\n",
    "<metadata>\n",
    "Passenger country is Spain\n",
    "Age range between 20-30\n",
    "Interested on water sports and theme parks\n",
    "Traveling during the summer\n",
    "</metadata>\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e14520a-990d-46b0-a660-3ea1b5a0f75d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a list of 10 recommended destinations for traveling based on the provided metadata:\n",
      "\n",
      "1. Hawaii - Beautiful beaches, surfing, and vibrant culture. Home to massive water parks and theme parks. \n",
      "2. Bali, Indonesia - Exotic island with stunning beaches, jungles, and rice paddies. Plenty of opportunities for snorkeling, boating, and other watersports. Also home to an exciting theme park.\n",
      "3. Orlando, Florida - Theme park capital of the world, including Walt Disney World and Universal Studios. Also close to beautiful beaches on the Gulf coast. \n",
      "4. Costa Rica - Pristine natural scenery, rainforests, and beaches along both the Pacific and Caribbean coasts. Eco-friendly destination for watersports and adventure activities.  \n",
      "5. Dubai, UAE - Glamorous city in the desert with massive water parks, indoor skiing, and the world's tallest rollercoaster. Also a hub for boating, jet skiing, and other watersports.\n",
      "6. Queensland, Australia - Miles of beaches along the Great Barrier Reef, perfect for swimming, snorkeling, sailing, and surfing. Also home to major theme parks like Sea World, Dreamworld, and Wet'n'Wild.\n",
      "7. Phuket, Thailand - Thailand's largest island in the Andaman Sea with scenic beaches, watersports, boat tours, and the Phuket FantaSea cultural theme park.\n",
      "8. Barcelona, Spain - Stylish city on the Mediterranean coast with a popular beachfront and nearby theme park. Close to the resort town of Salou, which offers more beaches, watersports, and the PortAventura theme park.\n",
      "9. Canary Islands, Spain - Archipelago off the coast of Morocco with a subtropical climate, volcanic landscapes, and beaches. Major destinations like Tenerife and Gran Canaria offer watersports, boating, and theme parks like Siam Park and Loro Parque. \n",
      "10. Algarve, Portugal - Southern region of Portugal centered around the Algarve coast, featuring stunning beaches, caves, and opportunities for swimming, surfing, kayaking, and other watersports. Also home to Zoomarine and Aquashow theme parks. \n",
      "\n",
      " Inference time: 0:00:12.102331\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ebf06a-1cf5-450c-953e-1cd1abe70f27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are 10 recommended destinations for traveling:\n",
      "\n",
      "Dubai - An ultramodern city with amazing architecture, shopping malls, and water parks.  \n",
      "\n",
      "Maldives - A tropical paradise with beautiful beaches, crystal clear water for snorkeling, and overwater bungalows.\n",
      "\n",
      "Orlando, Florida - Home to many theme parks like Disney World, Universal Studios, and SeaWorld with roller coasters and water rides.   \n",
      "\n",
      "Bali, Indonesia - Tropical island known for its beaches, surfing, water sports, and Hindu culture.\n",
      "\n",
      "Phuket, Thailand - Beautiful beaches, waterfalls, and islands for snorkeling and diving near Phuket's lively city.   \n",
      "\n",
      "Barcelona, Spain - Home city with beautiful architecture, beaches, and theme parks like PortAventura.\n",
      "\n",
      "Ibiza, Spain - Famous for nightlife but also has beautiful beaches and coves for swimming and water sports.\n",
      "\n",
      "Miami, Florida - Beaches, art deco architecture, theme parks like Wet n Wild, and many water activities.   \n",
      "\n",
      "Cancun, Mexico - Long stretches of white sand beaches, turquoise water for swimming, and water parks.\n",
      "\n",
      "Santorini, Greece - Stunning caldera views, beaches for swimming, and volcanic black sand beaches. \n",
      "\n",
      " Inference time: 0:00:03.779193\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847647f-94e4-4a47-9cd2-2609af023546",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde01ec0-52c2-471e-aaf4-b4803085f162",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Estimate capacity for airlines or hotel properties based on historical data\n",
    "\n",
    "**Use Case:** A T&H company wants to estimate capacity/occupancy levels they could have for the next days based on historical information and flights/hotels metadata.\n",
    "\n",
    "**Task:** Complex Reasoning\n",
    "\n",
    "**Prompt Technique:** Chain-of-Thoughts (CoT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f8993b8-2772-4c33-b17b-7fbddb9b7e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Human: Last week, the passengers of 3 routes of an airline were according to the following data:\n",
    "- Monday: Paris 650, New York 320, Singapore 415\n",
    "- Tuesday: Paris 640, New York 330, Singapore 410\n",
    "- Wednesday: Paris 630, New York 340, Singapore 425\n",
    "\n",
    "Question: How many passengers can we expect next Friday on the route to Paris?\n",
    "Answer: According to the numbers given and without having more information, there is a daily decrease of 10 passengers for the route to Paris.\n",
    "If we assume that this trend will continue during the following days, we can expect 620 passengers for the next day which is Thursday and,\n",
    "therefore, 610 passengers for Friday.\n",
    "\n",
    "Question: How many passengers can we expect on Saturday on each of the routes? Reason step by step and provide recommendations to increase the passengers\n",
    "Assistant:\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732984e8-2c6d-4b45-9b77-90e856c2b10e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- For the Paris route: There is a daily decrease of 10 passengers. Since Friday had 610 passengers, we can expect 600 passengers on Saturday.\n",
      "- For the New York route: There is a daily increase of 10 passengers. Since Friday had 340 passengers, we can expect 350 passengers on Saturday.\n",
      "- For the Singapore route: There is no clear trend. The numbers go up and down between 410 to 425 passengers. Without more data, the best assumption is to expect around 420 passengers on Saturday.\n",
      "\n",
      "Recommendations to increase passengers:\n",
      "\n",
      "1. Offer promotions and discounts: This can attract more customers to choose these routes, especially for Paris and Singapore where the numbers are decreasing or unstable.\n",
      "\n",
      "2. Improve service quality: Better service and experience can lead to higher customer satisfaction and loyalty. This can translate to repeat customers and word-of-mouth marketing to new potential customers. \n",
      "\n",
      "3. Optimize flight schedules: Review the flight schedules and frequencies to ensure they are convenient and suitable for customers. Add more flights during peak periods.\n",
      "\n",
      "4. Targeted marketing: The airline can analyze their customer base and target market to customize marketing campaigns for each route. For example, market the Paris route to honeymooners and couples. Market the Singapore route to business travelers. This can boost demand.\n",
      "\n",
      "5. Explore new markets: The airline may be able to tap into new markets that currently do not have direct access to these routes. For example, market the Paris route to customers from North Africa or the Middle East. Market the New York route to South Americans. New markets can increase the potential customer base.\n",
      "\n",
      "In summary, by offering better value and service to customers, optimizing operations, and strategic marketing to new and existing markets, the airline should be able to boost demand and increase passenger numbers for these routes over time. But it will require continuous effort and innovation. \n",
      "\n",
      " Inference time: 0:00:15.236301\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70e8bc44-aa79-4bbd-b5b7-52be3c0f51d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given data and trend, we can estimate the number of passengers for Saturday as follows:\n",
      "\n",
      "Paris route:\n",
      "- Monday: 650 passengers\n",
      "- Tuesday: 640 passengers  (a decrease of 10 passengers from Monday)\n",
      "- Wednesday: 630 passengers (a decrease of 10 passengers from Tuesday)\n",
      "- Thursday (estimated): 620 passengers (a decrease of 10 passengers from Wednesday)\n",
      "- Friday (estimated): 610 passengers (a decrease of 10 passengers from Thursday)\n",
      "- Saturday (estimated): 600 passengers (a decrease of 10 passengers from Friday)\n",
      "\n",
      "New York route:\n",
      "- Monday: 320 passengers\n",
      "- Tuesday: 330 passengers (an increase of 10 passengers from Monday)  \n",
      "- Wednesday: 340 passengers (an increase of 10 passengers from Tuesday)\n",
      "- Assuming the same trend continues:\n",
      "Thursday (estimated): 350 passengers (an increase of 10 passengers from Wednesday)\n",
      "Friday (estimated): 360 passengers (an increase of 10 passengers from Thursday)  \n",
      "Saturday (estimated): 370 passengers (an increase of 10 passengers from Friday)\n",
      "\n",
      "Singapore route:\n",
      "- Monday: 415 passengers\n",
      "- Tuesday: 410 passengers (a decrease of 5 passengers from Monday)\n",
      "- Wednesday: 425 passengers (an increase of 15 passengers from Tuesday)\n",
      "- Assuming the same trend continues:\n",
      "Thursday (estimated): 440 passengers (an increase of 15 passengers from Wednesday)\n",
      "Friday (estimated): 455 passengers (an increase of 15 passengers from Thursday)\n",
      "Saturday (estimated): 470 passengers (an increase of 15 passengers from Friday)\n",
      "\n",
      "To increase the number of passengers, some recommendations are:\n",
      "- Offer promotional fares and discounts\n",
      "- Run advertising and marketing campaigns  \n",
      "- Improve customer service and onboard experience\n",
      "- Add more flight options and frequencies on popular routes\n",
      "- Partner with travel agencies and companies for corporate bookings \n",
      "\n",
      " Inference time: 0:00:04.018523\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253149f-ae27-42d0-a36c-bd07fc22264c",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f45c25-cb45-4d9d-8cb1-29b3547483b3",
   "metadata": {},
   "source": [
    "## 3. Create a question answering assistant for customer service\n",
    "\n",
    "**Use Case:** A company wants to create a bot capable of answering questions about the services available, based on the internal information for these.\n",
    "\n",
    "**Task:** Question Answering with Dialogue Asistant (no memory)\n",
    "\n",
    "**Prompt Technique:** Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b5cc7e9-876e-4d77-99cd-099439033148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "Context: An airline services available for purchase are as follows\n",
    "1. Seat upgrades, available from 20 Euros, to classes Economy Plus and Business, on weekdays' flights\n",
    "2. Meals, available for payment in-flight, mediterranean menu, on all days' flights\n",
    "3. Fast boarding, from 30 Euros, available for premier customers, on all days' flights\n",
    "\n",
    "Instruction: Answer any questions about the services available in a friendly manner. If you don't know the answer just say 'Apologies, but I don't have the answer for that. Please contact our team by phone.'\n",
    "\n",
    "Assistant: Welcome to Airline Services, how can I help you?\n",
    "Human: Hi, I would like to know what are the services available please.\n",
    "Assistant: Of course, right now we have the seat upgrades, the meals, and the fast boarding.\n",
    "Human: Thank you. I would like to know details for those please.\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceae8a78-c7d2-470d-82da-8f08677cb469",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Certainly, here are the details for our available services:\n",
      "\n",
      "Seat upgrades:\n",
      "- Economy Plus upgrade: Extra legroom seats, available for 20 Euros on weekdays' flights. \n",
      "- Business class upgrade: Wider, more comfortable seats, available for 50-100 Euros depending on the route, on weekdays' flights.\n",
      "\n",
      "Meals:\n",
      "- Mediterranean menu: A selection of meals like pasta, pizza, paninis available for around 10 Euros, on all days' flights.\n",
      "\n",
      "Fast boarding:\n",
      "- For our premier customers, fast boarding option allows you to board the plane before general boarding, available for 30 Euros on all days' flights.\n",
      "\n",
      "Does this help explain our services? Let me know if you have any other questions. \n",
      "\n",
      " Inference time: 0:00:04.445540\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78d63227-09c8-4ea6-bf13-712b837a934c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are the details:\n",
      "\n",
      "1. Seat upgrades, available from 20 Euros, to classes Economy Plus and Business, on weekdays' flights. This allows you to move to a more spacious seat with extra legroom.\n",
      "\n",
      "2. Meals, available for payment in-flight, mediterranean menu, on all days' flights. You can choose from a selection of meals like pasta, salad, sandwiches, etc. \n",
      "\n",
      "3. Fast boarding, from 30 Euros, available for premier customers, on all days' flights. This allows you to board the plane before other passengers so you can get settled in quickly.\n",
      "\n",
      "Please let me know if you need any clarification or have additional questions. I'm happy to help. \n",
      "\n",
      " Inference time: 0:00:01.706800\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130aa69b-0ec0-4837-a019-fb16fca9fb0e",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80a21f-7987-40d0-b923-193c72367f7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Generate content summary based on transcriptions from media files\n",
    "\n",
    "**Use Case:** A company needs to generate summaries of the audio transcription for audio and video files for customer service, to be sent to their operations quality team. They also want to classify this content according to specific categories.\n",
    "\n",
    "**Task:** Text Summarization & Text Classification\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374d510-d20d-4820-96d6-156977876859",
   "metadata": {},
   "source": [
    "#### (Pre-requisite)\n",
    "\n",
    "First, we will need to transcribe the media files. You can e.g. use Amazon Transcribe for this task following examples like this: https://docs.aws.amazon.com/code-library/latest/ug/transcribe_example_transcribe_StartTranscriptionJob_section.html\n",
    "\n",
    "For our sample we will start from an interview transcription in the file \"interview.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edaa1e2c-6de3-4b24-805f-2090fd7909b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jimmy Fallon: (00:00)\n",
      "Thank you for doing This Christmas Will Be Different. I appreciate you doing that. We hung out all day together.\n",
      "\n",
      "Matthew McConaughey: (00:04)\n",
      "How fun was that?\n",
      "\n",
      "Jimmy Fallon: (00:05)\n",
      "It was the greatest. We always…\n",
      "\n",
      "Matthew McConaughey: (00:07)\n",
      "Two take maximum. Two take maximum.\n",
      "\n",
      "Jimmy Fallon: (00:09)\n",
      "We nailed it, we have some good takes. That was so much fun. Happy holidays to you and your family. I’m happy to see you in person. Thanks for making the trip and being here.\n",
      "\n",
      "Matthew McConaughey: (00:18)\n",
      "Absolutely.\n",
      "\n",
      "Jimmy Fallon: (00:19)\n",
      "Do you have like family traditions? Do you have holiday plans? What do you have coming up?\n",
      "\n",
      "Matthew McConaughey: (00:24)\n",
      "This year, we’re going to get all the McConaughey family. We’re also getting Camila’s family. So when we do that and we have that multicultural Christmas, Christmas lasts a long time at our place because they celebrate on the 24th. Midnight you exchange presents. All right. So you have the big sit down dinner, you get the china out for the first time all year. If it was up to my family, it’d be paper plates. Thank you, Camila for getting the china out and having a better ritual.\n",
      "\n",
      "Jimmy Fallon: (00:50)\n",
      "No, we are using china.\n",
      "\n",
      "Matthew McConaughey: (00:51)\n",
      "Yes.\n",
      "\n",
      "Jimmy Fallon: (00:52)\n",
      "Thank you, Camila.\n",
      "\n",
      "Matthew McConaughey: (00:53)\n",
      "We do that that night. And then we get up the next day and we do our Christmas, which is everyone opens present. Santa came. The problem, the reason I say it’s longer already is that my mother who’s 90 still demands that everyone open their present and everyone watch one person open their present at the time.\n",
      "\n",
      "Jimmy Fallon: (01:09)\n",
      "Yeah. Yeah.\n",
      "\n",
      "Matthew McConaughey: (01:10)\n",
      "You’ve got a big Brazilian family, you’ve got a big McConaughey family, there’s a family of 20. There’s a lot of presents, thankfully. It may be dark on the 25th when we’re done opening presents from that morning. And so seven o’clock PM and you just finished opening presents from Christmas morning. So the nights get long.\n",
      "\n",
      "Jimmy Fallon: (01:26)\n",
      "My grandma used to do this thing where we would unwrap the presents. She goes, can you just not rip it just so I can reuse the wrapping.\n",
      "\n",
      "Matthew McConaughey: (01:32)\n",
      "Save the wrapping.\n",
      "\n",
      "Jimmy Fallon: (01:33)\n",
      "Save the wrap for the next year. I go, yes, okay, grandma.\n",
      "\n",
      "Matthew McConaughey: (01:36)\n",
      "It’s 3:00 PM.\n",
      "\n",
      "Jimmy Fallon: (01:36)\n",
      "Let’s go. Let’s open up the thing. Yeah. It’s so fun. I look forward to it. Are you a guy that makes New Year’s resolutions?\n",
      "\n",
      "Matthew McConaughey: (01:43)\n",
      "Yeah. I check in on myself.\n",
      "\n",
      "Jimmy Fallon: (01:46)\n",
      "You check in on yourself.\n",
      "\n",
      "Matthew McConaughey: (01:49)\n",
      "I asked myself to work on my patience last year on New Year’s Eve.\n",
      "\n",
      "Jimmy Fallon: (01:55)\n",
      "We all need to do that.\n",
      "\n",
      "Matthew McConaughey: (01:57)\n",
      "And now thank you for reminding me, I guess tonight, I’ll start thinking about how I’ve done the last 11 months.\n",
      "\n",
      "Jimmy Fallon: (02:01)\n",
      "Exactly right. Well, I think last time we talked, I mean, congratulations, your book, Green Lights, was on the New York Times’ bestseller list 50, 5-0, 50 weeks. It sold like two and a half million copies. It is a giant, giant hit. But congratulations. I loved it.\n",
      "\n",
      "Matthew McConaughey: (02:18)\n",
      "Thank you.\n",
      "\n",
      "Jimmy Fallon: (02:19)\n",
      "Did you realize it would take off like that? I mean so many people.\n",
      "\n",
      "Matthew McConaughey: (02:22)\n",
      "I had no idea.\n",
      "\n",
      "Jimmy Fallon: (02:23)\n",
      "It’s massive.\n",
      "\n",
      "Matthew McConaughey: (02:24)\n",
      "It hit a nerve. Thank you everyone out there who had a read of it.\n",
      "\n",
      "Jimmy Fallon: (02:29)\n",
      "It was so honest and it was so… I loved it. I told you as soon as I read it, I couldn’t stop reading it. I go, oh, it’s so personal, but it’s so also universal.\n",
      "\n",
      "Matthew McConaughey: (02:39)\n",
      "Yep. I think that’s what people got from it. People said, hey, I see myself and you, I see my stories in your stories. And it kind of lays out a map of process. It’s a process book. It’s not a product book. It’s a approach to life with this rodeo we’re all trying to get through and trying to get our eight seconds on. How can we do our best to get it?\n",
      "\n",
      "Jimmy Fallon: (02:59)\n",
      "You’re coming out with a journal now, a companion journal to help people. Because I think you were saying in the book too, it’s tough when you write to just tell someone, hey, just write something down every day or every night.\n",
      "\n",
      "Matthew McConaughey: (03:12)\n",
      "A blank sheet of paper intimidates the heck out of us. Right?\n",
      "\n",
      "Jimmy Fallon: (03:15)\n",
      "It does.\n",
      "\n",
      "Matthew McConaughey: (03:15)\n",
      "But journaling or writing things down I’ve done it all my life and it’s how I wrote Green Lights the book. Immensely valuable. I mean, I write things down to forget. If you write them down, you can forget them because they’re in there. Don’t just go to the diary or the journal to write down when you’re frustrated and confused. Go to the journal to write down what you’re doing in life when you’re rolling, when you’re catching green lights, when you’re in the flow, because we will get out of flow again. And it’s nice to have a document to go back and go, hoo, what was I doing when I was cruising?\n",
      "\n",
      "Jimmy Fallon: (03:44)\n",
      "Yeah. When life was perfect there in that moment.\n",
      "\n",
      "Matthew McConaughey: (03:46)\n",
      "You see habits and you can change and recalibrate. But yeah, it’s a journal. I got little nudges along the way that kind of help you and ask you some questions to write your story. The book Green Lights was my story. This is for your story.\n",
      "\n",
      "Jimmy Fallon: (03:57)\n",
      "Ah, I love that buddy. That’s awesome. Congrats on that.\n",
      "\n",
      "Matthew McConaughey: (04:02)\n",
      "Thank you.\n",
      "\n",
      "Jimmy Fallon: (04:03)\n",
      "We also, you were nice enough to Zoom into us when we couldn’t get any guests anywhere. No one was allowed to travel or do anything, but there was talk of you maybe running for governor of Texas and you recently decided to not run for governor.\n",
      "\n",
      "Matthew McConaughey: (04:17)\n",
      "Yes.\n",
      "\n",
      "Jimmy Fallon: (04:17)\n",
      "Can you walk us through that decision?\n",
      "\n",
      "Matthew McConaughey: (04:19)\n",
      "Well, it was a to two year consideration that I came to the decision really over the last couple of months. And I was asking myself the original question and trying to answer it, how and where and what can I do to be most useful to myself, to my family and to the most amount of people. The embassy, the category of politics came up and it’s a privileged one that I gave great consideration to. But at this point in my life are the things I’ve got a 13 year old, 11 year old and an eight year old, the life I’m living right now, the storytelling I want to keep doing, it’s not the category for me at this point in my life.\n",
      "\n",
      "Jimmy Fallon: (04:51)\n",
      "Still not ruling out future.\n",
      "\n",
      "Matthew McConaughey: (04:53)\n",
      "I’m not until I am.\n",
      "\n",
      "Jimmy Fallon: (04:55)\n",
      "Okay.\n",
      "\n",
      "Matthew McConaughey: (04:56)\n",
      "Someone told me that was a very McConaughey answer the other day.\n",
      "\n",
      "Jimmy Fallon: (04:59)\n",
      "Not until I am. It’s very, yeah.\n",
      "\n",
      "Matthew McConaughey: (05:02)\n",
      "I’ll be keeping an eye open for-\n",
      "\n",
      "Jimmy Fallon: (05:03)\n",
      "Because I know Texas loves you. And when we did the show from Texas, you were nice enough to come on the show and gosh, you’re beloved down there as well. You think people love you here, standing ovations. They love you there.\n",
      "\n",
      "Matthew McConaughey: (05:15)\n",
      "It’s a great state.\n",
      "\n",
      "Jimmy Fallon: (05:16)\n",
      "I know you put on a benefit concert. What’s [inaudible 00:05:20] We’re Texas. After that rough, awful, devastating…\n",
      "\n",
      "Matthew McConaughey: (05:25)\n",
      "Winter storm Uru came through. We’re not used to winter storms like that in Texas. Okay. We were a bit awkward. We weren’t prepared. And a lot of people were out of home. A lot of people were out of school. A lot of people needed some help because they didn’t know how to deal with it. And so we, my foundation, which is the Just Keep Livin Foundations, we got together and said, we’re not disaster relief, but want to be disaster relief. We said, let’s go. And I headed to Texas. I got on the phone, Camilla got on the phone. 100% of the people we called, whether it was companies who donated, whether it was musicians who came in, everybody was a yes in the first 30 seconds. We went down to Texas, put the show on. We raised over $7.7 million, which is still being put out to our community.\n",
      "\n",
      "Jimmy Fallon: (06:05)\n",
      "That’s how you do it right there. You just stepped up. And I go, oh my gosh, what do you know about putting on a live concert? You’re like, nothing.\n",
      "\n",
      "Matthew McConaughey: (06:12)\n",
      "It was like takes today. You get one take, two maximum, but let’s throw it together. Because you have to. Disaster relief, you have to move quickly because if you take your time to say, oh, this has got to be perfect. Something else is taking the front page news. There’s another disaster coming, you know? So you need to jump on it quickly and get everyone together and take advantage of trying to get people to give at that time when it is front page news and they know people need help.\n",
      "\n",
      "Jimmy Fallon: (06:36)\n",
      "I saw Hollywood Reporter named you philanthropist of the year with all the stuff you do to give back.\n",
      "\n",
      "Matthew McConaughey: (06:41)\n",
      "That was cool.\n",
      "\n",
      "Jimmy Fallon: (06:44)\n",
      "It’s good to be you, but it’s also great to give back and it’s great. You know what you do? You show up. Every time you always show up for me, but I think for anything. I know you’re a great dad.\n",
      "\n",
      "Matthew McConaughey: (06:56)\n",
      "Thank you. Try to. I think we all try to. I think we learn more and more as we age, we serve ourself when we do serve others. That is a reciprocity little exchange right there. And then also there’s ways to serve ourself and serve others at the same time and where those two meet when we’re filling our bank account and our souls account at the same time, we’re getting the quantity and the quality at the same time. Honey, ho.\n",
      "\n",
      "Jimmy Fallon: (07:20)\n",
      "That’s what I’m talking about. I want to talk about and show a clip from Sing 2. More with Matthew McConaughey when we come back. Everybody come on back.\n"
     ]
    }
   ],
   "source": [
    "f = open(\"interview.txt\", \"r\").read()\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7e6dea9-7ae5-42ae-8195-b670e36d1482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =f\"\"\"\n",
    "Human:\n",
    "Generate a summary of the transcription in the <transcription></transcription> XML tags below.\n",
    "Then, classify the mood of the participants according to the closest category within 'fully satisfied', 'satisfied', 'unsatisfied', 'fully unsatisfied', or 'neutral'.\n",
    "\n",
    "<transcription>\n",
    "{f}\n",
    "</transcription>\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "770b5b1d-d553-4526-8892-ec9f4570f731",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the transcription:\n",
      "\n",
      "Jimmy Fallon and Matthew McConaughey discuss McConaughey's holiday plans, family traditions, and philanthropic work. McConaughey talks about celebrating Christmas with both his and his wife Camila's extended families, which results in long days of present opening and meals. Fallon and McConaughey bond over memories of saving wrapping paper and impatiently waiting to open presents with family. \n",
      "\n",
      "McConaughey discusses his decision not to run for Texas governor at this point to focus on his family and storytelling. However, he does not rule out running for political office in the future. McConaughey also talks about organizing a benefit concert that raised over $7 million for Texans affected by Winter Storm Uri. Fallon praises McConaughey for his philanthropic work and showing up to help others in times of need.\n",
      "\n",
      "Overall, the mood of the participants seems satisfied and content discussing family, charity work, and life events. The friendly, casual tone and laughter throughout the conversation indicates Fallon and McConaughey are fully satisfied with their discussion. \n",
      "\n",
      " Inference time: 0:00:09.338650\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29d09320-6f1e-4596-8f51-55dfc0b127d5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the transcription:\n",
      "\n",
      "- Jimmy Fallon and Matthew McConaughey discuss Matthew filming a Christmas song for Jimmy's show. They had fun filming it together.\n",
      "\n",
      "- Matthew talks about his family's Christmas traditions which involve both his and his wife's large extended families. They celebrate on Christmas Eve and Christmas Day, so the celebrations last a long time. \n",
      "\n",
      "- They discuss New Year's resolutions and Matthew says his resolution last year was to work on his patience. \n",
      "\n",
      "- Jimmy congratulates Matthew on the success of his book \"Green Lights\" which was a New York Times bestseller for 50 weeks and sold over 2.5 million copies. Matthew says he had no idea it would be so successful but it hit a nerve with people.\n",
      "\n",
      "- They discuss Matthew's new companion journal to his book to help people journal their own stories. \n",
      "\n",
      "- Matthew considered running for governor of Texas but recently decided not to run, citing his young children and wanting to focus on storytelling at this point in his life. \n",
      "\n",
      "- Matthew organized a benefit concert in Texas after a winter storm to raise money for disaster relief, which raised over $7 million.\n",
      "\n",
      "- In summary, the mood of the conversation seems 'fully satisfied'. The participants are enjoying their discussion, congratulating each other on successes, and discussing positive life events and charitable work in a cheerful manner. \n",
      "\n",
      " Inference time: 0:00:05.302026\n"
     ]
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "print(response, \"\\n\\n\", \"Inference time:\", latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9410031e-d47f-485f-b83e-cbdbbb2fa42b",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d617cee-a8e9-4728-b821-6ebf2c6d51fc",
   "metadata": {},
   "source": [
    "## 5. Create splash pages describing upcoming promotions\n",
    "\n",
    "**Use Case:** A company wants to create HTML pages quickly and easily for their upcoming promotions.\n",
    "\n",
    "**Task:** Code Generation\n",
    "\n",
    "**Prompt Technique:** Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e248a2a2-687b-40c5-aeed-e183bd181b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data =\"\"\"\n",
    "There is an upcoming promotion presented by the Spanish Wings airline.\n",
    "The promotion is targeting young audience in the age range between 18 and 40.\n",
    "The promotion consists of a 20% discount when purchasing tickets online.\n",
    "There will be additional fees for seat assignment and tickets can be bought trought this same portal.\n",
    "The promotion is part of the Summer Discounts of the company.\n",
    "The promotion is available from June 28th to August 31st.\n",
    "\n",
    "Based the this information, generate the HTML code for an attractive splash page for this promotion.\n",
    "Include catchy phrases and invite customers to sign-up for the airlines' loyalty program.\n",
    "Have the splash page use yellow fonts and black background, according to the airlines' branding.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2f4a927-6e7a-49fd-b253-6ee555b17fbe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "Here is a draft HTML code for the splash page:\n",
       "\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>Spanish Wings Summer Promotion</title> \n",
       "<style>\n",
       "body {\n",
       "background-color: black;\n",
       "color: yellow; \n",
       "font-family: Helvetica, sans-serif;\n",
       "}\n",
       "h1 {\n",
       "font-size: 60px;\n",
       "}\n",
       "p {\n",
       "font-size: 20px;\n",
       "}\n",
       "</style>\n",
       "</head>\n",
       "<body>\n",
       "<h1>20% OFF THIS SUMMER!</h1>\n",
       "<p>Young travelers, this one's for you! From June 28 to August 31, get 20% off when you book on <span style=\"color:red;\">spanishwings.com</span>.</p>\n",
       "<p>Escape the heat and discover new destinations. Adventure awaits!</p>  \n",
       "<button style=\"background-color: yellow; color: black; font-size: 25px;\">Sign up for our loyalty program today!</button> \n",
       "<p>Additional baggage and seat selection fees may apply. Discount applies to base fare only.</p>\n",
       "<img src=\"beach.jpg\" width=\"600\" height=\"400\">\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-v1', prompt_data)\n",
    "#print(response, \"\\n\\n\", \"Inference time:\", latency)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbf6f2f2-601e-4da8-bf2f-ec1ef4840faf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "<body style=\"background-color:black;\">\n",
       "<center>\n",
       "<h1 style=\"color:yellow;\">Fly Now, Pay Less with Spanish Wings!</h1>\n",
       "<p style=\"color:yellow;\">Get 20% off your next flight when you book online now.</p>\n",
       "<p style=\"color:yellow;\">Hurry, offer ends August 31!</p> \n",
       "<p style=\"color:yellow;\">Sign up for our loyalty program and earn points on every flight.</p>\n",
       "<form>\n",
       "<input style=\"color:yellow;\" type=\"email\" placeholder=\"Enter email\"> \n",
       "<input style=\"color:yellow;\" type=\"submit\" value=\"Sign Me Up!\">\n",
       "</form>  \n",
       "</center>\n",
       "</body>\n",
       "</html>\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response, latency = call_bedrock('anthropic.claude-instant-v1', prompt_data)\n",
    "#print(response, \"\\n\\n\", \"Inference time:\", latency)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c45ec6-8934-4a2e-a53c-03ffa81ddd31",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
