{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db53f808-9fbd-408d-a6a0-d18200733876",
   "metadata": {},
   "source": [
    "## Using PyTorch DLC to Host the Whisper Model for Automatic Speech Recognition Tasks\n",
    "\n",
    "This notebook is derived from this blog post:  https://aws.amazon.com/blogs/machine-learning/host-the-whisper-model-on-amazon-sagemaker-exploring-inference-options/\n",
    "\n",
    "This notebook requires the **ml.m5.large** instance with **Data Science 2.0** kernel (Python 3.8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a75f20-21ff-4d05-a0e8-50a6ceaa49c2",
   "metadata": {},
   "source": [
    "### Common set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12501f18-d807-4337-b4e9-7e1c2d7590df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper==20231117 in /opt/conda/lib/python3.8/site-packages (20231117)\n",
      "Requirement already satisfied: triton<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from openai-whisper==20231117) (2.1.0)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.8/site-packages (from openai-whisper==20231117) (0.54.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from openai-whisper==20231117) (1.20.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from openai-whisper==20231117) (2.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from openai-whisper==20231117) (4.62.3)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.8/site-packages (from openai-whisper==20231117) (8.10.0)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.8/site-packages (from openai-whisper==20231117) (0.5.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.3.1)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/lib/python3.8/site-packages (from numba->openai-whisper==20231117) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from numba->openai-whisper==20231117) (69.0.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.8/site-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.8/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (1.9)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.3.101)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchaudio==2.1.2 in /opt/conda/lib/python3.8/site-packages (2.1.2)\n",
      "Requirement already satisfied: torch==2.1.2 in /opt/conda/lib/python3.8/site-packages (from torchaudio==2.1.2) (2.1.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (1.9)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2->torchaudio==2.1.2) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->torchaudio==2.1.2) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch==2.1.2->torchaudio==2.1.2) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch==2.1.2->torchaudio==2.1.2) (1.3.0)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets==2.16.1 in /opt/conda/lib/python3.8/site-packages (2.16.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (3.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (1.20.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (1.3.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (4.62.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.8/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (0.20.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from datasets==2.16.1) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.16.1) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.16.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.16.1) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.16.1) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.16.1) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.16.1) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.19.4->datasets==2.16.1) (4.8.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets==2.16.1) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.16.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.16.1) (3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.16.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.16.1) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==2.16.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==2.16.1) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets==2.16.1) (1.16.0)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: librosa==0.10.1 in /opt/conda/lib/python3.8/site-packages (0.10.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (5.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (0.54.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (4.8.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.8/site-packages (from librosa==0.10.1) (1.0.2)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/lib/python3.8/site-packages (from numba>=0.51.0->librosa==0.10.1) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from numba>=0.51.0->librosa==0.10.1) (69.0.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa==0.10.1) (4.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa==0.10.1) (21.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa==0.10.1) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20.0->librosa==0.10.1) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile>=0.12.1->librosa==0.10.1) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa==0.10.1) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->pooch>=1.0->librosa==0.10.1) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.10.1) (2023.11.17)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: soundfile==0.12.1 in /opt/conda/lib/python3.8/site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile==0.12.1) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile==0.12.1) (2.20)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U openai-whisper==20231117\n",
    "%pip install -U torchaudio==2.1.2\n",
    "%pip install -U datasets==2.16.1\n",
    "%pip install -U librosa==0.10.1\n",
    "%pip install -U soundfile==0.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fec1136-d7b0-402f-b959-d0302680c508",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import whisper\n",
    "import torchaudio\n",
    "import sagemaker\n",
    "import time\n",
    "import json\n",
    "import boto3\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443ea851-3d8c-42d6-bcbe-334d7cde01ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Basic configurations\n",
    "sess = sagemaker.session.Session()\n",
    "bucket = sess.default_bucket()\n",
    "region = sess._region_name\n",
    "prefix = 'whisper'\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# below boto3 clients are for invoking asynchronous endpoint \n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb0f2b-1dd6-4624-ad4b-b65a19937d2d",
   "metadata": {},
   "source": [
    "### Create Whisper pytorch model artifacts and upload to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c6071c7-dfac-4114-ab17-c71bfaf5df66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 131MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the PyTorch model and save it in the local repo\n",
    "model = whisper.load_model(\"base\")\n",
    "torch.save(\n",
    "    {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'dims': model.dims.__dict__,\n",
    "    },\n",
    "    'base.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be5edfa-3268-4cbf-9bd6-47f5951b1e02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./base.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-079002598131/whisper/pytorch/model/model.tar.gz'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the 'model' directory and create a tarball\n",
    "!mkdir -p model\n",
    "!mv base.pt model\n",
    "!tar cvzf model.tar.gz -C model/ .\n",
    "\n",
    "# Upload the model to S3\n",
    "model_uri = sess.upload_data('model.tar.gz', bucket=bucket, key_prefix=f\"{prefix}/pytorch/model\")\n",
    "!rm model.tar.gz\n",
    "!rm -rf model\n",
    "model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc49067-13c1-4512-b453-aead1c46164c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a unique model name and provide image uri\n",
    "\n",
    "id = int(time.time())\n",
    "model_name = f'whisper-pytorch-model-{id}'\n",
    "\n",
    "# !Please change the image URI for the region that you are using: e.g. us-east-1\n",
    "image = f\"763104351884.dkr.ecr.{region}.amazonaws.com/huggingface-pytorch-inference:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9682718-6ddf-4a75-a99e-7df8ba9a9c03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create a PyTorchModel for deployment\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "whisper_pytorch_model = PyTorchModel(\n",
    "    model_data=model_uri,\n",
    "    image_uri=image,\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir='code_pytorch',\n",
    "    name=model_name,\n",
    "    env = {\n",
    "        'MMS_MAX_REQUEST_SIZE': '2000000000',\n",
    "        'MMS_MAX_RESPONSE_SIZE': '2000000000',\n",
    "        'MMS_DEFAULT_RESPONSE_TIMEOUT': '900' \n",
    "    } # we use huggingface container, so add MMS env variables\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee32e99-edb5-43da-9bd4-015d4477933d",
   "metadata": {},
   "source": [
    "### Real-time inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25574fd6-d888-47b3-beb4-ab9a441d648a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import DataSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Define serializers and deserializer\n",
    "audio_serializer = DataSerializer(content_type=\"audio/x-audio\")\n",
    "deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a97d22-3990-4024-b859-1df12da7741d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "---------!CPU times: user 1min 44s, sys: 1.45 s, total: 1min 45s\n",
      "Wall time: 6min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Deploy the model for real-time inference\n",
    "endpoint_name = f'whisper-pytorch-real-time-endpoint-{id}'\n",
    "\n",
    "real_time_predictor = whisper_pytorch_model.deploy(\n",
    "    initial_instance_count=1,  # number of instances\n",
    "    instance_type=\"ml.g4dn.xlarge\",  # instance type\n",
    "    endpoint_name = endpoint_name,\n",
    "    serializer=audio_serializer,\n",
    "    deserializer = deserializer\n",
    ")\n",
    "# this step takes about 7 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5779179-cde1-472f-8307-3d33f0e63812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%mkdir -p tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb6c2b0-2b90-4313-a0c9-b46dd282b95e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/datasets/load.py:1429: FutureWarning: The repository for MLCommons/peoples_speech contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/MLCommons/peoples_speech\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeaec05925164bca980e4da5ab9109b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading metadata file: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio sample saved to 'tmp/sample_audio.wav'.\n"
     ]
    }
   ],
   "source": [
    "# Download a test data sample from huggingface dataset\n",
    "dataset = load_dataset('MLCommons/peoples_speech', split='train', streaming = True)\n",
    "sample = next(iter(dataset))\n",
    "audio_data = sample['audio']['array']\n",
    "output_path = 'tmp/sample_audio.wav'\n",
    "sf.write(output_path, audio_data, sample['audio']['sampling_rate'])\n",
    "\n",
    "print(f\"Audio sample saved to '{output_path}'.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8635750c-1d6e-48b6-ba28-3122924392da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I wanted to just share a few things, but I'm not going to not share as much as I wanted to share because we are starting late. I'd like to get this thing going so we all get home at a decent hour. This election is very important to us.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Perform real-time inference\n",
    "\n",
    "audio_path = \"tmp/sample_audio.wav\"\n",
    "#audio_path = \"wav/starwars_3s.wav\"\n",
    "#audio_path = \"wav/starwars_60s.wav\"\n",
    "\n",
    "response = real_time_predictor.predict(data=audio_path)\n",
    "\n",
    "print(json.loads(response[0])['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89c4ca3-39e9-4294-806d-1afd81dfd8d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfdd88c-8ded-408c-b1ba-aa9b273d1d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # optional: Delete real-time inference endpoint, this is not required for below steps\n",
    "# real_time_predictor.delete_endpoint()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9378e69-2aba-4060-bd6a-21561d169323",
   "metadata": {},
   "source": [
    "### Batch Transform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44690feb-f5c8-4c36-b79a-7af263f66edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create a transformer\n",
    "# whisper_transformer = whisper_pytorch_model.transformer(\n",
    "#     instance_count = 1,\n",
    "#     instance_type = \"ml.g4dn.xlarge\", \n",
    "#     output_path=\"s3://{}/{}/batch-transform/\".format(bucket, prefix),\n",
    "#     max_payload = 100\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51def5a5-a7e0-4926-89c4-f3ccb724c0eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Please provide the S3 path where you have one or more audio files that you want to process \n",
    "\n",
    "# data = \"s3://xxx/audio-files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c8b5c-5dc0-407a-8f39-616416cd8aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define request data and job name\n",
    "# job_name = f\"whisper-pytorch-batch-transform-{id}\"\n",
    "\n",
    "# # Start batch transform job\n",
    "# whisper_transformer.transform(data = data, job_name= job_name, wait = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c16fd-99e0-4178-8845-10a0fdaf02ac",
   "metadata": {},
   "source": [
    "### Asynchronous Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470dd4a-f898-4344-9e65-bc95f0fa76b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "# # Create an AsyncInferenceConfig object\n",
    "# async_config = AsyncInferenceConfig(\n",
    "#     output_path=f\"s3://{bucket}/{prefix}/output\", \n",
    "#     max_concurrent_invocations_per_instance = 4,\n",
    "#     # notification_config = {\n",
    "#             #   \"SuccessTopic\": \"arn:aws:sns:us-east-2:123456789012:MyTopic\",\n",
    "#             #   \"ErrorTopic\": \"arn:aws:sns:us-east-2:123456789012:MyTopic\",\n",
    "#     # }, #  Notification configuration \n",
    "# )\n",
    "\n",
    "# # Deploy the model for async inference\n",
    "# endpoint_name = f'whisper-pytorch-async-endpoint-{id}'\n",
    "# async_predictor = whisper_pytorch_model.deploy(\n",
    "#     async_inference_config=async_config,\n",
    "#     initial_instance_count=1, # number of instances\n",
    "#     instance_type ='ml.g4dn.xlarge', # instance type\n",
    "#     endpoint_name = endpoint_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9bf42a-5cba-49fb-96d2-4ac40c96d5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Provide the S3 path for the audio file you want to processs\n",
    "\n",
    "# input_path = \"s3://xxx/audio-files/xxx.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbb3d2-0b8d-4431-9cdb-6f48acaad709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Perform async inference\n",
    "# initial_args = {'ContentType':\"audio/x-audio\"}\n",
    "# response = async_predictor.predict_async(initial_args = initial_args, input_path=input_path)\n",
    "# response.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d804fecd-42d2-494e-8169-9c48f5fec233",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optional: Test autoscaling configurations for Async inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16a29a-67ac-4884-94ba-e2424debe2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# autoscale = boto3.client('application-autoscaling') \n",
    "# resource_id='endpoint/' + endpoint_name + '/variant/' + 'AllTraffic'\n",
    "\n",
    "# # Register scalable target\n",
    "# register_response = autoscale.register_scalable_target(\n",
    "#     ServiceNamespace='sagemaker', \n",
    "#     ResourceId=resource_id,\n",
    "#     ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "#     MinCapacity=0,  \n",
    "#     MaxCapacity=3 # * check how many instances available in your account\n",
    "# )\n",
    "\n",
    "# # Define scaling policy\n",
    "# scalingPolicy_response = autoscale.put_scaling_policy(\n",
    "#     PolicyName='Invocations-ScalingPolicy',\n",
    "#     ServiceNamespace='sagemaker', # The namespace of the AWS service that provides the resource. \n",
    "#     ResourceId=resource_id,  \n",
    "#     ScalableDimension='sagemaker:variant:DesiredInstanceCount', # SageMaker supports only Instance Count\n",
    "#     PolicyType='TargetTrackingScaling', # 'StepScaling'|'TargetTrackingScaling'\n",
    "#     TargetTrackingScalingPolicyConfiguration={\n",
    "#         'TargetValue': 3.0, # The target value for the metric. \n",
    "#         'CustomizedMetricSpecification': {\n",
    "#             'MetricName': 'ApproximateBacklogSizePerInstance',\n",
    "#             'Namespace': 'AWS/SageMaker',\n",
    "#             'Dimensions': [\n",
    "#                 {'Name': 'EndpointName', 'Value': endpoint_name }\n",
    "#             ],\n",
    "#             'Statistic': 'Average',\n",
    "#         },\n",
    "#         'ScaleInCooldown': 60, # The cooldown period helps you prevent your Auto Scaling group from launching or terminating \n",
    "#                                 # additional instances before the effects of previous activities are visible. \n",
    "#                                 # You can configure the length of time based on your instance startup time or other application needs.\n",
    "#                                 # ScaleInCooldown - The amount of time, in seconds, after a scale in activity completes before another scale in activity can start. \n",
    "#         'ScaleOutCooldown': 60 # ScaleOutCooldown - The amount of time, in seconds, after a scale out activity completes before another scale out activity can start.\n",
    "        \n",
    "#         # 'DisableScaleIn': True|False - indicates whether scale in by the target tracking policy is disabled. \n",
    "#                             # If the value is true , scale in is disabled and the target tracking policy won't remove capacity from the scalable resource.\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# scalingPolicy_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b7350-ed96-4ae8-b81b-97c2fe8a9cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trigger 1000 asynchronous invocations with autoscaling from 1 to 3\n",
    "# # then scale down to 0 on completion\n",
    "\n",
    "# print(endpoint_name)\n",
    "# for i in range(1,1000):\n",
    "#     response = sm_runtime.invoke_endpoint_async(\n",
    "#     EndpointName=endpoint_name, \n",
    "#     InputLocation=input_path)\n",
    "    \n",
    "# print(\"\\nAsync invocations for PyTorch serving with autoscaling\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67964e18-fab6-457a-9325-7ebea398d4a6",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660fd945-ee90-4773-add4-2168bb35d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Asynchronous inference endpoint\n",
    "async_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa31bad-1ccf-4cfe-ab0c-34ffb5eac997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
